<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pilosa</title>
    <link>https://www.pilosa.com/blog/</link>
    <description>Recent content from Pilosa</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Aug 2020 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.pilosa.com/blog/" rel="self" type="application/rss+xml" />
    
      
        <item>
          <title>The Effort Behind Marginal Performance Improvements</title>
          <link>https://www.pilosa.com/blog/marginal-performance-improvements/</link>
          <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/marginal-performance-improvements/</guid>
          <description>&lt;p&gt;A look at the amount of effort that we sometimes put into pursuing performance.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;Pilosa is built on the &lt;a href=&#34;https://roaringbitmap.org/&#34;&gt;Roaring bitmaps&lt;/a&gt; concept, a high-performance technique for operations on compressed sets of bits. It starts by representing all data in terms of bitmaps, each defined as one of three &amp;ldquo;container types&amp;rdquo;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Array: a list of integers indicating set bit positions.&lt;/li&gt;
&lt;li&gt;Bitmap: a direct binary representation of the bitmap.&lt;/li&gt;
&lt;li&gt;Run: a list of intervals, each indicating a contiguous &amp;ldquo;run&amp;rdquo; of set bits.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For each bitmap, its container type is chosen to minimize storage space, which keeps memory use low. Queries on the data are defined in terms of basic logical operations on pairs of bitmaps. Time-optimized operations are implemented for each pair of container types, which precludes the need for converting back and forth between container types (a drain on both memory and time).&lt;/p&gt;
&lt;p&gt;What we gain in query performance, we lose in added code complexity. This complexity is explained in a previous &lt;a href=&#34;https://www.pilosa.com/blog/adding-rle-support/&#34;&gt;blog post&lt;/a&gt;, where we detail how four logical operations, each supporting three container types for both operands, require 27 implementation functions.&lt;/p&gt;
&lt;p&gt;Now, I&amp;rsquo;d like to describe another dimension of complexity: in-place operations.&lt;/p&gt;
&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;
&lt;p&gt;While this proliferation of type-specific implementations does wonders for speed, it can be suboptimal in terms of memory allocation. In an illustrative example, we might execute a union across the containers of two existing rows in a Pilosa index. In this case, it&amp;rsquo;s not uncommon for the union of two containers to result in yet another, newly allocated container. But, in the case that one of the operands can be discarded, there is an opportunity to reduce memory usage by re-using that operand&amp;rsquo;s container: an &lt;a href=&#34;https://en.wikipedia.org/wiki/In-place_algorithm&#34;&gt;in-place&lt;/a&gt; operation.&lt;/p&gt;
&lt;p&gt;When one of our customers&#39; Pilosa clusters started consuming too much memory due to union-in-place operations, we had an opportunity to explore one facet of this problem. Diving into profiler logs, we noticed that most cases were a union-in-place of two &lt;strong&gt;run&lt;/strong&gt; containers. In this case, we would always convert the first &lt;em&gt;run container&lt;/em&gt; into a &lt;em&gt;bitmap container&lt;/em&gt;, and then perform the operation. This union operation is fast (simply iterate over runs and set the appropriate bits), but the prerequisite type conversion has a high memory cost. We needed to eliminate this, while maintaining the speed. And so a new operation function, &lt;code&gt;unionRunRunInPlace&lt;/code&gt;, was born.&lt;/p&gt;
&lt;p&gt;Specifically, this function needs to look at a pair of &lt;em&gt;run containers&lt;/em&gt;, combine them optimally, and return the result in one of the two original containers. As a graphical example, operating on input containers like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a:            |-----------------|

b:  |------------|              |---------|
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;should update container &lt;code&gt;a&lt;/code&gt; to look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;a:  |-------------------------------------|
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;While this is &lt;em&gt;essentially&lt;/em&gt; a basic algorithm problem, we found that the competing goals of time complexity, space complexity, and code complexity made things a bit more interesting. These functions power Pilosa&amp;rsquo;s core query engine, so keeping them performant and bug-free is a top priority. This partly explains why not all operation-type-type combinations currently have an in-place version; if they did, it would more than double the number of operation functions.&lt;/p&gt;
&lt;h2 id=&#34;the-solution&#34;&gt;The Solution&lt;/h2&gt;
&lt;p&gt;The new &lt;code&gt;unionRunRunInPlace&lt;/code&gt; went through several iterations before it settled into something both performant and maintainable.&lt;/p&gt;
&lt;p&gt;The first attempt was the naive one:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Join the two slices of intervals into one.&lt;/li&gt;
&lt;li&gt;Sort the joined slice.&lt;/li&gt;
&lt;li&gt;Iterate through intervals in joined slices and merge overlapping or adjacent intervals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This resulted in simple, understandable code, which accomplished the goal of avoiding the container type conversion. Adding a sorting step felt like the wrong approach; surely we can avoid all that additional time and memory usage. If nothing else, it became a useful baseline for benchmarking.&lt;/p&gt;
&lt;p&gt;The next attempt looked great in terms of performance. The idea was to iterate over the runs in both containers in parallel, selecting two near-by runs, and then handling each possible case of overlap in a separate branch, updating the values in the first container along the way.&lt;/p&gt;
&lt;p&gt;Unfortunately, it was &lt;strong&gt;so&lt;/strong&gt; high-performance that it was nearly unreadable. It sat in limbo for a week while we fought over the responsibility of reviewing it (one reviewer remarking &amp;ldquo;I&amp;rsquo;m not sure if I should be excited or scared by the use of the &lt;code&gt;goto&lt;/code&gt;&amp;quot;). I&amp;rsquo;m in favor of commenting code, but when understanding code crucially depends on dense comments, it may be a sign of fragility, and future maintenance problems.&lt;/p&gt;
&lt;p&gt;Fortunately, &lt;a href=&#34;https://github.com/kuba--&#34;&gt;Kuba&lt;/a&gt; stepped in with a much-improved third iteration. In the interest of keeping this post relatively short, we&amp;rsquo;ll just outline the approach here. Rather than iterating over &lt;em&gt;intervals&lt;/em&gt;, iteration is done over &lt;em&gt;values&lt;/em&gt;, while tracking a state variable indicating whether the current value is inside any interval or not. The shift to a state-based solution simplifies the code, in part by consolidating some logic into a state-update function. The inner loop again requires several branches for different interval-overlap cases, but now each branch calls the state-update function with minor differences. The resulting code is quite a bit more readable. &lt;a href=&#34;https://github.com/pilosa/pilosa/blob/55353a256773172284ed58b01c5e3ef49c4b4323/roaring/roaring.go#L3943&#34;&gt;See for yourself&lt;/a&gt;!&lt;/p&gt;
&lt;h2 id=&#34;the-results&#34;&gt;The Results&lt;/h2&gt;
&lt;p&gt;Below is a chart comparing performance before and after adding &lt;code&gt;unionRunRunInPlace&lt;/code&gt;. Each test case is described with a schematic representation of a bitmap: ■□□□□□□□ represents a bitmap with only the first bit set. Other patterns were also tested, and some cases showed worse performance, but generally they were so pathological as to be meaningless (for example, bit patterns that would never be maintained in &lt;em&gt;run containers&lt;/em&gt; due to inefficiency). In practice, we find that &lt;em&gt;run containers&lt;/em&gt; often contain a small number of runs, so we expect these cases to be representative of real-world behavior.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/marginal-performance-improvements/performance-chart.png&#34; alt=&#34;Performance Improvement&#34;&gt;
&lt;em&gt;Performance Improvement&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In short, the performance improvement was consistent and fantastic: an order of magnitude faster, and two orders of magnitude less memory usage. This doesn&amp;rsquo;t look like a &amp;ldquo;marginal improvement,&amp;rdquo; you might say. That&amp;rsquo;s true, for this case in itself. As just one of five union-in-place functions, and one of 23 in-place functions, the overall effect on general query performance is tempered somewhat. Still, we&amp;rsquo;re proud of the progress.&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>The Value in Failed Prototypes</title>
          <link>https://www.pilosa.com/blog/engineering-through-failure/</link>
          <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/engineering-through-failure/</guid>
          <description>&lt;p&gt;To solve hard problems successfully, you usually have to be willing to
solve them unsuccessfully in order to learn more about them. The process of
learning &lt;em&gt;why&lt;/em&gt; a given solution doesn&amp;rsquo;t work can allow you to learn more about
what &lt;em&gt;would&lt;/em&gt; work. Here&amp;rsquo;s a case study.&lt;/p&gt;
&lt;h3 id=&#34;some-background&#34;&gt;Some background&lt;/h3&gt;
&lt;p&gt;This one is a bit complicated, so bear with me. There are two central
requirements that turn out to be in tension here.&lt;/p&gt;
&lt;h4 id=&#34;memory-mapping-and-memory-remapping&#34;&gt;Memory-mapping and memory-remapping&lt;/h4&gt;
&lt;p&gt;Pilosa works with fairly large data sets, and reading data in can be slow,
but memory-mapping files and reading them later can be fast. So we like to
memory-map files. This offers a neat bonus feature: The kernel is able to
drop pages of mapped data that are mapped to on-disk files, and recover
them later by reading the disk, which means that we can have more &amp;ldquo;memory&amp;rdquo;
available than there is physical memory in a machine. (That comes up more
than you might expect.)&lt;/p&gt;
&lt;p&gt;The unit by which these are done is called, internally, a &amp;ldquo;fragment&amp;rdquo;. A
fragment represents one shard&amp;rsquo;s worth of data for a single view of a
single field, but possibly many rows. Each fragment is about a million columns
by default, and each fragment gets its own distinct data file. Each fragment
(and bitmap) is logically divided into sections of 65,536 (1&amp;laquo;16) bits,
called &amp;ldquo;containers&amp;rdquo;; the individual container data structures are what
contain pointers to the mmapped data. So here&amp;rsquo;s how it looks right after
you&amp;rsquo;ve just opened a fragment from the disk:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/mmap1.png&#34; alt=&#34;Freshly-mapped fragment&#34;&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, it only works for data that&amp;rsquo;s identical to the on-disk
file. We don&amp;rsquo;t want to corrupt the data, so we don&amp;rsquo;t write back to the
memory-mapped parts of the file; rather, when an object which was memory-mapped
changes, we allocate new storage in memory and use that. So after a couple of
changes, it looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/mmap2.png&#34; alt=&#34;Partially-mapped fragment&#34;&gt;&lt;/p&gt;
&lt;p&gt;Unlike the file-backed memory, this memory can&amp;rsquo;t just be discarded by the kernel
whenever it wants more space. So, eventually, we want to update the on-disk
representation to match the in-memory representation, and go back to using
memory-mapped access. We call this operation a &amp;ldquo;snapshot&amp;rdquo;. After that, we would
end up in the same state we were in before, with a freshly-mapped fragment.&lt;/p&gt;
&lt;p&gt;So, that&amp;rsquo;s part one of the backstory: We have a lot of things which are
memory-mapped, and occasionally we want to clear the old memory maps and
make new ones.&lt;/p&gt;
&lt;h4 id=&#34;caching-and-copy-on-write-semantics&#34;&gt;Caching and copy-on-write semantics&lt;/h4&gt;
&lt;p&gt;Now let&amp;rsquo;s talk about mixed loads, where there&amp;rsquo;s both read and write operations
happening. It&amp;rsquo;s undesireable to have bits mutating while you read them, and
Go makes no guarantees about what happens if you try. So, when a read operation
comes in, it temporarily locks the object it&amp;rsquo;s reading from, and extracts the
bits it cares about. Then it &lt;em&gt;releases&lt;/em&gt; that lock, and goes on to process the
data it retrieved, without the lock held. So, we create a new in-memory
structure, which refers to the same memory that the fragment is using for
a single row&amp;rsquo;s data:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/mmap3.png&#34; alt=&#34;A row, with containers pointing at both mapped and heap storage&#34;&gt;&lt;/p&gt;
&lt;p&gt;But now that we&amp;rsquo;ve released the lock, other parts of the system can come along
and modify the data in the fragment. You might ask why we don&amp;rsquo;t just keep the
lock; the answer is that we have a lot of parallel processing going on, and
furthermore, in some cases we might need several separate reads from the same
data source, which will be used as inputs to computations which need to happen
before we can be done using this data. For instance, consider a query like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Intersect(Row(x=1),Row(x=2))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;Intersect&lt;/code&gt; query needs to operate on the contents of two separate rows from
the same field, which means they&amp;rsquo;re using the same storage. We have to be able
to retrieve both, and each of them wants to grab the lock, so they have to
release the lock, too.&lt;/p&gt;
&lt;p&gt;In the times of long-ago, we had a simple solution: Make a copy of the data,
store that copy in a cache, and then use that to answer read requests. And that
works, but it costs a &lt;em&gt;lot&lt;/em&gt; of memory, and takes a significant amount of time.&lt;/p&gt;
&lt;p&gt;To resolve this, we developed a software-emulated &amp;ldquo;copy on write&amp;rdquo; functionality;
when a given piece of data gets read, we don&amp;rsquo;t copy it, but we mark it as
&amp;ldquo;frozen&amp;rdquo;; this means that specific data is never allowed to be modified, and
anything that wants to modify it needs to create a copy and start using that
copy. So, when you read part of a bitmap, that part is frozen; when writes to
that part of the bitmap happen, the bitmap allocates new copies that it can
write to.&lt;/p&gt;
&lt;p&gt;So, in this scheme, if additional writes come in, they may change what
the fragment refers to, but they won&amp;rsquo;t change the contents of an existing
row object. It looks a bit like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/mmap4.png&#34; alt=&#34;Row with references to storage the fragment doesn&amp;rsquo;t use&#34;&gt;&lt;/p&gt;
&lt;p&gt;At this point, if a new write came in for Row 0, Container 1, we&amp;rsquo;d end up
with a &lt;em&gt;new&lt;/em&gt; container in memory; the row object would still point to the old
one, but the fragment would get the new one. Then, when the row argument goes
away, the in-memory object it was using gets garbage collected.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s part two of the backstory: We&amp;rsquo;re using copy-on-write semantics, and
unmodifiable copies of chunks of data, to reduce copying and memory overhead.&lt;/p&gt;
&lt;h4 id=&#34;oops&#34;&gt;Oops&lt;/h4&gt;
&lt;p&gt;And then I realized the problem, which didn&amp;rsquo;t show up in production often
enough for us to catch it, but which I could reproduce with a custom test
case: If you have stale containers using memory-mapped bits, and you unmap
the addresses they were at, and then access those containers, you have a crash.&lt;/p&gt;
&lt;p&gt;Have a look at the state immediately after a snapshot, when a row object
exists:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/mmap5.png&#34; alt=&#34;Row with references to an old mapping&#34;&gt;&lt;/p&gt;
&lt;p&gt;As long as the objects the row has references to aren&amp;rsquo;t memory-mapped, we
don&amp;rsquo;t have a problem. If they are, we have a problem &amp;ndash; when can we unmap
this memory?&lt;/p&gt;
&lt;p&gt;This initially escaped my notice because I had evaluated everything in terms of
changes to the actual representation of the container objects &amp;ndash; every operation
which could do that was being invoked on a specific container, and could check
that the container wasn&amp;rsquo;t frozen, or create a new container to operate on. But
unmapping memory &lt;em&gt;doesn&amp;rsquo;t&lt;/em&gt; have to write to the in-memory data structure to be
effectively a change to it, invalidating the address it stored for the data it
wants to refer to.&lt;/p&gt;
&lt;p&gt;The temporary solution for this is obvious: When marking a thing as frozen, we
always first make that initial copy, making it be a memory object rather than a
mapped object. Which is to say, revert a significant part of the copy-on-write
semantics change, and lose a lot of its benefits. The nicer solution would be to
make sure that we have a way to track whether anything&amp;rsquo;s still using a given
mapping, so we can map a new file, then unmap the old one only after all of its
users are gone. But that requires a way to &lt;em&gt;track&lt;/em&gt; all those users. And we
didn&amp;rsquo;t really have a good way to express that, and there&amp;rsquo;s a lot of code that
might be referencing these hunks of bitmaps, and all of it would need to be
changed. So this got shelved for a while; we took the performance hit but
kept things safe and stable.&lt;/p&gt;
&lt;h3 id=&#34;round-two-i-have-this-great-idea&#34;&gt;Round Two: I have this great idea&amp;hellip;&lt;/h3&gt;
&lt;p&gt;I wanted to work on some code to improve reliability during opens with
possibly-corrupt files, and in the process of this,  I ran into the problem that
the file open/close logic, which also handles memory mapping, was really a bit
more complicated than I wanted it to be. It wasn&amp;rsquo;t wrong, just hard to follow or
modify cleanly, and I wanted to fix this up. So I started working on cleaning it
up, and dividing it up into logical components that are easier to reason about.&lt;/p&gt;
&lt;p&gt;For instance, when we memory-map a new file, we need to point all the fragment&amp;rsquo;s
storage to that file&amp;rsquo;s mapping, so we can unmap the old file. This logic is
tied in closely with the logic for reading and validating the file and ensuring
that it&amp;rsquo;s not corrupt, and the logic for handling missing files, and it just
ends up being a lot. A good starting point would be to separate this logic out,
and handle the memory-mapping logic separately from the rest of the open/close
logic. Some of the complexity comes from the fragment needing to know what
its current memory-map is. So I wanted to make a separate object that represents
the memory-mapping and handles that bookkeeping.&lt;/p&gt;
&lt;p&gt;And that gave me an idea: Part of the problem is that we need to know the
address to unmap it, so if we overwrite the fragment&amp;rsquo;s memory-map
attribute, we&amp;rsquo;ve got to have unmapped the old one before that. But this separate
object could track the old mapping separately, and unmap it at some other
time.&lt;/p&gt;
&lt;p&gt;I named the new data structure a &amp;ldquo;generation&amp;rdquo;; each fragment would have
sequentially-numbered generations representing times we&amp;rsquo;ve opened a copy of that
fragment and mapped it in. The periodic &amp;ldquo;snapshot&amp;rdquo; tasks would then create a new
generation for that fragment. Then these generations could be assigned to
bitmaps as &amp;ldquo;sources&amp;rdquo;, which the bitmaps could then track, and mark as in-use or
not-in-use. So, basically: Reference counting. Unmap things when the reference
count reaches zero, and the problem is solved. (Narrator: It wasn&amp;rsquo;t solved.)&lt;/p&gt;
&lt;h4 id=&#34;building-a-new-interface&#34;&gt;Building a new interface&lt;/h4&gt;
&lt;p&gt;My initial design was to have a compatibility API for these which would still
do the copying, and a new API that would let you basically &amp;ldquo;check out&amp;rdquo; a given
mapping, then return it when you&amp;rsquo;re done, and that wouldn&amp;rsquo;t need to do the
copying. Existing code would start out using the compatibility API, and then
I&amp;rsquo;d migrate things to the new API and they&amp;rsquo;d work better.&lt;/p&gt;
&lt;p&gt;This does imply a fair amount of work, though, to track ownership, and make
sure it gets tracked correctly across operations. For instance, if you perform
a union operation on two bitmaps, it&amp;rsquo;s &lt;em&gt;possible&lt;/em&gt; that the resulting bitmap
actually still contains some of the individual containers from either or both
sources. So there&amp;rsquo;s support for making a combined/merged source. But if you
combine two references, should you end up with a single reference, or with
two? If you&amp;rsquo;re just performing an intersect operation on two items, and never
touch those items again, you probably want to think of this as one reference.
If you&amp;rsquo;re intersecting a row with each of 20 other rows, it&amp;rsquo;s more complicated.&lt;/p&gt;
&lt;p&gt;So I spent a few days prototyping this and making sure things ran and passed
the existing tests cleanly.&lt;/p&gt;
&lt;h4 id=&#34;testing-it-more-carefully&#34;&gt;Testing it more carefully&lt;/h4&gt;
&lt;p&gt;Eventually I had something that sort of worked, but I wasn&amp;rsquo;t confident that I&amp;rsquo;d
proven that it was correct. And then I had a great insight: Go supports
finalizers for garbage-collected objects, so I could write finalizers which
checked the reference counts on items, and their history, and reported items
which had the wrong reference count on close.&lt;/p&gt;
&lt;p&gt;That worked out pretty well. It definitely identified problems, and it
made it pretty easy to correct them. Well, easy to identify them and figure
out where they were happening; correcting them was hard, and messy, and
required a lot of fiddly little details to try to track reference counts
and ownership. Roughly two weeks after I first started on this, I had it
basically working: It passed all the tests, and thanks to the fancy
finalizer-based code, I had reasonable confidence that it was correct, and that
if we got anything wrong in the complicated reference-counting code, we would
be able to detect it.&lt;/p&gt;
&lt;p&gt;And that got me to thinking, and I had a couple of insights that are closely
related:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;My confidence in the finalizers is much higher than my confidence in
the code they&amp;rsquo;re checking.&lt;/li&gt;
&lt;li&gt;The entire purpose of this is to determine whether or not I have anything
left that contains a reference to a thing. I don&amp;rsquo;t actually care about the
number of references, just &amp;ldquo;are there any&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;So basically, this is just a slower, more error-prone, reimplementation
of what the garbage collector &lt;em&gt;already does&lt;/em&gt; to decide whether to call those
finalizers.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Which is to say, I realized I&amp;rsquo;d just spent two weeks building a convincing
argument against my current design.&lt;/p&gt;
&lt;h3 id=&#34;round-three-lessons-learned&#34;&gt;Round Three: Lessons Learned&lt;/h3&gt;
&lt;p&gt;So I started over, mostly. I kept a lot of the base code for the generations,
and the source tracking, but I didn&amp;rsquo;t implement any reference counting at all.
Instead, I implemented a tracker (controlled by a build tag) which records
when a generation is created, when we declare it &amp;ldquo;ended&amp;rdquo; (not planning to
hand out new references to it), and when it gets finalized, and functionality
for reporting on any generations which ended up in undesired states. For
instance, if a generation got finalized without having been marked as ended,
or hadn&amp;rsquo;t been finalized yet at the end of the run, even after explicitly
running the garbage collector, that should be reported as suspicious. That&amp;rsquo;s
no longer a functional part of the generation code; it&amp;rsquo;s an additional bit
of code used only for debugging and testing.&lt;/p&gt;
&lt;p&gt;Implementing this, and cleaning it up, took about a week. It did turn up a
handful of bugs, but while the previous implementation turned up mostly bugs it
had &lt;em&gt;introduced&lt;/em&gt; by requiring careful reference counting which could be wrong,
this one caught &lt;em&gt;existing&lt;/em&gt; problems like tests which weren&amp;rsquo;t cleaning up after
themselves properly, which are arguably actual bugs.&lt;/p&gt;
&lt;p&gt;This code isn&amp;rsquo;t in-tree yet, because we still want to do more testing, but
it appears that it finally gets us the performance boosts we wanted for
read-only access to files, without the crash risks we were working so hard
to avoid. Memory usage and CPU time are down, and the code that manages
opening and closing the files is clearer and easier to read.&lt;/p&gt;
&lt;p&gt;But the point of this long rambling story is: I wouldn&amp;rsquo;t have gotten there
without the detour.&lt;/p&gt;
&lt;p&gt;If you want to do something that looks hard, and you&amp;rsquo;re not sure whether you
can do it, the best strategy I&amp;rsquo;ve found is to go &lt;em&gt;try&lt;/em&gt; it, even if you&amp;rsquo;re
not sure at all whether your approach is going to be viable. The most likely
outcome is that you will fail, but that you&amp;rsquo;ll learn enough about the problem
in the process to have a much better chance next time. That said, test your
experimental designs extra carefully and thoroughly; if the reason you&amp;rsquo;re in
this situation is that you don&amp;rsquo;t fully understand what problems you need to
solve, you shouldn&amp;rsquo;t assume that you&amp;rsquo;ll have thought of all the problems that
might crop up.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.pexels.com/photo/close-up-of-pictures-185933/&#34;&gt;Hero image credit&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Pilosa 1.4 Released</title>
          <link>https://www.pilosa.com/blog/pilosa-1-4-released/</link>
          <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/pilosa-1-4-released/</guid>
          <description>&lt;p&gt;Yesterday we cut Pilosa v1.4.0 — our first new minor version since
April! While we haven&amp;rsquo;t made an official release since then, several
of &lt;a href=&#34;https://www.molecula.com/&#34;&gt;Molecula&amp;rsquo;s&lt;/a&gt; clients have been using
much of the new Pilosa code for some time and some of the improvements
are &lt;strong&gt;vast&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This release has a variety of fixes, changes, and additions, and you
can get all the gory details in &lt;a href=&#34;https://github.com/pilosa/pilosa/blob/master/CHANGELOG.md&#34;&gt;the
changelog&lt;/a&gt;.
I would, however, like to call out a few of the more interesting
developments, and go into more detail on the general theme of &amp;ldquo;worker
pools&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;callouts&#34;&gt;Callouts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/1988&#34;&gt;Improved startup time&lt;/a&gt;
by concurrently loading fragment data. This makes it possible to
iterate faster when working with large data sets in Pilosa, and to
recover from failures more quickly.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2041&#34;&gt;Using UnionInPlace for time range
queries&lt;/a&gt; greatly reduces
memory allocations for these queries which improves overall
performance and stability. This makes a night and day difference for
workloads which query time ranges.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/1902&#34;&gt;Made integer fields unbounded by using sign+magnitude
representation&lt;/a&gt;. This
means one no longer needs to specify the minimum or maximum values
for an integer field ahead of time, and integers will use &lt;em&gt;exactly&lt;/em&gt;
the number of bits they need to represent the data they have on a
per-shard basis. The range grows and shrinks automatically.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2004&#34;&gt;Added fuzz tests&lt;/a&gt; to
our roaring implementation, and fixed
&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2021&#34;&gt;a&lt;/a&gt;
&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2019&#34;&gt;number&lt;/a&gt;
&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2017&#34;&gt;of&lt;/a&gt;
&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2012&#34;&gt;subtle&lt;/a&gt;
&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/1975&#34;&gt;bugs&lt;/a&gt;. Big shout out to
our interns for tackling this project!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;worker-pools&#34;&gt;Worker Pools&lt;/h3&gt;
&lt;h4 id=&#34;the-problem&#34;&gt;The Problem&lt;/h4&gt;
&lt;p&gt;To motivate this section, I need to describe a particular subtle issue
that has been plaguing us for some time. Pilosa runs a background task
which uses a gossip protocol to maintain cluster membership and share
metadata around the cluster. This task issues constant heartbeats to
check that all the nodes in the cluster are still around and
healthy. If a node hasn&amp;rsquo;t been heard from after a particular amount of
time or number of retries, it is marked as dead and the cluster may
drop into a non-working state depending on how many replicas it has
configured. The problem we&amp;rsquo;d been having was that the gossip task
would erroneously identify nodes as having died when the cluster was
under load.&lt;/p&gt;
&lt;p&gt;The root cause of this issue was very difficult to track down, and I&amp;rsquo;m
not sure we&amp;rsquo;ve 100% nailed it, but this is the best theory we have at
this time:&lt;/p&gt;
&lt;p&gt;Pilosa tends to have a relatively large number of objects on the
heap. This means that Go&amp;rsquo;s garbage collector has to do a lot of work
during its marking phase scanning through all of the data even though
it is mostly long-lived and static. Normally this isn&amp;rsquo;t too much of a
problem, though it does take a percentage of system resources. Go&amp;rsquo;s GC
does almost all of its work concurrently with two very short STW
(stop-the-world) phases where it has to make sure all running threads
get to a safe point, stop them, and then do a small amount of
work. Most code is chock-full of preemption points where the runtime
can quickly stop all threads, do the GC work, and get them running
again within microseconds. It&amp;rsquo;s possible, however, to write code with
very tight loops which can block GC from running for arbitrarily long
times. This is documented
&lt;a href=&#34;https://github.com/golang/go/issues/10958&#34;&gt;here&lt;/a&gt;, and is being worked
on for future versions of Go.&lt;/p&gt;
&lt;p&gt;What seems to happen is that Pilosa has many routines performing heavy
query processing tasks which involve tight loops that may run for a
few ms at a time. When the GC reaches a STW phase, it has to wait for
all running routines to finish whatever tight loops they are in, and
won&amp;rsquo;t let new routines be scheduled until it finishes its phase. So,
every time GC has to run, there are two &amp;ldquo;spin down&amp;rdquo; phases where we have
to wait for all running threads to get out of tight loops (meanwhile
the threads which finish first are idle), &lt;em&gt;and&lt;/em&gt; a significant percentage
of CPU resources are taken up by GC work.&lt;/p&gt;
&lt;p&gt;This problem is compounded if there are many goroutines all vying for
attention from the scheduler, and there&amp;rsquo;s no way to tell the scheduler
that this one tiny background task in a single one of those goroutines
is actually somewhat latency sensitive, and &amp;ldquo;hey could you maybe run
this one thing pretty regularly so that it doesn&amp;rsquo;t look like this
whole machine has fallen off the face of the planet causing a total
failure of the cluster until it re-establishes contact??&amp;rdquo;&lt;/p&gt;
&lt;p&gt;So&amp;hellip; in addition to a variety of other improvements we&amp;rsquo;ve made to
reduce the amount of data and pointers visible to GC, and to reuse
memory rather than re-allocating it, we thought it might be best to
reduce the number of goroutines competing for scheduling attention at
any given time.&lt;/p&gt;
&lt;h4 id=&#34;query-pool&#34;&gt;Query Pool&lt;/h4&gt;
&lt;p&gt;We &lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2034&#34;&gt;implemented&lt;/a&gt; a
goroutine worker pool for queries. This was one of those fun cases
where things worked very well until several dimensions of scale were
being exercised simultaneously. One particular workload had huge
amounts of data — a thousand Pilosa shards &lt;em&gt;per node&lt;/em&gt; (each shard is
roughly 1 million records), and was issuing dozens of concurrent
queries.&lt;/p&gt;
&lt;p&gt;Our original design had each query launching a separate goroutine
&lt;em&gt;per-shard&lt;/em&gt;, which in this case meant that tens of thousands of
goroutines were being created and destroyed every second. It is
absolutely a testament to the creators of Go and the efficiency of its
runtime that things were still more-or-less working at this scale.&lt;/p&gt;
&lt;p&gt;The classic solution to this problem is to create a fixed pool of
long-lived goroutines and pass items of work to them through a
channel. In this case, the per-shard query processing work is pretty
CPU intensive, so there isn&amp;rsquo;t much point in having concurrency beyond
the number of CPU cores available. Luckily Go provides us with a
mechanism for determining the number of logical CPUs available with
&lt;code&gt;runtime.NumCPU()&lt;/code&gt;, so at startup time, we create a pool of goroutines
of that size to process queries.&lt;/p&gt;
&lt;p&gt;Amazingly, the actual performance issue that we were experiencing
around this was not that 20,000 goroutines were popping in and out of
existence each second, which the runtime handled pretty well, but that
in some cases they were all contending for the same mutexes. We
discovered via &lt;a href=&#34;https://golang.org/pkg/net/http/pprof/&#34;&gt;profiling&lt;/a&gt;
that there was a lot of contention in our
&lt;a href=&#34;https://opentracing.io/&#34;&gt;tracing&lt;/a&gt; subsystem which probabilistically
samples queries and provides detailed timing and metadata about each
processing step. Manually disabling tracing and other sources of lock
contention resulted in similar performance to what we achieved after
implementing the worker pool. With the worker pool, however, we were
able to re-enable important services like tracing without running into
lock contention issues.&lt;/p&gt;
&lt;h4 id=&#34;ingest-pools&#34;&gt;Ingest Pools&lt;/h4&gt;
&lt;p&gt;Query processing wasn&amp;rsquo;t the only area we found where we could benefit
from worker pools. In
&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2024&#34;&gt;#2024&lt;/a&gt; we added a
different sort of pool which helped to make data ingest more
efficient. Pilosa often has to decide between applying writes in
memory and appending them to a file, or taking a full snapshot of a
whole data fragment. Previously, it made this decision on a
fragment-by-fragment basis, which could result in many snapshots being
taken simultaneously. Now, there is a small pool of background
routines which combs through fragments with outstanding writes, and
limits concurrent snapshotting to more efficiently use the available
I/O throughput. When the system is under heavy load, it will naturally
skew more towards append only writes, and each snapshot will be
covering more outstanding writes.&lt;/p&gt;
&lt;p&gt;We also implemented a &lt;a href=&#34;https://github.com/pilosa/pilosa/pull/2048&#34;&gt;worker pool for import
jobs&lt;/a&gt; so that large
numbers of concurrent imports wouldn&amp;rsquo;t spawn unlimited numbers of
goroutines potentially created the same performance and contention
issues we&amp;rsquo;d seen with queries.&lt;/p&gt;
&lt;h3 id=&#34;wrapping-up&#34;&gt;Wrapping Up&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;m very proud of the work the team has done between 1.3 and 1.4, but
more than that, I&amp;rsquo;m excited for what we already have lined up for our
next release. We decided to cut the 1.4 release with what we knew was
a fairly stable codebase, even though there were a number of
outstanding pull requests with interesting features and improvements.&lt;/p&gt;
&lt;p&gt;Be on the lookout for another release before too long with interesting things like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An extension interface for dynamically adding new query
functionality to Pilosa.&lt;/li&gt;
&lt;li&gt;An overhauled, and more scalable key translation system.&lt;/li&gt;
&lt;li&gt;New types of queries (e.g. GROUP BY with aggregates over integer fields).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/blob/master/CONTRIBUTING.md&#34;&gt;Contributions&lt;/a&gt; from viewers like you!&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
      
    
      
        <item>
          <title>Apophenia: Seeking Patterns in Randomness</title>
          <link>https://www.pilosa.com/blog/apophenia/</link>
          <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/apophenia/</guid>
          <description>&lt;p&gt;Apophenia provides a seekable (but not cryptographically secure) PRNG
implementation. Because what&amp;rsquo;s the point in random numbers if you can&amp;rsquo;t
predict them?&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;One of the difficulties of working with large data sets is that large data
sets take up a large amount of space. For testing and benchmarking, it
turns out that you don&amp;rsquo;t care that much whether the data&amp;rsquo;s accurate, but you
want to be able to generate it quickly.&lt;/p&gt;
&lt;p&gt;To this end, I started working on a tool called &lt;code&gt;imagine&lt;/code&gt; (still being
developed) which allows creating pretty large amounts of data matching
fairly arbitrary specifications of its characteristics. For instance, we
might want data in which about 1% of bits are set, or data where which bits
are set follows a Zipf distribution.&lt;/p&gt;
&lt;p&gt;And then I had this great idea: It&amp;rsquo;d be nice, for performance testing, to be
able to compare results between data sets even when the data sets were generated
in different ways. For instance, generating all the column values for one row,
then moving on to the next row, or generating all the row values for one column,
then moving on to the next column. But what if differences between the data sets
made them perform differently? Obviously, the solution is to make sure the data
will be the same regardless of the order in which it&amp;rsquo;s generated. And that
suggests that what we really want is not just a PRNG, but a PRNG where
we can seek to a given point in its output stream arbitrarily.&lt;/p&gt;
&lt;p&gt;I spent some time looking into existing work in this field, and there&amp;rsquo;s a lot
of it, but most of it is relatively computationally expensive, and really,
we don&amp;rsquo;t &lt;em&gt;care&lt;/em&gt; about the quality of the bits all that much &amp;ndash; we just need
a lot of them, really fast.&lt;/p&gt;
&lt;p&gt;Enter the realization that AES-128 is very similar to a PRNG. If you initialize
an AES block cipher with a given key (think of that as a seed), and then treat
its 128-bit inputs as a 128-bit integers, start at 0, and count up, you get a
series of 128-bit values. This isn&amp;rsquo;t a novel idea; there&amp;rsquo;s a lot of existing
implementations out there that do things basically like it, but the ones I&amp;rsquo;ve
found typically use the counter (CTR) mode, or one of the chained modes.
Apophenia runs in the default block cipher mode, maintaining an offset/counter
internally, so we can jump to specific locations in the stream.&lt;/p&gt;
&lt;p&gt;And I could have stopped there, and just built anything else that wanted
random values of more specific types in terms of it in our other code, but
there&amp;rsquo;s some conceptual overlap, so I built some of that additional
functionality into the same package, to make the implementation more
consistent.&lt;/p&gt;
&lt;p&gt;As a side note: Throughout, I&amp;rsquo;m referring to powers of two as &lt;code&gt;1&amp;lt;&amp;lt;N&lt;/code&gt; rather than
&lt;code&gt;2^N&lt;/code&gt;. This is because we&amp;rsquo;re writing in Go, and in Go, &lt;code&gt;2^16&lt;/code&gt; is just a fancy
way of spelling &lt;code&gt;18&lt;/code&gt;, and I am trying to get out of that habit before it bites
me.&lt;/p&gt;
&lt;h4 id=&#34;that-sure-is-a-lot-of-bits&#34;&gt;That sure is a lot of bits&lt;/h4&gt;
&lt;p&gt;First off, while AES-128 is usually conceived of as 16 byte inputs and outputs,
for our purposes, I wanted to treat it as a single &lt;code&gt;uint128&lt;/code&gt;, only that&amp;rsquo;s not
a type in Go. Enter &lt;code&gt;apophenia.Uint128&lt;/code&gt;, a structure that holds a pair of
&lt;code&gt;uint64&lt;/code&gt; values named &lt;code&gt;Hi&lt;/code&gt; and &lt;code&gt;Lo&lt;/code&gt;. (I am not the most creative person when
it comes to naming things.) So we&amp;rsquo;re looking at AES-128, not so much as a
sequence of &lt;code&gt;1&amp;lt;&amp;lt;135&lt;/code&gt; bits, as a sequence of &lt;code&gt;1&amp;lt;&amp;lt;128&lt;/code&gt; 128-bit values. You
might wonder why it&amp;rsquo;s a structure, and not &lt;code&gt;[2]uint64&lt;/code&gt;; the answer is the
compiler appears to be slightly smarter about the structure, and it&amp;rsquo;s a bit
less ambiguous. (Should &lt;code&gt;u[0]&lt;/code&gt; be the high-order-bits? Always, or just on
big-endian hardware? Let&amp;rsquo;s just call them Hi and Lo and be done.)&lt;/p&gt;
&lt;p&gt;I was raised by mathematicians and still think it&amp;rsquo;s weird when people call
a number large even though it&amp;rsquo;s obviously finite, but I will admit, there&amp;rsquo;s a
fair amount of space in a 128-bit input. We take advantage of this to ensure
that if you&amp;rsquo;re grabbing sequences of values from the 128-bit space, you don&amp;rsquo;t
get the same sequence for two different things.&lt;/p&gt;
&lt;p&gt;For our purposes, we&amp;rsquo;re mostly concerned with things where we might be iterating
over a 64-bit range of &amp;ldquo;columns&amp;rdquo;, so let&amp;rsquo;s use the column values as the low
order word of our &lt;code&gt;Uint128&lt;/code&gt; offsets. We also often care about iterating over
rows, which tend to be significantly smaller &amp;ndash; a few dozen is common, but we
could reasonably expect to see values in the low billions. So we&amp;rsquo;ll want
a 32-bit value that can correspond to those in some way. That leaves us only
32 more bits. Well, let&amp;rsquo;s block out an 8-bit byte for the &lt;em&gt;kind&lt;/em&gt; of thing being
generated &amp;ndash; for instance, Zipf distributions will use an entirely different
set of 128-bit values than we use when generating permutations. This doesn&amp;rsquo;t
really matter very much, but hey, bits are cheap. So we have 24 bits left. What
are those for? Well, it turns out, a lot of algorithms, like Zipf generators,
want multiple consecutive values which they iterate on. Let&amp;rsquo;s call those
&amp;ldquo;iterations&amp;rdquo; and give them the remaining 24 bits.&lt;/p&gt;
&lt;p&gt;So this gives us our layout:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/apophenia/seed-structure.png&#34; alt=&#34;Apophenia seed structure&#34;&gt;&lt;/p&gt;
&lt;p&gt;This allows some neat tricks. One is that you can compute the next iteration
from a given value just by incrementing the high-order word. Most of these
algorithms use only a handful of words, but just in case, the order is
selected such that overflowing iteration hops to a different sequence, not
to another seed of the same sequence. Similarly, you can just set the low-order
word to the index you want without worrying about the high-order word at all.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s also a convenience function to create these offsets:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;OffsetFor(sequence SequenceType, seed uint32, iteration uint32, id uint64) Uint128&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;useful-generators&#34;&gt;Useful Generators&lt;/h4&gt;
&lt;p&gt;It&amp;rsquo;s great to have a seekable PRNG, but usually you want values which follow
specific patterns. Apophenia provides a handful of prebuilt generators which
produce values following specific rules, built on top of an underlying &lt;code&gt;Sequence&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The three currently-defined types are permutations (yielding the values from
0 to N-1 in an arbitrary order), zipf distributions (yielding values from 0
to N with a weighted distribution), and weighted bits. The zipf and permutation
forms are straightforward, and correspond to similar functionality in Go&amp;rsquo;s
&lt;code&gt;math/rand&lt;/code&gt;, although making them seekable changes them a bit. The weighted
bits, however, are a relatively unusual application.&lt;/p&gt;
&lt;p&gt;Frequently, people look at creating weighted distributions of values; for
instance, if you generate numbers by summing evenly-distributed values, you
get a nice pretty bell curve. But in Molecula&amp;rsquo;s use case, we frequently want
billions of bits with some density of bits set; we don&amp;rsquo;t care so much about
weighting values within a larger range, as weighting 0 and 1.&lt;/p&gt;
&lt;p&gt;Usually, when people want to generate bits with a given probability that
they&amp;rsquo;re set, they generate a random number, then test it for a property with
the given probability of being true. For instance, if you want a 1-in-6 chance,
you might express this as &lt;code&gt;(x % 6) == 0&lt;/code&gt;, which is pretty close. (It&amp;rsquo;s not
exactly correct, because the range of x isn&amp;rsquo;t a multiple of 6, so some numbers
are more likely than others, but with a 64-bit range, it&amp;rsquo;s a very small
difference.) And this works reasonably well, but it does suggest one possible
problem, which is that you need to generate a random value for every bit you
want. What if you want to generate a &lt;em&gt;lot&lt;/em&gt; of bits?&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Weighted&lt;/code&gt; generator supports this use case. You give it a density,
expressed as a ratio where the denominator is a power of 2. For instance,
you could request bits of which 3/16 are set, or 7/1024. Apophenia then
creates bundles of 128 bits, with approximately that proportion of bits set,
using bitwise operations on &lt;code&gt;Uint128&lt;/code&gt;, using log2(denominator) steps. It
doesn&amp;rsquo;t try to solve the case where the denominator isn&amp;rsquo;t a power of two,
but it can generally be as close as you need, and it&amp;rsquo;s a significant speedup.&lt;/p&gt;
&lt;h4 id=&#34;future-directions&#34;&gt;Future Directions&lt;/h4&gt;
&lt;p&gt;The apophenia package is pretty new, but it&amp;rsquo;s been fairly stable from an API
standpoint for a while now. It will probably get more sequence types and
functionality added, but this seems like a good point for a release. So,
here you go: &lt;a href=&#34;https://github.com/molecula/apophenia&#34;&gt;https://github.com/molecula/apophenia&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Note that this implementation, despite being based on a crypto function, is
not itself reasonable for cryptographic purposes; it is entirely too possible
to derive information about the &amp;ldquo;state&amp;rdquo; of the PRNG and predict its behavior.
The tradeoff from security to controlled reproducibility is intentional, and
is not a bug, but it&amp;rsquo;s a real tradeoff.&lt;/p&gt;
&lt;h4 id=&#34;useful-links&#34;&gt;Useful Links&lt;/h4&gt;
&lt;p&gt;Some background reading if you want to read more about this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cryptographic_hash_function&#34;&gt;https://en.wikipedia.org/wiki/Cryptographic_hash_function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Advanced_Encryption_Standard&#34;&gt;https://en.wikipedia.org/wiki/Advanced_Encryption_Standard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://crypto.stackexchange.com/questions/32495/how-to-convert-aes-to-a-prng-in-order-to-run-nist-statistical-test-suite&#34;&gt;https://crypto.stackexchange.com/questions/32495/how-to-convert-aes-to-a-prng-in-order-to-run-nist-statistical-test-suite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/paragonie/seedspring&#34;&gt;https://github.com/paragonie/seedspring&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
      
    
      
        <item>
          <title>Building Throwaway Machines with Terraform</title>
          <link>https://www.pilosa.com/blog/terraform-experiment/</link>
          <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/terraform-experiment/</guid>
          <description>&lt;p&gt;Looking for an easy way to quickly try out some new whiz-bang software safely and securely? Look no further!&lt;/p&gt;
&lt;p&gt;At my day job at &lt;a href=&#34;https://www.molecula.com/&#34;&gt;Molecula&lt;/a&gt;, I often find myself needing to perform a simple experiment and I
run off and install a bunch of tools, run a bunch of tests, make brilliant
observations and then go onto the next Big Thing.  The problem with this approach is
if I run my experiments on my local laptop, it becomes cluttered and the cruft
builds up into an unmanageable rats nest.  When I run my experiments on
machines in the cloud, many juicy artifacts are often lost when my cloud machine
is destroyed.  I usually capture the major focus of the experiement in notes,
but later I realize that I missed something that was contained in the output of
a command or even what commands I actually executed.  So following the &lt;a href=&#34;http://www.jasontconnell.com/comment/grunt-work-principle&#34;&gt;grunt work principle&lt;/a&gt;,
this task must be automated.&lt;/p&gt;
&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;
&lt;p&gt;First, install the awesome Terraform, a cloud provisioning tool from
&lt;a href=&#34;https://www.hashicorp.com/&#34;&gt;HashiCorp&lt;/a&gt;. This basically requires putting an executable in your path, but the
install process is described in detail at &lt;a href=&#34;https://learn.hashicorp.com/terraform/getting-started/install.html&#34;&gt;HashiCorp&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once this is installed, you have to craft a few files that describe which cloud
provider to connect to and how to set it up.  The links below are the ones I use
for GCP (Google Cloud Platform), and those files assume you have exported your google
credentials to a local file &lt;code&gt;credentials.json&lt;/code&gt; file from the GCP dashboard, you use an RSA key
(&lt;code&gt;~/.ssh/id_rsa.pub&lt;/code&gt;) in your home directory and you have generated a gist cli access token (&lt;code&gt;~/.gist&lt;/code&gt;), the process to generate is described &lt;a href=&#34;https://github.com/defunkt/gist&#34;&gt;here&lt;/a&gt;. After those files are in place
simply &lt;code&gt;init&lt;/code&gt; and &lt;code&gt;apply&lt;/code&gt; and you are off to the races. You will have to replace the project value in the &lt;code&gt;main.tf&lt;/code&gt; with &lt;code&gt;project_id&lt;/code&gt; value located your &lt;code&gt;credentials.json&lt;/code&gt;&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/tgruben/b89299c25438e15129c25e7f14cee217.js&#34;&gt;&lt;/script&gt;

&lt;pre&gt;&lt;code&gt;terraform init
terraform apply
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once it&amp;rsquo;s all up and running you can access that machine by&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ssh ubuntu@`terraform output ip`
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And finally cleanup when you&amp;rsquo;re done with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;terraform destroy
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All ssh sessions are recorded to log files which reside in the ubuntu home directory &lt;code&gt;/home/ubuntu&lt;/code&gt; of the generated machine.  When the machine is destroyed via terraform those logs are uploaded to a &lt;a href=&#34;https://gist.github.com&#34;&gt;gist&lt;/a&gt; which has the nice feature of making the content of the gist indexed and searchable via &lt;a href=&#34;https://gist.github.com/search&#34;&gt;search&lt;/a&gt;.  Don&amp;rsquo;t forget to limit to just your gists by adding the user filter that looks something like &lt;code&gt;user:tgruben&lt;/code&gt;.  It should be noted that gists are publicly viewable.  You can add  the private flag &lt;code&gt;-p&lt;/code&gt; from the destroy hook in &lt;code&gt;main.tf&lt;/code&gt; and the content is not &lt;code&gt;discoverable&lt;/code&gt; but it is still viewable by the public if you can find the link.&lt;/p&gt;
&lt;p&gt;I hope you find this useful.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>How to Generate an Arbitrarily Large Amount of Test Data</title>
          <link>https://www.pilosa.com/blog/smote/</link>
          <pubDate>Wed, 21 Aug 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/smote/</guid>
          <description>&lt;p&gt;Have you ever looked at some publicly available data, and thought, &amp;ldquo;I wish this data set was 100 times larger&amp;rdquo;? It seems like there should be an easy way to do that, and it turns out, there is!&lt;/p&gt;
&lt;p&gt;Much of the work we do with &lt;a href=&#34;https://www.pilosa.com&#34;&gt;Pilosa&lt;/a&gt; involves benchmarking and optimization of data ingestion. With extreme scalability as one of our selling points, using large data sets is crucial. Sample data sets of all kinds are available all over the web, but it isn&amp;rsquo;t always easy to find data sets that are 1) huge, 2) meaningful, 3) well-fit to our target use cases and data models. Often we&amp;rsquo;ll find a great, clean public data set that looks perfect for an experiment, then download it and realize it consists of 100,000 records - not even close to big enough for our purposes.&lt;/p&gt;
&lt;h3 id=&#34;oversampling&#34;&gt;Oversampling&lt;/h3&gt;
&lt;p&gt;Oversampling can save us here. Wikipedia &lt;a href=&#34;https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis#Oversampling_techniques_for_classification_problems&#34;&gt;lists&lt;/a&gt; only three oversampling methods, starting with random duplication. While duplication would probably do fine for most of our work, it just feels icky to me. Ideally, we could generate realistic samples from the multidimensional distribution underlying the true dataset. A naive way to approach this is to use the marginal distributions - randomly choosing each column value (e.g. from a CSV file) based on the distribution of true values in that column - but this has problems too. Each value would look reasonable by itself, but the relationships between those values wouldn&amp;rsquo;t be realistic (usually).&lt;/p&gt;
&lt;p&gt;As a silly example, a medical data set might have two fields, &lt;code&gt;heartRate&lt;/code&gt; (numeric) and &lt;code&gt;alive&lt;/code&gt; (boolean):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;heartRate&lt;/th&gt;
&lt;th&gt;alive&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;180&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;60&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;90&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Analyzing each column, we can approximate its distribution independently of the others. Maybe we&amp;rsquo;d assume &lt;code&gt;heartRate&lt;/code&gt; is uniformly distributed between the minimum and maximum values, while &lt;code&gt;alive&lt;/code&gt; is either true or false, with a probability matching the proportion of true values in the data. Generating values for these independently, you might produce a record with &lt;code&gt;heartRate=90&lt;/code&gt; and &lt;code&gt;alive=false&lt;/code&gt;. With some approximation of that full, true distribution, we can avoid this situation. However, estimating such a thing for a CSV file with arbitrary data types, and correlations, seems tricky.&lt;/p&gt;
&lt;h3 id=&#34;smote&#34;&gt;SMOTE&lt;/h3&gt;
&lt;p&gt;The other two oversampling methods listed on Wikipedia are variants of &lt;a href=&#34;https://arxiv.org/pdf/1106.1813.pdf&#34;&gt;SMOTE&lt;/a&gt; (Synthetic Minority Over-sampling TEchnique), an old-fashioned AI algorithm that is deceptively simple, even elegant. SMOTE provides a solution to the correlation problem, without needing to explicitly understand the full distribution. We have taken the core idea of this algorithm, twisted it and abused it, to synthesize silly amounts of test data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/smote/smote-diagram.png&#34; alt=&#34;SMOTE concept&#34;&gt;
&lt;em&gt;Illustration of synthesizing data points in SMOTE. Graphic from a &lt;a href=&#34;https://www.jair.org/index.php/jair/article/view/11192&#34;&gt;survey&lt;/a&gt; of SMOTE extensions.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The basic algorithm is described &lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume16/chawla02a-html/node6.html&#34;&gt;here&lt;/a&gt;. Briefly, an original data point (x&lt;!-- raw HTML omitted --&gt;i&lt;!-- raw HTML omitted --&gt;, in N-dimensional space &lt;strong&gt;R&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;N&lt;!-- raw HTML omitted --&gt;) is chosen, one of K &lt;a href=&#34;https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm&#34;&gt;nearest neighbors&lt;/a&gt; (x&lt;!-- raw HTML omitted --&gt;i3&lt;!-- raw HTML omitted --&gt;, for example) is selected, and a random linear interpolation of those two is produced (r&lt;!-- raw HTML omitted --&gt;3&lt;!-- raw HTML omitted --&gt;). That&amp;rsquo;s it! Do that, say, 100 times for each data point, and you get a huge oversampling factor, with reasonable computational efficiency. SMOTE takes advantage of the local structure of the dataset to synthesize statistically reasonable data, without explicitly understanding the full correlations.&lt;/p&gt;
&lt;p&gt;This works great for real-valued (floating point) data. What if the dataset contains other types, like integers, categorical string values, or even arbitrary text? Although &lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume16/chawla02a-html/node15.html&#34;&gt;some variants&lt;/a&gt; handle some of these cases, we had a few other minor modifications in mind.&lt;/p&gt;
&lt;h3 id=&#34;pilosa-smote&#34;&gt;Pilosa-SMOTE&lt;/h3&gt;
&lt;p&gt;The practical goal is to run this algorithm on a wide range of CSV files, which means supporting more data types is important. Supporting integers and categorical values should go a long way, so we started with those. Let&amp;rsquo;s look at the last step of the basic SMOTE algorithm, the random combination (r&lt;!-- raw HTML omitted --&gt;3&lt;!-- raw HTML omitted --&gt;) of the original point (x&lt;!-- raw HTML omitted --&gt;i&lt;!-- raw HTML omitted --&gt;) and the neighbor (x&lt;!-- raw HTML omitted --&gt;i3&lt;!-- raw HTML omitted --&gt;). We can write this as r&lt;!-- raw HTML omitted --&gt;3&lt;!-- raw HTML omitted --&gt; = αx&lt;!-- raw HTML omitted --&gt;i&lt;!-- raw HTML omitted --&gt; + (1-α)x&lt;!-- raw HTML omitted --&gt;i3&lt;!-- raw HTML omitted --&gt;, where α is a random floating point value in [0, 1]. In pseudocode, with a single floating-point value for the data point &lt;code&gt;x&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;neighborIdx = rand.Intn(5)
weight = rand.Float64()
synthetic = weight * x + (1-weight) * neighbors[neighborIdx]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, if &lt;code&gt;x&lt;/code&gt; is an integer, this will still produce a floating-point synthetic value. To address this, we simply round the result to the nearest integer. If &lt;code&gt;x&lt;/code&gt; is categorical (say, one of ten different string values), this doesn&amp;rsquo;t quite work. We could select one of the values based on the random weight, that is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;synthetic = x
if weight &amp;lt; 0.5 {
    synthetic = neighbors[neighborIdx]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The problem with this is that in the case of a data set with all categorical values, this reduces to duplication of the entire record (because the same weight value is applied to each field). Instead, you might choose the value that occurs in the majority of the K nearest neighbors. Another option, the one we went with, is to use the weight to control &lt;em&gt;another&lt;/em&gt; random choice between the two points (with potentially different results for each field):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;synthetic = x
if weight &amp;lt; rand.Float64() {
    synthetic = neighbors[neighborIdx]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These handle a much wider range of data sets; the most significant remaining type is arbitrary text data. We have only started exploring Pilosa&amp;rsquo;s capabilities in that area, so we aren&amp;rsquo;t handling that here. With these modifications, and some finer control over the classes of data points produced, this just about covers our needs. Of course there are a few outstanding TODO items. In particular, computing nearest neighbors is a crucial step, and that can&amp;rsquo;t be done directly on non-numeric data. As a quick workaround, we mapped categorical data to integers (with a loosely meaningful ordering when possible), and then used a standard KNN algorithm to compute neighbors. I can imagine a sort of k-d tree variant that understands categorical axes, with a custom distance metric (say, an inequality test). This would simplify the process, but it may require an unreasonable effort. Another idea is to generate synthetic data points based on a combination of more than just one neighbor, but it&amp;rsquo;s not clear how beneficial this would be.&lt;/p&gt;
&lt;p&gt;Despite being a quick prototype, this is all pretty fast. For a base dataset of about about 41,000 records, with 15 fields of various types, we can generate just over one million synthetic data points (25x oversampling) in about 23 seconds. Generating ten million points takes about 430 seconds. Finding nearest neighbors takes eight seconds, and the synthesis time &lt;em&gt;should&lt;/em&gt; scale linearly with the output size. This is in python/numpy, so there is lots of room for improvement. We will likely rewrite this in Go, the next time we need a billion synthetic data points.&lt;/p&gt;
&lt;p&gt;One last note: despite a perhaps-unreasonable focus on the quality of test data, there are no guarantees regarding the statistical validity of this variant of SMOTE. I would not suggest using it for any sort of predictive modeling work without further study.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/alanbernstein/smote&#34;&gt;Try it out&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Banner image by Felix Mittermeier on Unsplash&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Building On a Strong Foundation</title>
          <link>https://www.pilosa.com/blog/building-on-a-strong-foundation/</link>
          <pubDate>Thu, 23 May 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/building-on-a-strong-foundation/</guid>
          <description>&lt;p&gt;In 2017, we &lt;a href=&#34;https://www.pilosa.com/blog/hello-world/&#34;&gt;open-sourced&lt;/a&gt; Pilosa with the goal of transforming the world of big data analytics using the power of bitmap indices and distributed computing. After two years of development, 38 releases, and tens of thousands of downloads, we couldn&amp;rsquo;t be more proud of the work we&amp;rsquo;ve done.&lt;/p&gt;
&lt;p&gt;Over that time, we&amp;rsquo;ve learned a few lessons. First, even as Pilosa is &lt;a href=&#34;https://www.pilosa.com/docs/getting-started/&#34;&gt;easy to get started with&lt;/a&gt;, our users are busy professionals and are looking for a more turn-key solution that smoothly integrates with a variety of data sources. Second, some of our users have come up with crazy and innovative ways to operate directly on Pilosa&amp;rsquo;s compressed bitmaps in-situ—unfortunately, without a common interface to this data, their solutions become expensive one-offs that are difficult to develop and maintain. We knew that we needed to expose the ability to load new algorithms dynamically which could operate directly on Pilosa&amp;rsquo;s data plane.&lt;/p&gt;
&lt;p&gt;Today, we are launching &lt;a href=&#34;https://www.molecula.com/&#34;&gt;Molecula&lt;/a&gt;, a Data Virtualization platform built around Pilosa. Molecula is not just a new brand. It&amp;rsquo;s a new identity for us, and a suite of products that furthers our original mission, making data instantly accessible to both humans and machines.&lt;/p&gt;
&lt;p&gt;We are beyond excited for what we&amp;rsquo;ll do with Molecula, but we aren&amp;rsquo;t done with Pilosa. We are as committed as ever to maintaining and improving Pilosa, with many new features in active development, including new data types, better memory management, new query language features, and an algorithm extension framework. The open source Pilosa will be the foundation on which we build Molecula. Please have a look at our &lt;a href=&#34;https://www.molecula.com/&#34;&gt;new website&lt;/a&gt;!&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Writing a Custom Handler for Oracle GoldenGate</title>
          <link>https://www.pilosa.com/blog/writing-a-custom-handler-for-goldengate/</link>
          <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/writing-a-custom-handler-for-goldengate/</guid>
          <description>&lt;p&gt;In this post, we will cover creating a custom handler for Oracle GoldenGate which updates the data in a Pilosa server.&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.oracle.com/middleware/technologies/goldengate.html&#34;&gt;Oracle GoldenGate&lt;/a&gt; captures and delivers real-time change data from a compatible database to other databases, data warehouses and applications. The change data is directly read from database logs, having minimal impact on the database itself.&lt;/p&gt;
&lt;p&gt;GoldenGate has three primary components:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Capture: &lt;em&gt;Extract groups&lt;/em&gt; retrieve change information from database logs and write it to &lt;em&gt;trail files&lt;/em&gt;. Since GoldenGate uses the transaction logs from databases, capturing changes has a low impact on the source system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Trail files: A trail file contains changes in a database, such as inserts, updates and deletes in a platfrom independent data format. The changes are ordered by commit time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delivery: The trail is sent over the network from the source system to the target and written in a remote trail. A replication group applies the changes to the target system. The extract group which reads the local trail and sends the changes is called a &lt;em&gt;pump&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the simplest case, GoldenGate can be used for unidirectional replication from a source to a target. GoldenGate also supports bidirectional and multi-master replication where there may be more than one writer to a database table.&lt;/p&gt;
&lt;p&gt;It is possible to extend Oracle GoldenGate&amp;rsquo;s functionality with custom handlers. We are going to use that feature to deliver and map real-time updates from an Oracle database to a Pilosa server using Pilosa Java client library.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.pilosa.com&#34;&gt;Pilosa&lt;/a&gt; is an open source distributed index which enables updating and querying massive data sets in real-time. See the &lt;a href=&#34;https://www.pilosa.com/pdf/PILOSA%20-%20Technical%20White%20Paper.pdf&#34;&gt;Pilosa whitepaper (PDF)&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;Using GoldenGate with Pilosa has the following benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pilosa is distributed and fast. It may be used for a lot of the tasks a database is used for, offloading the tasks to Pilosa and freeing up database resources.&lt;/li&gt;
&lt;li&gt;Using GoldenGate, updates from a database to the Pilosa server can be delivered in a low impact way. GoldenGate extracts changes in the database from logs instead of running queries.&lt;/li&gt;
&lt;li&gt;The data in the database is replicated to a Pilosa server in real-time, making the data in the Pilosa side always up-to-date.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;getting-ready&#34;&gt;Getting Ready&lt;/h3&gt;
&lt;p&gt;Requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux or MacOS, Bash or compatible shell&lt;/li&gt;
&lt;li&gt;Docker 17.05 or better&lt;/li&gt;
&lt;li&gt;Docker Compose&lt;/li&gt;
&lt;li&gt;git&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;creating-docker-images&#34;&gt;Creating Docker Images&lt;/h4&gt;
&lt;p&gt;Oracle doesn&amp;rsquo;t provide Docker images for their products, but they allow downloading them for evaluation purposes. They supply scripts for creating Docker images from downloaded products.&lt;/p&gt;
&lt;p&gt;Clone Oracle Docker Images repository, which contains the necessary scripts to create Docker images for Oracle products:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/oracle/docker-images.git
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Switch to the &lt;code&gt;docker-images&lt;/code&gt; directory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd docker-images
&lt;/code&gt;&lt;/pre&gt;&lt;h5 id=&#34;creating-the-oracle-database-image&#34;&gt;Creating the Oracle Database Image&lt;/h5&gt;
&lt;p&gt;Create the Oracle Database 12c image (&lt;code&gt;oracle/database:12.2.0.1-ee&lt;/code&gt;) using the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Switch to &lt;code&gt;OracleDatabase/SingleInstance/dockerfiles&lt;/code&gt; directory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd OracleDatabase/SingleInstance/dockerfiles
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download Oracle Database 12c Release 2 archive (linuxx64_12201_database.zip) from &lt;a href=&#34;https://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html&#34;&gt;https://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html&lt;/a&gt; and copy it to &lt;code&gt;12.2.0.1&lt;/code&gt; directory/&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the image creation script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./buildDockerImage.sh -v 12.2.0.1 -e -i
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;creating-oracle-goldengate-images&#34;&gt;Creating Oracle GoldenGate Images&lt;/h5&gt;
&lt;p&gt;We need to create two Oracle GoldenGate images:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Oracle GoldenGate 18 for the &lt;code&gt;extract&lt;/code&gt; container.&lt;/li&gt;
&lt;li&gt;Oracle GoldenGate for BigData image for the &lt;code&gt;replicat&lt;/code&gt; container.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, switch to &lt;code&gt;OracleGoldenGate&lt;/code&gt; directory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd ../../../OracleGoldenGate
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Make sure that &lt;code&gt;strings&lt;/code&gt;, &lt;code&gt;unzip&lt;/code&gt; and GNU &lt;code&gt;tar&lt;/code&gt; utilities are installed in your system. These are required by Oracle&amp;rsquo;s GoldenGate Docker image creation script. On Linux, GNU &lt;code&gt;tar&lt;/code&gt; should be already installed, but on MacOS follow the steps below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download the patch:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl -O https://raw.githubusercontent.com/pilosa/sample-ogg-handler/master/macos/dockerBuild.sh.patch
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Apply the patch:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ patch &amp;lt; dockerBuild.sh.patch
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Create the Oracle GoldenGate 18 image using the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download Oracle GoldenGate 18.1.0.0.0 for Oracle on Linux x86-64 (&lt;code&gt;181000_fbo_ggs_Linux_x64_shiphome.zip&lt;/code&gt;) from &lt;a href=&#34;https://www.oracle.com/technetwork/middleware/goldengate/downloads/index.html&#34;&gt;https://www.oracle.com/technetwork/middleware/goldengate/downloads/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the image creation script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ BASE_IMAGE=oracle/database:12.2.0.1-ee ./dockerBuild.sh 181000_fbo_ggs_Linux_x64_shiphome.zip --build-arg BASE_COMMAND=&amp;quot;su -c &#39;/opt/oracle/runOracle.sh&#39; oracle&amp;quot; --tag oracle/db-12.2-goldengate-standard:18.1.0.0.0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Create the GoldenGate for BigData image using the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download Oracle GoldenGate for Big Data 12.3.2.1.1 on Linux x86-64 (&lt;code&gt;OGG_BigData_Linux_x64_12.3.2.1.1.zip&lt;/code&gt;) from &lt;a href=&#34;https://www.oracle.com/technetwork/middleware/goldengate/downloads/index.html&#34;&gt;https://www.oracle.com/technetwork/middleware/goldengate/downloads/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the image creation script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;BASE_IMAGE=&amp;quot;oraclelinux:7-slim&amp;quot; ./dockerBuild.sh OGG_BigData_Linux_x64_12.3.2.1.1.zip --tag oracle/goldengate-standard-bigdata:12.3.0.1.2
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;patching-the-oracle-database-image&#34;&gt;Patching the Oracle Database Image&lt;/h5&gt;
&lt;p&gt;After completing the &lt;em&gt;Creating the Oracle GoldenGate Image&lt;/em&gt; section above, we should end up with the &lt;code&gt;oracle/db-12.2-goldengate-standard:18.1.0.0.0&lt;/code&gt; image. The &lt;code&gt;root&lt;/code&gt; user in the created image doesn&amp;rsquo;t have the correct &lt;a href=&#34;http://www.linux-pam.org&#34;&gt;PAM&lt;/a&gt; so we need to add them. The simplest way of doing it is creating another Docker image based on the image we have created.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone &lt;a href=&#34;https://github.com/pilosa/sample-ogg-handler&#34;&gt;https://github.com/pilosa/sample-ogg-handler&lt;/a&gt; to somewhere in your system.&lt;/li&gt;
&lt;li&gt;Switch to the &lt;code&gt;sample-ogg-handler/docker&lt;/code&gt; directory.&lt;/li&gt;
&lt;li&gt;Run the following to create the patched image:
&lt;pre&gt;&lt;code&gt;$ docker build -t oracle/db-12.2-goldengate-standard:18.1.0.0.0-patched .
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;running-the-setup&#34;&gt;Running the Setup&lt;/h3&gt;
&lt;p&gt;The sample setup is composed of an Oracle database container, the replication container which also contains the custom adapter, and a Pilosa container.&lt;/p&gt;
&lt;p&gt;We have already cloned the sample project in the &lt;em&gt;Patching the Oracle Database Image&lt;/em&gt; section. The sample project includes a Docker compose file. Let&amp;rsquo;s run it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker-compose up
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This takes a while.&lt;/p&gt;
&lt;p&gt;Before carrying on with enabling GoldenGate support, we have to modify the &lt;code&gt;tnsnames.ora&lt;/code&gt; file which contains database service names mapped to listener protocol addresses. The default installed one doesn&amp;rsquo;t seem to be in the correct format:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker exec -it sampleogghandler_extract_1 cp /prv/tnsnames.ora /opt/oracle/oradata/dbconfig/ORCLCDB/tnsnames.ora
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Make sure running the following commands end with &lt;code&gt;OK&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;docker exec -it sampleogghandler_extract_1 tnsping ORCLCDB&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker exec -it sampleogghandler_extract_1 tnsping ORCLPDB1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;enabling-goldengate-support-on-an-oracle-database&#34;&gt;Enabling GoldenGate Support on an Oracle Database&lt;/h4&gt;
&lt;p&gt;The support for GoldenGate is not enabled on Oracle databases by default. Follow the steps below to enable it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Start a shell on the extract container with the &lt;code&gt;oracle&lt;/code&gt; user:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker exec -it sampleogghandler_extract_1 su oracle
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prepare the root database.&lt;/p&gt;
&lt;p&gt;Login to the root database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sqlplus / as SYSDBA
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Turn on the archive log:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SHUTDOWN IMMEDIATE;
STARTUP MOUNT EXCLUSIVE;
ALTER DATABASE ARCHIVELOG;
ALTER DATABASE OPEN;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This may take a while.&lt;/p&gt;
&lt;p&gt;Create the extract user. The user must be added to the root database when the integrated mode is used:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE USER c##ggadmin IDENTIFIED BY w
DEFAULT TABLESPACE users
TEMPORARY TABLESPACE temp;
GRANT DBA TO c##ggadmin container=all;
EXEC dbms_goldengate_auth.grant_admin_privilege(&#39;c##ggadmin&#39;,container=&amp;gt;&#39;all&#39;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check whether GoldenGate replication was enabled on this database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SHOW PARAMETER ENABLE_GOLDENGATE_REPLICATION;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If it is not already enabled, enable it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER SYSTEM SET ENABLE_GOLDENGATE_REPLICATION=true SCOPE=both;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Chech whether supplemental logging is enabled:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT SUPPLEMENTAL_LOG_DATA_MIN, FORCE_LOGGING FROM v$database;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If it is not already enabled, enable it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER DATABASE ADD SUPPLEMENTAL LOG DATA;
ALTER DATABASE FORCE LOGGING;
ALTER SYSTEM SWITCH LOGFILE;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Exit &lt;code&gt;sqlplus&lt;/code&gt; using &lt;code&gt;Ctrl+D&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next, let&amp;rsquo;s prepare the pluggable database:&lt;/p&gt;
&lt;p&gt;Login to the pluggable database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sqlplus SYS/w@ORCLPDB1 as SYSDBA
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create the schema:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE USER ogguser IDENTIFIED BY w;
GRANT CONNECT, RESOURCE, UNLIMITED TABLESPACE, CREATE VIEW TO ogguser;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Exit &lt;code&gt;sqlplus&lt;/code&gt; using &lt;code&gt;Ctrl+D&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create demo tables:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo EXIT | sqlplus ogguser@ORCLPDB1/w @$ORACLE_HOME/demo/schema/human_resources/hr_cre.sql
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the GoldenGate credentials store and add the user for extract:&lt;/p&gt;
&lt;p&gt;Start GoldenGate console:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ggsci
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Add a credential store and store the root database user credentials:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ADD CREDENTIALSTORE
ALTER CREDENTIALSTORE ADD USER c##ggadmin@ORCLCDB PASSWORD w ALIAS c##ggadmin
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Enable schema-level supplemental logging for the database tables:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DBLOGIN USERIDALIAS c##ggadmin
ADD SCHEMATRANDATA ORCLPDB1.ogguser
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;setting-up-extract-and-pump-groups&#34;&gt;Setting Up Extract and Pump Groups&lt;/h4&gt;
&lt;p&gt;While still in the GoldenGate console, follow these steps to create and start extract and pump groups.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The extract group is used to obtain the changes from the database log and save it to the trail file. Let&amp;rsquo;s add it.&lt;/p&gt;
&lt;p&gt;Check the contents of the extract group:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;VIEW PARAM ext
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;EXTRACT ext
SETENV (ORACLE_SID = ORCLCDB)
USERIDALIAS c##ggadmin
EXTTRAIL ./dirdat/et
GETUPDATEBEFORES
UPDATERECORDFORMAT COMPACT

SOURCECATALOG ORCLPDB1
TABLE ogguser.*;
SEQUENCE ogguser.*;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Add the extract group. We limit each trail file to be at most 5 megabytes; that&amp;rsquo;s adequate for the sample project.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ADD EXTRACT ext, INTEGRATED TRANLOG, BEGIN NOW
ADD EXTTRAIL ./dirdat/et, EXTRACT ext, MEGABYTES 5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Register the extract group with the pluggable database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;REGISTER EXTRACT ext DATABASE CONTAINER (ORCLPDB1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This may take a while to complete.&lt;/p&gt;
&lt;p&gt;Check that extract group is present:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO EXTRACT ext
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Should output something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;EXTRACT    EXT       Initialized   2019-02-07 14:29   Status STOPPED
Checkpoint Lag       00:00:00 (updated 00:01:20 ago)
Log Read Checkpoint  Oracle Integrated Redo Logs
                    2019-02-07 14:29:08
                    SCN 0.0 (0)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The pump group is used to send the local trail to a remote location over the network, in our case the &lt;code&gt;replicat&lt;/code&gt; container.&lt;/p&gt;
&lt;p&gt;Check the contents of the pump group:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;VIEW PARAM pump
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;EXTRACT pump
RMTHOST replicat, MGRPORT 7809, COMPRESS
RMTTRAIL ./dirdat/pm
PASSTHRU

SOURCECATALOG ORCLPDB1
TABLE ogguser.*;
SEQUENCE ogguser.*;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Using our Docker compose setup, the replicat container is accessible with the host name &lt;code&gt;replicat&lt;/code&gt;. We set the trail format to &lt;code&gt;12.1&lt;/code&gt; for the pump too.&lt;/p&gt;
&lt;p&gt;Add the pump group.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ADD EXTRACT pump, EXTTRAILSOURCE ./dirdat/et
ADD RMTTRAIL ./dirdat/pm, EXTRACT pump, MEGABYTES 5
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the extract and pump groups:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;START EXTRACT EXT
START EXTRACT PUMP
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check that the extract groups are running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO ALL
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Should output something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
EXTRACT     RUNNING     EXT         00:32:27      00:00:04
EXTRACT     RUNNING     PUMP        00:00:00      00:00:08
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If any of the items in that list has &lt;code&gt;STOPPED&lt;/code&gt; or &lt;code&gt;ABENDED&lt;/code&gt; status, check the logs for errors using &lt;code&gt;VIEW REPORT GROUP_NAME&lt;/code&gt;, e.g., for &lt;code&gt;ext&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;VIEW REPORT ext
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;setting-up-the-pilosa-handler-project&#34;&gt;Setting Up the Pilosa Handler Project&lt;/h4&gt;
&lt;p&gt;We are going to take a detour to set up the custom handler project here.&lt;/p&gt;
&lt;p&gt;Requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JDK 1.8&lt;/li&gt;
&lt;li&gt;Maven 3.6 or better&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A sample Pilosa handler for GoldenGate is included in the &lt;code&gt;handler&lt;/code&gt; directory in &lt;code&gt;sample-ogg-handler&lt;/code&gt; that we cloned earlier.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;You have already downloaded &lt;code&gt;OGG_BigData_Linux_x64_12.3.2.1.1.zip&lt;/code&gt; before. Extract &lt;code&gt;OGG_BigData_Linux_x64_12.3.2.1.1.tar&lt;/code&gt; from &lt;code&gt;OGG_BigData_Linux_x64_12.3.2.1.1.zip&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Extract &lt;code&gt;ggjava&lt;/code&gt; directory from &lt;code&gt;OGG_BigData_Linux_x64_12.3.2.1.1.tar&lt;/code&gt; and copy it to the &lt;code&gt;sample-ogg-handler/handler/local&lt;/code&gt; directory, so &lt;code&gt;sample-ogg-handler/handler/local/ggjava&lt;/code&gt; directory contains the GoldenGate libraries.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In a shell, register the libraries for the GoldenGate Java Adapter. This has to be done only once:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make install-libs
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In order to build the project, run &lt;code&gt;make&lt;/code&gt;. If there are no errors, you should end up with &lt;code&gt;target/sample-ogg-handler-0.1.0-all.jar&lt;/code&gt;. This file contains everything needed to run the handler.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Copy &lt;code&gt;sample-ogg-handler/handler/target/sample-ogg-handler-0.1.0-all.jar&lt;/code&gt; to the &lt;code&gt;sample-ogg-handler/v_dirprm/handler&lt;/code&gt; directory. We  will need to do that any time we modify the handler.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can open the GoldenGate handler project in the &lt;code&gt;sample-ogg-handler/handler&lt;/code&gt; directory with your favorite IDE/editor and check the contents of &lt;code&gt;src/main/java/sample/PilosaHandler.java&lt;/code&gt;. This is the source file that contains all the logic for the handler.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;setting-up-replication&#34;&gt;Setting Up Replication&lt;/h4&gt;
&lt;p&gt;Our custom handler will run in the replicat container and react to the changes to the trail file. The trail file is updated using the data sent by the pump in the extract container.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Run a shell in the replicat container using the &lt;code&gt;oracle&lt;/code&gt; user:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker exec -it sampleogghandler_replicat_1 su oracle
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check that properties for the custom handler are correct:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat dirprm/pilosa.properties
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Should output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gg.log = log4j
gg.log.level = info
gg.classpath = dirprm/handler/sample-ogg-handler-0.1.0-all.jar
gg.handlerlist = pilosa

gg.handler.pilosa.type = sample.PilosaHandler
gg.handler.pilosa.address = pilosa:10101
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The properties file contains settings for the custom handler. Most of the entries in the properties file should be self-explanatory. The most import entries are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gg.classpath&lt;/code&gt; should contain the class path for the handler. You can specify a comma delimited list of directories and jar files.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gg.handlerlist&lt;/code&gt; should contain a comma delimited list of handler names. You can choose any name you would like, but it should match the entries for other settings for the handler.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gg.handler.HANDLER_NAME.type&lt;/code&gt; should contain the complete name of the handler, including the package name.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gg.handler.HANDLER_NAME.address&lt;/code&gt; is a setting directly passed to &lt;code&gt;setAddress&lt;/code&gt; method of &lt;code&gt;sample.PilosaHandler&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The name of the properties file is the same as the extract group we will be adding next, so it is found automatically.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Replicat groups process a trail file and apply the changes to a database, or execute a handler in our case.&lt;/p&gt;
&lt;p&gt;Run the GoldenGate console:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ggsci
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The replicat params are in &lt;code&gt;dirprm/pilosa.prm&lt;/code&gt;. Verify that it&amp;rsquo;s there:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;VIEW PARAM pilosa
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Should output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;REPLICAT pilosa
TARGETDB LIBFILE libggjava.so
REPORTCOUNT EVERY 1 MINUTES, RATE
GROUPTRANSOPS 1000
MAP ORCLPDB1.ogguser.*, TARGET ogguser.*;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Add the replicat group:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ADD REPLICAT pilosa, EXTTRAIL ./dirdat/pm, NODBCHECKPOINT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check that the extract group was created:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO ALL
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Should output something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
REPLICAT    STOPPED     PILOSA      00:00:00      00:00:01
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Start the replicat group:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;START REPLICAT pilosa
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check that the extract group is running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INFO ALL
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Should output something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Program     Status      Group       Lag at Chkpt  Time Since Chkpt

MANAGER     RUNNING
REPLICAT    RUNNING     PILOSA      00:00:00      00:00:05
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If the group has &lt;code&gt;STOPPED&lt;/code&gt; or &lt;code&gt;ABENDED&lt;/code&gt; status, check the logs for errors using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;VIEW REPORT pilosa
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;View the custom handler logs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;VIEW REPORT pilosa
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The replicat container log is located at: &lt;code&gt;dirrpt/PILOSA_info_log4j.log&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;insert-data-to-the-source-database&#34;&gt;Insert Data to the Source Database&lt;/h4&gt;
&lt;p&gt;Start a shell on the Pilosa container with &lt;code&gt;oracle&lt;/code&gt; user:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker exec -it sampleogghandler_extract_1 su oracle
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Insert sample records into the source database:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo EXIT | sqlplus ogguser@ORCLPDB1/w @$ORACLE_HOME/demo/schema/human_resources/hr_popul.sql
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;check-the-data-on-the-pilosa-side&#34;&gt;Check the Data on the Pilosa Side&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s confirm the data on the Pilosa side was updated when we inserted some records to the source database.&lt;/p&gt;
&lt;p&gt;Start a shell on the Pilosa container:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker exec -it sampleogghandler_pilosa_1 sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s find out what are the top 5 jobs and the number of employees having those jobs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl pilosa:10101/index/employees/query -d &#39;TopN(job, Row(ok=true), n=5)&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Turns out there are 30 sales representatives, 20 shipping clerks, etc.:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;results&amp;quot;:[[{&amp;quot;id&amp;quot;:0,&amp;quot;key&amp;quot;:&amp;quot;SA_REP&amp;quot;,&amp;quot;count&amp;quot;:30},{&amp;quot;id&amp;quot;:0,&amp;quot;key&amp;quot;:&amp;quot;SH_CLERK&amp;quot;,&amp;quot;count&amp;quot;:20},{&amp;quot;id&amp;quot;:0,&amp;quot;key&amp;quot;:&amp;quot;ST_CLERK&amp;quot;,&amp;quot;count&amp;quot;:20},{&amp;quot;id&amp;quot;:0,&amp;quot;key&amp;quot;:&amp;quot;FI_ACCOUNT&amp;quot;,&amp;quot;count&amp;quot;:5},{&amp;quot;id&amp;quot;:0,&amp;quot;key&amp;quot;:&amp;quot;SA_MAN&amp;quot;,&amp;quot;count&amp;quot;:5}]]}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Which sales representatives earn $10000 or more and what do we know about them?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl pilosa:10101/index/employees/query -d &#39;Options(Intersect(Row(ok=true), Row(salary &amp;gt;= 10000), Row(job=&amp;quot;SA_REP&amp;quot;)), columnAttrs=true)&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;results&amp;quot;:[{&amp;quot;attrs&amp;quot;:{},&amp;quot;columns&amp;quot;:[150,156,162,168,169,174]}],&amp;quot;columnAttrs&amp;quot;:[{&amp;quot;id&amp;quot;:150,&amp;quot;attrs&amp;quot;:{&amp;quot;email&amp;quot;:&amp;quot;PTUCKER&amp;quot;}},{&amp;quot;id&amp;quot;:156,&amp;quot;attrs&amp;quot;:{&amp;quot;email&amp;quot;:&amp;quot;JKING&amp;quot;}},{&amp;quot;id&amp;quot;:162,&amp;quot;attrs&amp;quot;:{&amp;quot;email&amp;quot;:&amp;quot;CVISHNEY&amp;quot;}},{&amp;quot;id&amp;quot;:168,&amp;quot;attrs&amp;quot;:{&amp;quot;email&amp;quot;:&amp;quot;LOZER&amp;quot;}},{&amp;quot;id&amp;quot;:169,&amp;quot;attrs&amp;quot;:{&amp;quot;email&amp;quot;:&amp;quot;HBLOOM&amp;quot;}},{&amp;quot;id&amp;quot;:174,&amp;quot;attrs&amp;quot;:{&amp;quot;email&amp;quot;:&amp;quot;EABEL&amp;quot;}}]}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s delete one of the employees from the source table to confirm that the corresponding column is marked non-existent.&lt;/p&gt;
&lt;p&gt;Open &lt;code&gt;sqlplus&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker exec -it sampleogghandler_extract_1 su oracle -c &#39;sqlplus ogguser@ORCLPDB1/w&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Delete the employee with ID 150, who is a sales representative:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DELETE FROM ogguser.employees WHERE employee_id=150;
COMMIT;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;How many sales representatives left?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; # curl pilosa:10101/index/employees/query -d &#39;Count(Intersect(Row(ok=true), Row(job=&amp;quot;SA_REP&amp;quot;)))&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;results&amp;quot;:[29]}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check out our &lt;a href=&#34;https://www.pilosa.com/docs/latest/query-language/&#34;&gt;documentation&lt;/a&gt; for PQL, the query language of Pilosa, for more.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;In this article we explored how to write a custom handler for Oracle GoldenGate, specifically a Pilosa handler. GoldenGate custom handlers enable acting on trail files in an efficient and fast way.&lt;/p&gt;
&lt;p&gt;We are developing a Pilosa adapter for Oracle GoldenGate, which provides a Javascript based API for programming the translation logic. It is still in early phase of development, but &lt;a href=&#34;https://www.pilosa.com/about/#contact&#34;&gt;let us know&lt;/a&gt; if you are interested in integrating Pilosa in your workflow or providing feedback.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Yüce is an Independent Software Engineer at Pilosa. When he&amp;rsquo;s not writing Pilosa client libraries, you can find him watching good bad movies. He is &lt;a href=&#34;https://github.com/yuce&#34;&gt;@yuce&lt;/a&gt; on GitHub and &lt;a href=&#34;https://twitter.com/tklx&#34;&gt;@tklx&lt;/a&gt; on Twitter.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>I Hope You Like Charts: Benchmarks On 4 Clouds</title>
          <link>https://www.pilosa.com/blog/cloud-bench-redux/</link>
          <pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/cloud-bench-redux/</guid>
          <description>&lt;p&gt;&lt;em&gt;This is a follow-on post to &lt;a href=&#34;../why-oci&#34;&gt;multi-cloud benchmarks.&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Previously, we ran a number of &lt;a href=&#34;https://github.com/pilosa/pilosa&#34;&gt;Pilosa&lt;/a&gt;
specific benchmarks across a variety of configurations of hosts on AWS, Azure,
and Oracle cloud. Our broad strokes conclusions were that AWS was the fastest,
Oracle was the most cost effective, and that while not far behind, Azure didn&amp;rsquo;t
stand out - if you work on Azure (or any other cloud incidentally) and want to
dig into this, we&amp;rsquo;d &lt;em&gt;love&lt;/em&gt; to.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve got a few exciting updates in this second edition:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We&amp;rsquo;ve added GCP to the mix!&lt;/li&gt;
&lt;li&gt;After getting some feedback from the OCI team, we changed the OS image that
we&amp;rsquo;re using which provided a pretty good boost in some benchmarks and solved
the mystery of performance differences between the &lt;code&gt;VM.Standard2.16&lt;/code&gt; and the
&lt;code&gt;BM.Standard2.52&lt;/code&gt; instances.&lt;/li&gt;
&lt;li&gt;We re-ran the AWS &lt;code&gt;c5.9xlarge&lt;/code&gt; benchmarks on Amazon Linux to be equitable
with the Oracle benchmarks.&lt;/li&gt;
&lt;li&gt;We ran some low level memory bandwidth benchmarks.&lt;/li&gt;
&lt;li&gt;We&amp;rsquo;ve updated our
&lt;a href=&#34;https://github.com/pilosa/infrastructure/tree/master/terraform/examples&#34;&gt;tooling&lt;/a&gt;
to make it significantly easier to add new configurations to our existing
results on &lt;a href=&#34;https://data.world/jaffee/benchmarks&#34;&gt;data.world&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;So, if you&amp;rsquo;ll recall, we had a suite of queries that we ran against Pilosa
clusters configured in each cloud, as well as a set of microbenchmarks that just
ran on one instance of each cluster.&lt;/p&gt;
&lt;p&gt;So, without further ado, here is the full set of configurations that we&amp;rsquo;ve
benchmarked against. These are the aggregate numbers across each &lt;em&gt;cluster&lt;/em&gt;, not
for a single instance of the given type.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Cloud&lt;/th&gt;
&lt;th&gt;Instance Type&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Num&lt;/th&gt;
&lt;th&gt;OS&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Cost/ Hr&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;CPUs&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Mem (GB)&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;NVME SSDs&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;VM.Standard2.16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Oracle Linux&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.06&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;720&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;VM.Standard2.16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.06&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;720&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GCP&lt;/td&gt;
&lt;td&gt;custom-36-73728-discounted&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.18&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;108&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;216&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;BM.Standard2.52&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;td&gt;Oracle Linux&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.32&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;104&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;BM.Standard2.52&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3.32&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;104&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;Standard_F32s_v2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.05&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;192&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GCP&lt;/td&gt;
&lt;td&gt;custom-36-73728&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.54&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;108&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;216&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c5.9xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.59&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;108&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;216&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c5.9xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Amazon Linux&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.59&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;108&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;216&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;Standard_F16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;6&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4.80&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;192&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;BM.HPC2.36&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;Oracle Linux&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;5.40&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;144&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;BM.HPC2.36&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;5.40&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;144&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;VM.DenseIO2.16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;6.12&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;720&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;r5d.12xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;6.91&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;r5d.12xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;Amazon Linux&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;6.91&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;Standard_E64s_v3&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;7.26&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;128&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;864&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;CPUs&amp;rdquo; here is the number of logical cores as reported by &lt;code&gt;/proc/cpuinfo&lt;/code&gt; - usually that means hyperthreads, though for Azure&amp;rsquo;s F16, it does mean physical cores.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There are a few nuances to note here. Oracle and Amazon provide custom linux
distributions (both based on CentOS), and we&amp;rsquo;ve run some of the configurations
on both Ubuntu and CentOS. Azure and GCP didn&amp;rsquo;t seem to have hand curated Linux
derivatives and they did have official Ubuntu images, so we used those.&lt;/p&gt;
&lt;p&gt;Now, Google does some interesting things with GCP: &lt;a href=&#34;https://cloud.google.com/compute/docs/machine-types#custom_machine_types&#34;&gt;custom instance types&lt;/a&gt;, and
&lt;a href=&#34;https://cloud.google.com/compute/docs/sustained-use-discounts#sud_custom&#34;&gt;sustained use discounts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We created a &lt;code&gt;custom-36-73728&lt;/code&gt; instance to be equivalent to AWS&amp;rsquo;s c5.9xlarge -
we&amp;rsquo;re even able to specify that we want Skylake class CPUs. Now, the base price
for this custom instance is about $1.51/hr which is almost exactly the same as
AWS&amp;rsquo;s c5.9xlarge at $1.53/hr. However, if we run the instance for more than 25%
of a month, we start getting discounted &lt;em&gt;automatically&lt;/em&gt;. Long story short, if we
keep the instance running for a month, the effective price is $1.06/hr — a 30%
discount! We look at both the full price and discounted price in our
cost/performance comparisons, the discounted price is associated with the
instance type called &lt;code&gt;custom-36-73728-discounted&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note that while all the providers have some form of &amp;ldquo;reserved&amp;rdquo; pricing where you
can commit in advance to a year or more of usage for a steep discount, Google is
the only one I&amp;rsquo;m aware of with any kind of totally automatic discounting.&lt;/p&gt;
&lt;h3 id=&#34;microbenchmarks&#34;&gt;Microbenchmarks&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s look first at IntersectionCount which is a simple, single-threaded benchmark with no I/O:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/benchmarkfragment-intersectioncount.png&#34; alt=&#34;IntersectionCount&#34;&gt;&lt;/p&gt;
&lt;p&gt;Immediately, we can see the Oracle Linux provided a big boost over Ubuntu for
the Oracle bare metal instances. &lt;code&gt;BM.HPC2.36&lt;/code&gt; has dethroned &lt;code&gt;c5.9xlarge&lt;/code&gt; as the
champion of CPU performance - this is pretty surprising as the AWS instance has
a faster processor on paper. Is virtualized vs bare metal the culprit? Or
perhaps differences in the memory subsytems give OCI the edge here.&lt;/p&gt;
&lt;p&gt;Now what about basic disk I/O?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/benchmarkfilewriterows100000.png&#34; alt=&#34;FileWrite&#34;&gt;&lt;/p&gt;
&lt;p&gt;Very interesting! The bare metal HPC instance using Oracle Linux with 1 SSD
outperforms the 2 SSD VM instances (running Ubuntu) both on Oracle and AWS. The
non-SSD Oracle and AWS instances also show marked improvement running their
respective official OS images instead of Ubuntu.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at the concurrent import benchmark which tests CPU, Memory, and I/O across multiple cores.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/benchmarkimportroaringconcurrent50rows16concurrency.png&#34; alt=&#34;Import16Conc50Rows&#34;&gt;&lt;/p&gt;
&lt;p&gt;So it seems like the AWS c5.9xlarge holds up a little bit better under these
mixed/concurrent conditions. There are quite a few variations on the concurrent
import in the raw results, and AWS does quite well in all of them. I suspect
that high EBS bandwidth and having multiple SSDs in the &lt;code&gt;r5d&lt;/code&gt; case has something
to do with this. Possible Oracle&amp;rsquo;s DenseIO2.16 would have fared a bit better if
we&amp;rsquo;d run it with Oracle Linux.&lt;/p&gt;
&lt;h3 id=&#34;cluster-benchmarks&#34;&gt;Cluster Benchmarks&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s look at raw performance for the queries - this time around, I&amp;rsquo;ve posted all of the charts for your perusal, and I&amp;rsquo;ll just provide some commentary on a few things:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/29-way-intersect.png&#34; alt=&#34;29WayIntersect&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/countintersectunionrowpickup-year2012-rowpickup-year2013-rowpickup-month3.png&#34; alt=&#34;3WayIntersect&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/groupbyrowsfieldcab-type-rowsfieldpickup-year-rowsfieldpassenger-count.png&#34; alt=&#34;GroupByCabTypeYearPass&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/groupbyrowsfieldcab-type-rowsfieldpickup-year-rowsfieldpickup-month.png&#34; alt=&#34;GroupByCabTypeYearMonth&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/groupbyrowsfieldpickup-year-rowsfieldpassenger-count-rowsfielddist-miles.png&#34; alt=&#34;GroupByYearPassDist&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/topncab-type.png&#34; alt=&#34;TopNCabType&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/topndist-miles-rowpickup-year2011.png&#34; alt=&#34;TopNFiltered&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/perf/topndist-miles.png&#34; alt=&#34;TopNDistMiles&#34;&gt;&lt;/p&gt;
&lt;p&gt;We see all 4 clouds making appearances in the top 3 of these query benchmarks
which have no disk I/O component. AWS wins 6 of 8, and Azure comes in first or
second in 6. Oracle has 4 top-3 appearances with 1 win, and GCP has 2 3rds and
some very close 4ths. To be fair, we&amp;rsquo;ve only tested one GCP configuration, so
they have fewer chances to win.&lt;/p&gt;
&lt;h3 id=&#34;cluster-costperformance&#34;&gt;Cluster Cost/Performance&lt;/h3&gt;
&lt;p&gt;And now the cost/performance in dollars per megaquery:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/dpmq/29-way-intersect.png&#34; alt=&#34;29WayIntersect&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/dpmq/countintersectunionrowpickup-year2012-rowpickup-year2013-rowpickup-month3.png&#34; alt=&#34;3WayIntersect&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/dpmq/groupbyrowsfieldcab-type-rowsfieldpickup-year-rowsfieldpassenger-count.png&#34; alt=&#34;GroupByCabTypeYearPass&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/dpmq/groupbyrowsfieldcab-type-rowsfieldpickup-year-rowsfieldpickup-month.png&#34; alt=&#34;GroupByCabTypeYearMonth&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/dpmq/groupbyrowsfieldpickup-year-rowsfieldpassenger-count-rowsfielddist-miles.png&#34; alt=&#34;GroupByYearPassDist&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/dpmq/topncab-type.png&#34; alt=&#34;TopNCabType&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/dpmq/topndist-miles-rowpickup-year2011.png&#34; alt=&#34;TopNFiltered&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/dpmq/topndist-miles.png&#34; alt=&#34;TopNDistMiles&#34;&gt;&lt;/p&gt;
&lt;p&gt;GCP shows its true colors! With that automatic discounting, Google&amp;rsquo;s cloud is
extremely cost effective when you&amp;rsquo;re running instances the majority of the time
for periods of 1 month or more.&lt;/p&gt;
&lt;p&gt;Another thing to note is the huge difference that Oracle Linux makes for the
&lt;code&gt;BM.HPC2.36&lt;/code&gt; instance type. In most cases it&amp;rsquo;s way ahead of the version running
Ubuntu. Except that one GroupBy query where the Ubuntu version gets third and
the Olinux version is way up in 10th. Weird.&lt;/p&gt;
&lt;h3 id=&#34;memory-bandwidth&#34;&gt;Memory Bandwidth&lt;/h3&gt;
&lt;p&gt;On OCI, the &lt;code&gt;VM.Standard2.16&lt;/code&gt; instance type runs on the &lt;code&gt;BM.Standard2.52&lt;/code&gt;
hardware. We&amp;rsquo;d previously been confused when Pilosa seemed to perform better
running in a 3-node cluster of &lt;code&gt;VM.Standard2.16&lt;/code&gt; than running on a single
&lt;code&gt;BM.Standard2.52&lt;/code&gt; which has slightly more horsepower both in CPU and Memory than
all 3 VMs combined. One theory was that the three VMs were allocated on
different physical hosts, and had access to more memory bandwidth in aggregate
than a single &lt;code&gt;BM.Standard2.52&lt;/code&gt;. To test this, we ran a large suite of memory
bandwidth benchmarks across several configurations using this really excellent
&lt;a href=&#34;https://zsmith.co/bandwidth.php&#34;&gt;benchmarking tool by Zack Smith&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We ran these with varying amounts of concurrency by running multiple instances
of the &lt;code&gt;bandwidth&lt;/code&gt; program in parallel and then summing each result as directed
by the documentation. However, there doesn&amp;rsquo;t seem to be any mechanism for
ensuring that the same tests are running simultaneously in each instance.
Looking at the output, they seem to stay mostly in sync, but one might take the
results at higher concurrency levels with a grain of salt. What follows are
charts of a small subset of the results - there are more on
&lt;a href=&#34;https://data.world/jaffee/benchmarks/workspace/query?queryid=57bd3780-e1ac-4dc7-acd7-c282243d9626&#34;&gt;data.world&lt;/a&gt;,
and way, way more if you run the entire suite yourself. (one run is 1500 tests,
and we ran them all on four different concurrency levels):&lt;/p&gt;
&lt;h4 id=&#34;random-1mb-reads-at-concurrency-1-16-36-52&#34;&gt;Random 1MB reads at concurrency 1, 16, 36, 52&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/bw/bwrandom-read-64-bit-size--1-mb-conc1.png&#34; alt=&#34;random-read-1-mb-conc1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/bw/bwrandom-read-64-bit-size--1-mb-conc16.png&#34; alt=&#34;random-read-1-mb-conc16&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/bw/bwrandom-read-64-bit-size--1-mb-conc36.png&#34; alt=&#34;random-read-1-mb-conc36&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/bw/bwrandom-read-64-bit-size--1-mb-conc52.png&#34; alt=&#34;random-read-1-mb-conc52&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can really watch the &lt;code&gt;BM.Standard2.52&lt;/code&gt; pull away from the &lt;code&gt;VM.Standard2.16&lt;/code&gt; at higher concurrencies.&lt;/p&gt;
&lt;h4 id=&#34;random-1mb-writes-at-concurrency-1-and-52&#34;&gt;Random 1MB writes at concurrency 1 and 52&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/bw/bwrandom-write-64-bit-size--1-mb-conc1.png&#34; alt=&#34;random-write-1-mb-conc1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/bw/bwrandom-write-64-bit-size--1-mb-conc52.png&#34; alt=&#34;random-write-1-mb-conc52&#34;&gt;&lt;/p&gt;
&lt;p&gt;1 MB writes follow the same pattern.&lt;/p&gt;
&lt;h4 id=&#34;sequential-1mb-reads-at-1-and-52&#34;&gt;Sequential 1MB reads at 1 and 52&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/bw/bwsequential-read-64-bit-size--1-mb-conc1.png&#34; alt=&#34;sequential-read-1-mb-conc1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cloud-bench-redux/bw/bwsequential-read-64-bit-size--1-mb-conc52.png&#34; alt=&#34;sequential-read-1-mb-conc52&#34;&gt;&lt;/p&gt;
&lt;p&gt;More of the same. There are &lt;em&gt;lots&lt;/em&gt; of other combinations, but the story is pretty similar all over.&lt;/p&gt;
&lt;h4 id=&#34;analysis&#34;&gt;Analysis&lt;/h4&gt;
&lt;p&gt;Essentially, it doesn&amp;rsquo;t appear that the performance difference between the
&lt;code&gt;VM.Standard2.16&lt;/code&gt; cluster and the &lt;code&gt;BM.Standard2.52&lt;/code&gt; machine are due to memory
bandwidth constraints. At high concurrency, we often see &lt;code&gt;BM.Standard2.52&lt;/code&gt;
having approximately triple the bandwidth of the &lt;code&gt;VM.Standard2.16&lt;/code&gt; system. So,
for now, this mystery remains unsolved - my next theory would be that something
in the Golang runtime (perhaps the scheduler) has some performance degredation
at high core counts and is more efficient on a machine with 32 logical cores
than one with 104. This is pure speculation, however.&lt;/p&gt;
&lt;h3 id=&#34;takeaways&#34;&gt;Takeaways&lt;/h3&gt;
&lt;p&gt;Using official Linux images helps pretty consistently on Oracle. The story is a
lot more mixed on Amazon. I would love to know what sort of specific tuning is
responsible for this, though I&amp;rsquo;m sure there are myriad kernel parameters that
one might tweak to get the most out of a specific hardware configuration in a
multi-tenant virtualized environment.&lt;/p&gt;
&lt;p&gt;Google&amp;rsquo;s automatic discounting is a significant advantage, though in my
estimation, Oracle still wins on overall cost effectiveness. The GCP instances
never overtake OCI by much in the $/MQ department, and the &lt;code&gt;VM.Standard2.16&lt;/code&gt;
instances have over 3x (!!) the memory.&lt;/p&gt;
&lt;p&gt;Amazon still takes the best overall raw performance though Azure and OCI do pop
up. Testing OCI&amp;rsquo;s DenseIO instances with Oracle Linux and figuring out how to
get NVME SSDs on Azure and GCP would likely make for more equitable all-around
comparison. It&amp;rsquo;s worth noting that even without NVME, the AWS instances on EBS
still do pretty well.&lt;/p&gt;
&lt;h3 id=&#34;future-work&#34;&gt;Future Work&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;d still like to do some more low level benchmarking (like the memory bandwidth
stuff) to get baseline performance of each aspect of each configuration&amp;rsquo;s
hardware.&lt;/p&gt;
&lt;p&gt;More importantly though, I think, I&amp;rsquo;d like to do more repeated runs on the same
configurations and see what kind of consistency we&amp;rsquo;re getting. Some of the
results presented here are difficult to explain, but repeated runs can yield
significant variation.&lt;/p&gt;
&lt;p&gt;Even without taking multi-tenancy into account, there are lots of factors that
contribute to inconsistency. The language runtime comes immediately to mind -
especially with garbage collection, but there are also OS tasks and other
user-level programs potentially taking resources and cluttering up the CPU
cache. Anything doing I/O is subject to the vagaries of external hardware, which
is only exacerbated in the case of network mounted storage.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Banner Photo by Victor Rodriguez on Unsplash&lt;/em&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>Oracle, AWS, and Azure Benchmarking Shootout</title>
          <link>https://www.pilosa.com/blog/why-oci/</link>
          <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/why-oci/</guid>
          <description>&lt;p&gt;&lt;em&gt;Psst - when you&amp;rsquo;re done with this, &lt;a href=&#34;../cloud-bench-redux&#34;&gt;check out part 2&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For those unfamiliar, Pilosa is an open source, distributed index which is
designed to help analyze huge datasets at &amp;ldquo;UI latency&amp;rdquo;. Basically we want all
queries to return in under a second regardless of complexity.&lt;/p&gt;
&lt;p&gt;This is a fairly tall order, and we&amp;rsquo;re in the midst of launching
&lt;a href=&#34;https://www.molecula.com&#34;&gt;Molecula&lt;/a&gt;, a managed service around Pilosa that makes
these kinds of low latency analytics a reality. We&amp;rsquo;re very interested in which
cloud providers—and which instance configurations on each provider—have the best
overall price/performance ratio.&lt;/p&gt;
&lt;p&gt;For this initial foray, we&amp;rsquo;ve run a massive suite of Pilosa-centric benchmarks
on 10 different configurations spread across Azure, AWS, and Oracle&amp;rsquo;s cloud (OCI).&lt;/p&gt;
&lt;p&gt;Now, when it comes to choosing a cloud provider, Oracle probably isn&amp;rsquo;t the first
company that comes to mind. I think most people would agree that the order is
something like:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;AWS&lt;/li&gt;
&lt;li&gt;Azure&lt;/li&gt;
&lt;li&gt;Google Cloud Platform&lt;/li&gt;
&lt;li&gt;Others&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We recently had the good fortune of being chosen to participate in the &lt;a href=&#34;https://www.oracle.com/startup/&#34;&gt;Oracle
Startup Accelerator&lt;/a&gt; program, and they&amp;rsquo;ve
strongly encouraged us to put OCI to the test.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;As we started to take it for a spin, we were pleasantly surprised by a number of things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It emulates AWS in a lot of ways, so it feels fairly familiar.&lt;/li&gt;
&lt;li&gt;It was built from the ground up to work with &lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt; which is muy bueno.&lt;/li&gt;
&lt;li&gt;The costs were quite competitive, especially considering the amount of memory and SSD available.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Check out this table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Cloud&lt;/th&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;n&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;$/hr&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;RAM&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;Threads&lt;/th&gt;
&lt;th&gt;Fast Disk/node&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;VM.Standard2.16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$3.06&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;720&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;VM.DenseIO2.16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$6.12&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;720&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td&gt;12.8 TB NVME&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;BM.Standard2.52&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$3.32&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;104&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;BM.HPC2.36&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$5.40&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;144&lt;/td&gt;
&lt;td&gt;6.7 TB NVME&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;F32s v2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$4.06&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;192&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td&gt;256 GB SSD&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;F16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;6&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$4.78&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;192&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td&gt;256 GB SSD&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;Standard_E64_v3&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$7.26&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;864&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;128&lt;/td&gt;
&lt;td&gt;864 GB SSD&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c4.8xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$4.77&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;180&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;108&lt;/td&gt;
&lt;td&gt;EBS only&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c5.9xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$4.59&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;216&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;108&lt;/td&gt;
&lt;td&gt;EBS only&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;r5d.12xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$6.91&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;768&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;96&lt;/td&gt;
&lt;td&gt;1.8 TB NVME&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In particular, a 2-node HPC2.36 cluster on OCI is comparable in price to a
3-node c5d.9xlarge on AWS, but has 5x the SSD space, significantly more
processors, and triple the memory.&lt;/p&gt;
&lt;p&gt;These basic numbers don&amp;rsquo;t tell the whole story of course - there are hundreds,
or even thousands of different hardware and software choices that a cloud
provider has to make when building their offering. Networking fabric, disk make
and model, processor type, motherboard, memory speed, network card, and
hypervisor just to name a few - not to mention the myriad configuration options,
any of which might have a drastic impact on performance. Some of these things
are published, or can be determined from inside of an instance, but many or even
most of them are intentionally abstracted away from the user. The only really
reliable way to see how different providers stack up is to run your workload on
them and measure the performance!&lt;/p&gt;
&lt;p&gt;Pilosa is a fairly interesting piece of software to benchmark as it works out a
few different areas of the hardware. During data ingest and startup, sequential
disk I/O is of critical importance. During most queries, Pilosa is heavily CPU
bound due to its almost unhealthy obsession with bitmap indexes. It&amp;rsquo;s also
written in Go and eats cores for breakfast - it will squeeze every inch of CPU
performance out of a machine. Pilosa holds its bitmap data in RAM, so memory
bandwidth is also a significant factor. Network throughput is probably the least
important aspect, though latency between hosts can make up a significant
percentage of query times for simpler queries.&lt;/p&gt;
&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;
&lt;p&gt;For our main Pilosa benchmarks, we decided to use the venerable &lt;a href=&#34;https://www.pilosa.com/blog/billion-taxi-ride-dataset-with-pilosa/&#34;&gt;Billion Taxi
Ride&lt;/a&gt;
dataset which is large enough to provide a realistic workload, without being
unwieldy.&lt;/p&gt;
&lt;p&gt;In order to aid repeatability and speed deployment, we produced a set of
parameterized &lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt; modules for each cloud
provider so that we could easily launch clusters with varying instance sizes.
Provisioning the machines was taken care of by a suite of
&lt;a href=&#34;https://www.ansible.com/&#34;&gt;Ansible&lt;/a&gt; playbooks. All of this is contained in the
&lt;code&gt;terraform&lt;/code&gt; and &lt;code&gt;ansible&lt;/code&gt; subdirectories of our
&lt;a href=&#34;https://github.com/pilosa/infrastructure&#34;&gt;infrastructure&lt;/a&gt; repository on Github.&lt;/p&gt;
&lt;p&gt;We ended up with the 10 different configurations listed above which contain a
mix of compute, memory, and storage optimized instances. Necessarily, there are
many configurations that we &lt;em&gt;didn&amp;rsquo;t&lt;/em&gt; run, but this selection should give us a
good sampling of the various CPU and storage options available on these clouds.
We would very much welcome any suggestions for additional configurations which
might be more performant or cost effective.&lt;/p&gt;
&lt;p&gt;After loading about 100GB (half) of the taxi data into each cluster, we ran 20
iterations of each of the following queries on each of our configurations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;TopN(distance, Row(pickup year=2011))&lt;/code&gt; - Number of rides for each integer distance (in miles) in the year 2011&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TopN(distance)&lt;/code&gt; - Number of rides for each integer distance in miles.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TopN(cab type)&lt;/code&gt; - Number of rides in each cab type (yellow or green)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GroupBy(year, passengers, distance)&lt;/code&gt; - Number of rides for every combination of year, number of passengers, and distance in miles&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GroupBy(cab type, year, month)&lt;/code&gt; - Number of rides for every combination of cab type, year, and month.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GroupBy(cab type, year, passengers)&lt;/code&gt; - Number of rides for every combination of cab type, year, and number of passengers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Count(Union(Row(year=2012), Row(year=2013), Row(month=March)))&lt;/code&gt; - Number of rides in 2012, 2013, or March of any year.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Count(Intersect(Row...)...)&lt;/code&gt; -  Number of rides matching a nested boolean combination of 29 values.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We also ran Pilosa&amp;rsquo;s extensive suite of micro-benchmarks which test some compute
and I/O related functions with fewer variables to consider.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;First, let&amp;rsquo;s take a look at raw performance and see which configuration was fastest for each query on average over the 20 iterations.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;cloud&lt;/th&gt;
&lt;th&gt;instance type&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;nodes&lt;/th&gt;
&lt;th&gt;query&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;r5d.12xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;TopN(distance, Row(pickup year=2011))&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c5.9xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;TopN(distance)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c5.9xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;TopN(cab type)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;BM.HPC2.36&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;GroupBy year, passengers, dist&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;r5d.12xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;Group By cab type, year, month&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;r5d.12xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;Group By cab type, year, passengers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c5.9xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Count Union of 3 rows&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;Standard_F32s_v2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Count Of intersection of unions involving 29 rows&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Wow! AWS is looking pretty good here, taking 6 of the 8 benchmarks evenly split
across their compute and memory optimized instances. Interestingly, the compute
optimized instances are winning at what are probably the 3 simplest queries
while the r5 instances are dominating some of the heavier queries. The OCI HPC
instances snuck in on one of the 3 field &amp;ldquo;Group By&amp;rdquo; queries, and Azure&amp;rsquo;s compute
optimized Standard_F32s won the long segmentation query.&lt;/p&gt;
&lt;p&gt;To get an idea of how much variation there is between the hardware types, this
is the relative performance of each configuration for one of the &amp;ldquo;Group By&amp;rdquo;
queries:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/why-oci/raw-query-perf-horizontal.png&#34; alt=&#34;RawGroupByPerf&#34;&gt;
&lt;em&gt;Group By Cab, Year, Passengers&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is a good start, but it has a few problems. Since the data set fits into
memory on all the configurations, any extra memory is effectively wasted. It
also doesn&amp;rsquo;t exercise disk performance at all, and most importantly, it doesn&amp;rsquo;t
take cost into account. This last is fairly easy to remedy; instead of looking
at the minimum average latency for each query, we can look at the minimum
average latency multipled by the cluster cost. With the right unit conversions,
this effectively gives us how much it would cost to run 1 Million of each given
query back to back on a particular configuration&amp;hellip; or as we like to call it,
&amp;ldquo;Dollars per Megaquery&amp;rdquo;. Let&amp;rsquo;s look at which configuration has the best $/MQ for
each of these benchmarks:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;cloud&lt;/th&gt;
&lt;th&gt;instance type&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;nodes&lt;/th&gt;
&lt;th&gt;query&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;$/MQ&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;VM.Standard2.16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;TopN(distance, Row(pickup year=2011))&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$8.08&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c5.9xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;TopN(distance)&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$13.17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AWS&lt;/td&gt;
&lt;td&gt;c5.9xlarge&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;TopN(cab type)&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$3.65&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;BM.HPC2.36&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;2&lt;/td&gt;
&lt;td&gt;GroupBy year, passengers, dist&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$281.12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;Standard F32s v2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Group By cab type, year, month&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$5.51&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Azure&lt;/td&gt;
&lt;td&gt;Standard F32s v2&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Group By cab type, year, passengers&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$8.13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;VM.Standard2.16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Count Union of 3 rows&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$3.59&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OCI&lt;/td&gt;
&lt;td&gt;VM.Standard2.16&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;3&lt;/td&gt;
&lt;td&gt;Count Of intersection of unions involving 29 rows&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;$141.75&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It appears that OCI&amp;rsquo;s VM.Standard2.16 is the king of cost effectiveness. This is
particularly interesting as these instances have 240 GB of memory to go with
their 32 hyperthreads whereas AWS&amp;rsquo;s c5.9xlarge (36 hyperthreads) and Azure&amp;rsquo;s
F32s have 72GB and 64GB respectively. So, although Oracle&amp;rsquo;s Standard2.16 VMs are
running on slower processors than the 3+ GHz Xeon Platinums that AWS and Azure
have, Oracle is able to offer them at a significantly lower price and with far
more memory.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/why-oci/filtered-topn-dpmq-horizontal.png&#34; alt=&#34;FilteredTopN&#34;&gt;
&lt;em&gt;Filtered TopN&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/why-oci/29seg-dpmq-horizontal.png&#34; alt=&#34;Segmentation&#34;&gt;
&lt;em&gt;29 Value Segmentation&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s also worth noting that Azure&amp;rsquo;s F32s machines performed best in cost
effectiveness on two pretty intensive queries, while AWS&amp;rsquo;s c5.9xlarges topped
the two simplest queries which are most likely to be affected by network
performance rather than computation. More dedicated testing would probably be
needed to determine whether AWS&amp;rsquo;s networking provides consistently lower latency
between VMs, or whether this is just a fluke. We did use the placement group
feature for AWS, but did not use any comparable features (if they exist) for the
other clouds.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/why-oci/groupby-dpmq-horizontal.png&#34; alt=&#34;GroupByCabYearPassengers&#34;&gt;
&lt;em&gt;GroupBy Cab, Year, Passengers&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;microbenchmarks&#34;&gt;Microbenchmarks&lt;/h3&gt;
&lt;p&gt;The main Pilosa package contains hundreds of micro-benchmarks, many of which
involve some form of data ingestion. Depending on the parameters, these are both
CPU and disk intensive.&lt;/p&gt;
&lt;p&gt;These benchmarks take advantage of at most 32 hyperthreads, so the per-thread
performance of a CPU is more important than the total performance.&lt;/p&gt;
&lt;p&gt;The most compute intensive benchmarks are dominated by the c5.9xlarge which
isn&amp;rsquo;t too surprising, but I would have expected similar performance out of
Azure&amp;rsquo;s F32s as they are also running high-end Intel processors.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/why-oci/intersection-count-horizontal.png&#34; alt=&#34;CPU&#34;&gt;
&lt;em&gt;CPU Intensive&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Those benchmarks which are both compute and I/O intensive are mostly swept by
the r5d.12xlarge which is also running Xeon Platinum (at a slightly lower
clock), and has 2 SSDs which we bonded into a single logical volume using LVM
striping.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/why-oci/import-concurrent-horizontal.png&#34; alt=&#34;CPU and I/O&#34;&gt;
&lt;em&gt;CPU and I/O Intensive&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The pure I/O benchmarks (literally just writing a file) were taken by Oracle&amp;rsquo;s
DenseIO instances which also have 2 SSDs striped by LVM. This would seem to
indicate that Oracle&amp;rsquo;s disks are slightly faster, or its I/O subsytem slightly
more optimized than AWS. On another note, the c5.9xlarge instances on EBS
actually fare pretty well compared to the NVME SSDs - only about a factor of 2
slower.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/why-oci/filewrite-horizontal.png&#34; alt=&#34;I/O&#34;&gt;
&lt;em&gt;I/O Intensive&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;puzzles&#34;&gt;Puzzles&lt;/h3&gt;
&lt;p&gt;A number of things didn&amp;rsquo;t quite add up that I&amp;rsquo;d like to dig into more:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Azure didn&amp;rsquo;t perform as well as expected overall - especially in I/O. I&amp;rsquo;m not
sure what type of SSDs Azure uses for its temporary storage, but we should
probably look into other storage options.&lt;/li&gt;
&lt;li&gt;OCI&amp;rsquo;s BM.Standard2.52 performed poorly. On paper it looks extremely cost
effective though: 104 hyper threads, &lt;del&gt;2 massive SSDs&lt;/del&gt;, and more RAM than you
can shake a stick at for $3.31/hr. With the same processor as the
&lt;code&gt;VM.Standard2.16&lt;/code&gt; models, its lack of performance is confusing.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;The r5d.12xlarge won the Filtered TopN query by a healthy margin, but got 6th
in the 29 value segmentation by a factor of 4. Those two queries aren&amp;rsquo;t
terribly different from a workload perspective, however.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion-and-future-work&#34;&gt;Conclusion and Future Work&lt;/h3&gt;
&lt;p&gt;For pure cost-effectiveness, Oracle is pretty compelling, especially given the
amount of memory and SSD you get compared to other cloud providers. The I/O
performance is also excellent.&lt;/p&gt;
&lt;p&gt;For pure speed, AWS seems to provide the fastest processors, although it&amp;rsquo;s
unclear why Azure&amp;rsquo;s offering wasn&amp;rsquo;t more competitive in this area - on paper it
seemed like they should be nearly equal.&lt;/p&gt;
&lt;p&gt;Overall, we&amp;rsquo;ve barely scratched the surface as to the types of tests we could
run, and there are certainly more instance configurations that we could try. A
good exercise would be to measure baseline performance of each subsystem in
isolation (e.g. simple disk write with &lt;code&gt;dd&lt;/code&gt;, simple network test with a TCP
based &lt;code&gt;ping&lt;/code&gt; tool, etc.), and then compare that with our assumptions about what
the various Pilosa benchmarks &lt;em&gt;should&lt;/em&gt; be testing.&lt;/p&gt;
&lt;p&gt;For those who wish to look at the data more closely, we&amp;rsquo;ve been munging all the
results on &lt;a href=&#34;https://data.world/jaffee/benchmarks&#34;&gt;data.world&lt;/a&gt;, which has been a
pretty nice platform for sharing data and various queries as well as producing
charts. Click &amp;ldquo;Launch Workspace&amp;rdquo; on the top right to start playing with the
data - you will have to create a (free) account.&lt;/p&gt;
&lt;p&gt;For those who wish to try to reproduce or expand on these benchmarks, we have a
variety of tooling available in our &lt;a href=&#34;https://github.com/pilosa/infrastructure/tree/master/terraform/examples&#34;&gt;Infrastructure repository.&lt;/a&gt;
This helps with deploying servers, installing and running Pilosa, loading data,
and running the benchmarks.&lt;/p&gt;
&lt;p&gt;Thanks for reading, and please reach out if you have any questions!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update: Part 2 with GCP, memory bandwidth, and more is &lt;a href=&#34;../cloud-bench-redux&#34;&gt;here!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Jaffee is a lead software engineer at Pilosa. When he’s not burning cloud credits for science, he enjoys jiu-jitsu, building mechanical keyboards, and spending time with family. Follow him on Twitter at &lt;a href=&#34;https://twitter.com/mattjaffee?lang=en&#34;&gt;@mattjaffee&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Banner Photo by Daniele Levis Pelusi on Unsplash&lt;/em&gt;&lt;/p&gt;
</description>
        </item>
      
    
      
        <item>
          <title>We Raised our Seed Round</title>
          <link>https://www.pilosa.com/blog/seed-round/</link>
          <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/seed-round/</guid>
          <description>&lt;p&gt;Today, we are excited to announce the first close of a $5.4 million Seed Round led by Skylark Partners. With this investment, John Porter of Skylark will join Tom Meredith and me on our three person board. Other investors in the round include Ben Lamm, Hypergiant, Chris Aniszczyk, Andrew Busey and Tony Robbins.&lt;/p&gt;
&lt;p&gt;Since we &lt;a href=&#34;https://www.statesman.com/news/20170509/austin-based-umbel-spinoff-pilosa-is-pushing-its-big-data-indexing-at-this-weeks-oscon&#34;&gt;spun out of Umbel 18 months ago&lt;/a&gt;, we’ve been focused on making all data easily and instantly analyzable for both humans and machines. Navigating a data industry plagued with increasing complexity and long term capital investments, Pilosa brings a simple solution to enterprises who need the ability to perform continuous analysis on their data. With our nine patents, this effectively means that the database as we know it is fracturing into two parts: the technology that writes data and the technology that accesses that data (the index).&lt;/p&gt;
&lt;p&gt;We focus on abstracting the index from data storage, and our open source Community Edition already has over &lt;a href=&#34;https://github.com/pilosa/pilosa/stargazers&#34;&gt;1,500 users&lt;/a&gt;. We are always blown away by the problems our community is solving with Pilosa. More importantly we are intently monitoring our commercial feedback loop as we continue to build an Enterprise Edition focused on large scale production environments. As we push into our next phase, we will combine these learnings with our funding to achieve these three goals:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Adoptability&lt;/strong&gt;
So far our radically new approach has yielded a burgeoning community of early adopters obsessed with performance, however to achieve our goals of going mainstream we are developing functionality to drive more rapid adoption of Pilosa. High on our list of priorities in this realm includes a SQL-like interface, native floating point data types and better time series support.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ease of Deployment in ANY Infrastructure&lt;/strong&gt;
A key part of our current mission is to enable drop-in continuous analysis on all of your data in any environment, so we are actively working on integrations/partnerships that will drive more pervasive, push button, use of Pilosa. Beyond stand-alone, behind the firewall integrations, we are currently working on tighter integration with &lt;a href=&#34;http://oracle.com/corporate/pressrelease/inaugural-austin-startup-class-101118.html&#34;&gt;Oracle’s Cloud Infrastructure&lt;/a&gt;, Confluent’s Kafka, Microsoft’s Azure, and we have mid-term plans to deepen our interoperability with Amazon’s AWS and Google’s Cloud Services. When integrating into any of these environments, we are primarily focused on data pipelines like Kafka, which already boasts over 35% of the Fortune 500.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Managed Services&lt;/strong&gt;
In the next three quarters we are launching a lightweight Cloud Edition and exploring the potential of going deep into verticals like bioinformatics. Today’s leading scientists and researchers are having to either rely on IT departments mired by monolithic infrastructures or become infrastructure experts to do their work. We see a world where humans (aided by machines doing AI/ML) have instant access to analyze all of their data, no matter how complex, as simply as storing a file. We believe that a “Cloud Edition” of Pilosa may be the fastest path for us to reach pervasive adoption.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We are really proud of what we have achieved so far, very excited about 2019 and mostly look forward to doubling our team. We are &lt;a href=&#34;https://www.pilosa.com/careers/&#34;&gt;currently hiring&lt;/a&gt; in engineering, marketing and customer service.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Pilosa 1.0 Released</title>
          <link>https://www.pilosa.com/blog/pilosa-1-0-released/</link>
          <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/pilosa-1-0-released/</guid>
          <description>&lt;p&gt;Pilosa is happy to announce version 1.0, available as of last week! After eight feature-heavy major releases since our launch, there were a lot of loose ends to clean up. As followers of &lt;a href=&#34;https://semver.org/&#34;&gt;semantic versioning&lt;/a&gt;, 1.0 is a big milestone, and a binding one. Although Pilosa is far from &amp;ldquo;complete&amp;rdquo;, this release signifies a certain stability. We plan to support the current feature set and API through all 1.x releases, and that entails more than you might think.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s in an API, anyway? The more we thought about that question, the more answers popped up. There is an obvious place to start—our HTTP interface and query language—but it keeps going. Since we&amp;rsquo;re an open-source project, the code itself is another facet of the API. Every public line of code is potentially a part of the API surface that requires support throughout 1.x.&lt;/p&gt;
&lt;p&gt;Among the components we considered, as we were going into 1.0:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP API&lt;/li&gt;
&lt;li&gt;Query language&lt;/li&gt;
&lt;li&gt;CLI usage&lt;/li&gt;
&lt;li&gt;Configuration&lt;/li&gt;
&lt;li&gt;Data storage format&lt;/li&gt;
&lt;li&gt;Golang package structure and exported variables&lt;/li&gt;
&lt;li&gt;Multiple language-specific clients, officially supported and otherwise&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/console&#34;&gt;Pilosa dev kit&lt;/a&gt;, which includes examples and connectors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As we approached our 1.0 release, the ability to maintain compatibility promises became increasingly important. We began to audit all of these components for long-term support, with the primary goal of paring things down to our core functionality. Each of these components of our API surface has its own quirks, so they each need special attention.&lt;/p&gt;
&lt;p&gt;A large portion of the work in this release focused on these API changes, but there were some more publicly visible changes as well:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PQL syntax has been updated significantly. See the &lt;a href=&#34;https://www.pilosa.com/docs/query-language/&#34;&gt;docs&lt;/a&gt; for details.&lt;/li&gt;
&lt;li&gt;Frames are now known as fields, and the nesting of fields within frames no longer exists; each field exists at the top level in an index.&lt;/li&gt;
&lt;li&gt;Field creation has been revamped, with a more sensible field type system. For example, fields that were &amp;ldquo;rangeEnabled&amp;rdquo; are now simply fields of type &amp;ldquo;int&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Slices are now known as shards.&lt;/li&gt;
&lt;li&gt;Query responses now refer to &amp;ldquo;columns&amp;rdquo; rather than &amp;ldquo;bits&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;WebUI has been removed from Pilosa, and is now available &lt;a href=&#34;https://github.com/pilosa/console&#34;&gt;separately&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;changelog&#34;&gt;Changelog&lt;/h3&gt;
&lt;p&gt;To see the complete list of new features, fixes, and performance improvements, check out &lt;a href=&#34;https://github.com/pilosa/pilosa/releases&#34;&gt;our releases on Github&lt;/a&gt;.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Genome Comparisons in 4 Milliseconds</title>
          <link>https://www.pilosa.com/blog/processing-genomes/</link>
          <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/processing-genomes/</guid>
          <description>&lt;p&gt;6 Gigabits. That&amp;rsquo;s about how much data is encoded in your DNA. That may sound like a lot, or a little depending on your comfort level, but with 7 billion humans on the planet, that we&amp;rsquo;re in &amp;ldquo;big data&amp;rdquo; territory is undeniable. Can we bend Pilosa to a problem of this mind boggling size? How fast can we compare two genomes? Or two thousand? What about finding groups of related individuals, or certain disease markers? How do you even represent this kind of data as a binary matrix? Let&amp;rsquo;s take a look&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;a-crash-course-in-genome-sequencing&#34;&gt;A Crash Course in Genome Sequencing&lt;/h3&gt;
&lt;p&gt;A genome is just a set of 23 pairs of really long strings, how difficult could it be to model it? As it turns out, the situation is quite a bit more nuanced.&lt;/p&gt;
&lt;p&gt;A human genome consists of approximately 3 billion base pairs. For a given sample, each of these is, naively, representable as single characters &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;T&lt;/code&gt;, &lt;code&gt;G&lt;/code&gt; or &lt;code&gt;C&lt;/code&gt;, at one precisely specified coordinate in the genome. When sequencing a genome, things get a little more fuzzy. To start with, the data coming out of a sequencer isn&amp;rsquo;t just a series of strings. It&amp;rsquo;s &lt;a href=&#34;https://medium.com/precision-medicine/how-big-is-the-human-genome-e90caa3409b0&#34;&gt;hundreds of gigs&lt;/a&gt; of short reads with corresponding metadata. After some processing, that same sample might be represented as a VCF file, showing the variants (mutations) relative to a reference genome.&lt;/p&gt;
&lt;p&gt;If a sequenced genome is stored as, more or less, a &amp;ldquo;diff&amp;rdquo; based on a reference genome, how is the reference stored? Data is available in many formats, but we chose to use the Genome Reference Consortium Human Build 37 (GRCh37) in FASTA format. This format is, ideally, very close to the &amp;ldquo;really long string&amp;rdquo; representation of a genome. A FASTA file has several sections, each of which might contain the series of &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;T&lt;/code&gt;, &lt;code&gt;G&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, at precisely-known offsets, for an entire chromosome. However, the format supports more than this: &lt;code&gt;N&lt;/code&gt;, which represents &lt;em&gt;any&lt;/em&gt; nucleotide, &lt;code&gt;-&lt;/code&gt;, for a &amp;ldquo;gap of indeterminate length&amp;rdquo;, and various other characters which represent combinations of multiple bases. These other characters are useful for representing heterozygosity (among other things) where each of the chromosomes in a pair might have a different base at a particular position.  The reference file is very clean: almost entirely &lt;code&gt;ATGC&lt;/code&gt;, and a small number of &lt;code&gt;N&lt;/code&gt;s.&lt;/p&gt;
&lt;p&gt;For our proof of concept, instead of trying to find real genome data for thousands of individuals, (which might have some privacy issues), we simply generated additional genomes by randomly mutating the GRCh37 reference genome. Each generated genome would contain between 0.1% and 0.5% mutations uniformly distributed in the reference. For this test, we sidestepped problems with alignment or variant confidence; this allowed us to work with some representative data to explore queries and measure performance.&lt;/p&gt;
&lt;h3 id=&#34;genomes-as-bitmaps&#34;&gt;Genomes as Bitmaps&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s revisit the basic Pilosa data model:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/docs/data-model.svg&#34; alt=&#34;Pilosa data model&#34;&gt;
&lt;em&gt;Pilosa data model&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Pilosa stores relationships as ones and zeros in an index that can easily scale in both rows and columns, and performs operations across rows. Given this giant binary matrix, what is a sensible way to represent a genome? Of course, the answer depends on what you want to do with the index. We had tried two approaches in the past:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;One genome per column, each row representing a different nucleotide.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This matches many Pilosa use cases, with columns as records, and rows as attributes. However, it is very awkward to handle, even for just a few genomes because each node in the cluster needs to know about all the rows. As more genomes are added, it can scale very well, but it has a lot of overhead at the outset and requires high memory machines even for small tests. Although each row only represents a single position on the genome, the internal memory needed to track each row is around 100 bytes. This doesn&amp;rsquo;t sound like much, but if you have 1 billion rows, that means you need 100GB of memory!&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;One genome per row, each column representing a &lt;a href=&#34;https://en.wikipedia.org/wiki/K-mer&#34;&gt;k-mer&lt;/a&gt; match to a sample genome.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/processing-genomes/kmer-model.png&#34; alt=&#34;K-mer data model&#34;&gt;
&lt;em&gt;K-mer data model&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The k-mer model works very well, but only stores the k-mer matches, not the genomes themselves. We want something that&amp;rsquo;s both general and scalable.&lt;/p&gt;
&lt;p&gt;With the experience gained from these two approaches, plus some expert advice from &lt;a href=&#34;https://twitter.com/gareth862&#34;&gt;Gareth&lt;/a&gt;, we settled on a new model. Pilosa is unique in that it can support extremely wide bitmaps. While most libraries and indexes won&amp;rsquo;t natively support bitmaps for integers larger than 32 bits, Pilosa&amp;rsquo;s custom &lt;a href=&#34;https://roaringbitmap.org/&#34;&gt;roaring&lt;/a&gt; implementation supports 64 bit integers. This means that we can scale columns effectively forever (2&lt;!-- raw HTML omitted --&gt;64&lt;!-- raw HTML omitted --&gt; is really big). Pilosa also supports embarrassingly scalable bitmap operations as the number of columns grows, so we decided to use this to our advantage. We simply indexed each entire genome in a single bitmap!&lt;/p&gt;
&lt;p&gt;In other words, each row is a genome, and columns represent base pairs at specific positions in the genome. Specifically, each base pair is represented as a group of four columns, one each for &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;T&lt;/code&gt;, &lt;code&gt;G&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt;. For most positions on the genome, one of those four columns is set. In the heterozygous case, we can simply set multiple bits.&lt;/p&gt;
&lt;p&gt;For example, using a reference genome that begins &lt;code&gt;GTAA&lt;/code&gt;, and another genome that begins &lt;code&gt;GTTA&lt;/code&gt;, one tiny corner of our index will look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/processing-genomes/genome-model-simple.png&#34; alt=&#34;Genome model simple&#34;&gt;
&lt;em&gt;Genome data model&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;With 3 billion base pairs, we end up with 12 billion columns, and one row per sample. In Pilosa, the combination of index width and &lt;a href=&#34;https://www.pilosa.com/docs/latest/glossary/#shardwidth&#34;&gt;&lt;code&gt;shard width&lt;/code&gt;&lt;/a&gt; affects parallel performance, as well as the number of open files. We took this opportunity to experiment with the shard width and found that increasing from our default size of 2&lt;!-- raw HTML omitted --&gt;20&lt;!-- raw HTML omitted --&gt; to 2&lt;!-- raw HTML omitted --&gt;23&lt;!-- raw HTML omitted --&gt; was a good balance.&lt;/p&gt;
&lt;p&gt;Sequenced genomes are the main entity in the index, but we can do more than that! For example, base pairs on chromosome 1 are all stored in the first billion or so columns (chromosome 1 is about 250M base pairs long). We can store a special &amp;ldquo;mask&amp;rdquo; bitmap that is all ones for those columns, and zero elsewhere. Do this for each of the 25 chromosomes (1-22, X, Y, and mitochondrial), and you gain the ability to select only base pairs on a given chromosome. Similarly, any gene that lives in a known region on a chromosome can be given a mask bitmap.&lt;/p&gt;
&lt;p&gt;Up to this point we have been describing DNA as one long string of data, but in reality DNA is tightly wrapped and compacted around nucleosomes. The specifics of this compacting allow for each cell type to have different characteristics by &amp;ldquo;opening&amp;rdquo; and &amp;ldquo;closing&amp;rdquo; specific portions of the DNA. We can use &amp;ldquo;cell type masks&amp;rdquo; to represent which regions of the genome are &amp;ldquo;open&amp;rdquo; in each cell type, allowing us to compare different tissue types against each other (such as normal and cancerous tissue) to understand how changes in the DNA landscape might be contributing to disease!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/processing-genomes/genome-model-details.png&#34; alt=&#34;Genome model details&#34;&gt;
&lt;em&gt;More genome bitmap tricks&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;now-what&#34;&gt;Now what?&lt;/h4&gt;
&lt;p&gt;With this more general data model, some interesting queries become possible:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;How similar are two people genetically? Pilosa allows for a number of comparison metrics here. Perhaps the simplest is a count of how many base pairs they share: &lt;code&gt;Count(Intersect())&lt;/code&gt;. Any &lt;a href=&#34;http://www.iiisci.org/journal/CV$/sci/pdfs/GS315JG.pdf&#34;&gt;binary similarity metric&lt;/a&gt; is also easy to compute by combining a small number of Pilosa queries. With the &amp;ldquo;mask&amp;rdquo; bitmaps shown above, it is trivial to run similar comparison queries restricted to specific chromosomes or genes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TopN: Which genomes are most similar to a particular genome? This might be used to identify people who are likely to have a disease, or certain disposition. A one-to-many comparison search on &lt;a href=&#34;https://www.gedmatch.com&#34;&gt;GEDMatch&lt;/a&gt; was recently used to match a suspect in a decades-old &lt;a href=&#34;https://www.washingtonpost.com/local/public-safety/to-find-alleged-golden-state-killer-investigators-first-found-his-great-great-great-grandparents/2018/04/30/3c865fe7-dfcc-4a0e-b6b2-0bec548d501f_story.html?utm_term=.87045d490fd3&#34;&gt;serial killer case&lt;/a&gt;. Perhaps there is an opportunity to speed up that kind of computation with Pilosa?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Identifying families and relations: a search could find cliques of individuals, &lt;em&gt;without&lt;/em&gt; a starting genome.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;performance&#34;&gt;Performance&lt;/h4&gt;
&lt;p&gt;With speed as a main goal, we spun up a 360-core cluster with 600GB of total RAM (10 x c4.8xlarge, 60GB RAM, 36 vCPU). Because we know ahead of time which Pilosa column each position on the genome maps to, we were able to parallelize the ingestion of each genome based on Pilosa&amp;rsquo;s shard width. Basically we cut each genome into portions that corresponded to 2&lt;!-- raw HTML omitted --&gt;23&lt;!-- raw HTML omitted --&gt; Pilosa columns, and gave each portion to a separate CPU core to process and send to Pilosa. Both client and cluster side, the ingestion was totally parallel.&lt;/p&gt;
&lt;p&gt;We were able to ingest new genomes on this cluster at a rate of less than 15 seconds each, or 216M SetBits (nucleotides) per second. This is already plenty fast, but there are several obvious improvements that could be made. Specifically, we built our import around the FASTA format, but with VCF files, we can run imports that only need to set one bit per variant, rather than one per base pair. Our import protocol is also built around specifying each bit as a row/column pair, but for this use case, we could specify the row once and then all the columns that need to be set, saving a ton of bandwith.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;With hundreds of genomes imported into this index, we were finally able to run some queries. Comparing two genomes, as in query #1 above, takes about 150 milliseconds. Query #2, identifying the most similar genomes to a given one, across the entire index, completes in just seconds. The best part? This scales to a large number of rows, allowing much faster queries across many more genomes.&lt;/p&gt;
&lt;p&gt;OK, but&amp;hellip; 4 milliseconds? Where&amp;rsquo;s that come from? We performed the following query &lt;code&gt;TopN(Difference(Bitmap(frame=sequences, row=1), Bitmap(frame=sequences, row=0)), frame=sequences)&lt;/code&gt;. This is subtracting the reference genome from Person 1&amp;rsquo;s genome to get all the places where Person 1 varies from the reference, and then using that as a filter to a TopN query. The result is a list of genomes ordered by the number of variants they have in common with Person 1. This query takes about 260ms on our cluster with 29 genomes loaded + the reference. 260ms/29 equals about 9ms per genome. We then loaded 100 genomes and ran the same query - the median run time was about 400ms or 4ms per genome! Upping the ante, we loaded 200 genomes - this time the median was 1.2s giving us about 6ms per genome. Interestingly, the minimum time we observed for this query was a fairly astounding 554ms which gives us hope that with some refinement, we may be able to process genome comparisons in under 3ms consistently.&lt;/p&gt;
&lt;p&gt;The work is ongoing, and you can follow new developments in the import process in the &lt;a href=&#34;https://github.com/pilosa/pdk/tree/genome/usecase/genome&#34;&gt;PDK repo&lt;/a&gt;. If you are conducting genomics research that you&amp;rsquo;d like to discuss with our team, please don&amp;rsquo;t hesitate to reach out to &lt;a href=&#34;mailto:info@pilosa.com&#34;&gt;info@pilosa.com&lt;/a&gt;. We&amp;rsquo;re excited to continue making advancements in this space!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Banner image by the original authors of the Protein Data Bank (PDB) structural data and open-source chemical structure viewer Jmol, CC BY-SA 3.0, &lt;a href=&#34;https://commons.wikimedia.org/w/index.php?curid=21983632&#34;&gt;https://commons.wikimedia.org/w/index.php?curid=21983632&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Alan is a software engineer at Pilosa. When he’s not mapping the universe, you can find him playing with laser cutters, building fidget spinners for his dog, or practicing his sick photography skills. Find him on Twitter &lt;a href=&#34;https://twitter.com/gsnark&#34;&gt;@gsnark&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Jaffee is a lead software engineer at Pilosa. When he’s not dabbling in bioinformatics, he enjoys jiu-jitsu, building mechanical keyboards, and spending time with family. Follow him on Twitter at &lt;a href=&#34;https://twitter.com/mattjaffee?lang=en&#34;&gt;@mattjaffee&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Pilosa Featured On Changelog&#39;s GoTime Podcast</title>
          <link>https://www.pilosa.com/blog/pilosa-featured-on-changelogs-gotime-podcast/</link>
          <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/pilosa-featured-on-changelogs-gotime-podcast/</guid>
          <description>&lt;p&gt;Since we write in Go all day, everyday, we LOVE Changelog’s GoTime Podcast. The show consists of a panel of Go experts and special guests discussing the Go programming language, the Go community, and everything in between.&lt;/p&gt;
&lt;p&gt;Pilosa’s very own Matt Jaffee was featured on GoTime last week to talk all things Go: distributed systems, indexing tools, cool Go projects, and more. Matt is our lead software engineer and a Go enthusiast.&lt;/p&gt;
&lt;p&gt;Check out his episode below to hear why Go is the perfect language for designing simple, high performance, distributed systems like Pilosa:&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;Go Time 76: Building a distributed index&lt;!-- raw HTML omitted --&gt; – Listen on &lt;!-- raw HTML omitted --&gt;Changelog.com&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Find GoTime on Twitter &lt;a href=&#34;https://twitter.com/GoTimeFM?lang=en&#34;&gt;@GoTimeFM&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Find Changelog on Twitter &lt;a href=&#34;https://twitter.com/changelog?lang=en&#34;&gt;@changelog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Jaffee is a lead software engineer at Pilosa. When he’s not evangelizing independent indexes, he enjoys jiu-jitsu, building mechanical keyboards, and spending time with family. Follow him on Twitter at &lt;a href=&#34;https://twitter.com/mattjaffee?lang=en&#34;&gt;@mattjaffee&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Sarah is Pilosa’s Community Manager by day. DJ by night. Cat lady by birth. Find her on Twitter at &lt;a href=&#34;https://twitter.com/sarahking_atx?lang=en&#34;&gt;@sarahking_atx&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Getting On the Map: Joining the Cloud Native Landscape</title>
          <link>https://www.pilosa.com/blog/cloud-native-landscape/</link>
          <pubDate>Tue, 13 Mar 2018 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/cloud-native-landscape/</guid>
          <description>&lt;p&gt;In an effort to stay relevant and cutting edge, more enterprises are having to swiftly migrate their monolith to fully distributed systems built around cloud-native applications.&lt;/p&gt;
&lt;p&gt;As you start to explore the cloud native space, it’s easy to be left scratching your head trying to conceptualize where this complex web of microservices begins and how those services fit together.&lt;/p&gt;
&lt;h3 id=&#34;cloud-native-trail-map&#34;&gt;Cloud Native Trail Map&lt;/h3&gt;
&lt;p&gt;Into view comes the &lt;a href=&#34;https://github.com/cncf/landscape&#34;&gt;Cloud Native Landscape Project&lt;/a&gt;. Created by the Cloud Native Computing Foundation, it was designed to help organizations navigate the hundreds of projects and product offerings in the cloud-native ecosystem. Along with this landscape, they developed an &lt;a href=&#34;https://landscape.cncf.io/&#34;&gt;awesome interactive tool&lt;/a&gt; that can filter based on a number of different product classifications.&lt;/p&gt;
&lt;p&gt;To get you started, CNCF published an easy-to-digest Cloud Native Trail Map to help you embark on the journey of choosing your cloud native microservices:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cncf/landscape/master/trail_map/CNCF_TrailMap_latest.png&#34; alt=&#34;Cloud Native Trail Map&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;pilosas-mark-on-the-map&#34;&gt;Pilosa&amp;rsquo;s Mark on the Map&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.cncf.io/&#34;&gt;Cloud Native Computing Foundation&lt;/a&gt;, &lt;a href=&#34;http://www.linuxfoundation.org/&#34;&gt;The Linux Foundation&lt;/a&gt;, &lt;a href=&#34;https://www.cloudfoundry.org/&#34;&gt;Cloud Foundry&lt;/a&gt;, and &lt;a href=&#34;https://www.opencontainers.org/&#34;&gt;Open Container Initiative&lt;/a&gt; were all established to promote continuous, unpolitical innovation (Ramji, OSCON 2015). These foundations allow for unbridaled collaboration with other open source technologies, which significantly enhances the speed at which projects can be built and deployed.&lt;/p&gt;
&lt;p&gt;As you know, speed is our middle name. It is our mission to make it as easy as Pi to drop Pilosa into any environment. Currently, Pilosa easily drops into a Lambda architecture—or any architecture built around a data pipeline—with a few lines of code, while other implementations require a bit more legwork to get Pilosa integrated. We are actively working on those latter cases, which is why we are so excited to be a part of the Cloud Native Landscape Project.&lt;/p&gt;
&lt;p&gt;We are eager to collaborate with partners in the Cloud Native Landscape to complement and accelerate projects, while also allowing turn key implementation of Pilosa into any cloud environment. If you’re part of this project and want to explore how we can work together, &lt;a href=&#34;mailto:info@pilosa.com&#34;&gt;drop us a line&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Sarah is Pilosa’s Community Manager by day. DJ by night. Cat lady by birth. Find her on Twitter at &lt;a href=&#34;https://twitter.com/sarahking_atx?lang=en&#34;&gt;@sarahking_atx&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Supercharge Azure Cosmos DB with Pilosa</title>
          <link>https://www.pilosa.com/blog/cosmos/</link>
          <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/cosmos/</guid>
          <description>&lt;p&gt;Pilosa is already super fast for huge data. Our next step is making it easy.&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;At Pilosa, we&amp;rsquo;re excited about finding new applications of the distributed bitmap index, so we have explored a number of use-cases. Some of these have been fairly application-specific, a sometimes necessary evil in evaluating a new technology. Looking ahead, we&amp;rsquo;ve explored several conceptual approaches to more general-purpose database connections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;client-integrated (library)&lt;/li&gt;
&lt;li&gt;datastore-integrated (supercharger)&lt;/li&gt;
&lt;li&gt;change feed (self-updating)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Briefly, the client-integrated approach is an ORM designed to transparently handle both storing data in the canonical store, and indexing it with Pilosa. This would have to be done for every combination of programming language and database which we wanted to support, and probably isn&amp;rsquo;t practical.&lt;/p&gt;
&lt;p&gt;The datastore-integrated approach is a relatively intrusive modification to an
existing database, augmenting the database&amp;rsquo;s existing internal indexing system.
Realistically, we would probably use Pilosa as a transparent proxy to the
database, indexing writes automatically, and re-writing queries to make the best
possible use of Pilosa. This requires supporting multiple different database
APIs, but is at least programming language agnostic.&lt;/p&gt;
&lt;p&gt;The change feed approach simply listens for updates via an existing hook.
Many databases have this kind of functionality, and Pilosa already has some &lt;a href=&#34;https://github.com/pilosa/pdk&#34;&gt;tooling&lt;/a&gt;
for indexing arbitrary data.
While this option doesn&amp;rsquo;t make reads any easier,
it is a fairly straightforward way to start indexing in Pilosa without making
intrusive modifications to your application.&lt;/p&gt;
&lt;p&gt;Each of these approaches has advantages in different dimensions: how easy is it
to use? How well does it guarantee some level of consistency between the
canonical store and Pilosa? How much of our development time will it take?&lt;/p&gt;
&lt;p&gt;Datastore integration is close to our long-term goal.
We want Pilosa to be a drop-in tool to enable fast access to any data,
and that means minimal setup and configuration.
It&amp;rsquo;s also a significant undertaking,
especially considering that the work might be largely specific to the database system we&amp;rsquo;re connecting to.
The change feed approach is a good intermediate step in that direction —
it is a way to reduce, or at least standardize, setup and configuration,
providing a consistent process to connect Pilosa to common data storage systems.&lt;/p&gt;
&lt;h3 id=&#34;enter-azure-cosmos-db&#34;&gt;Enter Azure Cosmos DB&lt;/h3&gt;
&lt;p&gt;Azure Cosmos DB is one of the newer offerings on Microsoft&amp;rsquo;s Azure cloud computing platform. As a multi-model database, it provides access to your data through document, graph and table models, among others.&lt;/p&gt;
&lt;p&gt;This means that while a user could be interacting with Azure Cosmos DB via a SQL, MongoDB, or Cassandra API, we can read the change feed and always see changes in the same format for indexing.&lt;/p&gt;
&lt;p&gt;One of the things we like about Azure Cosmos DB is its consistency model. Although tunable consistency is not new, the ability to select between &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels#consistency-levels&#34;&gt;five consistency levels&lt;/a&gt; while maintaining SLA guarantees is an interesting and novel feature. As believers in &lt;a href=&#34;https://www.pilosa.com/blog/oscon-2017-recap-the-index-as-a-first-class-citizen/&#34;&gt;the index as a first-class citizen&lt;/a&gt;, we&amp;rsquo;re happy to see consistency being handled in a more fine-grained way: consistency and availability are both crucial, broadly speaking, but it can make a lot of sense to forfeit strong consistency for performance in the context of an index.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cosmos/banner.jpg&#34; alt=&#34;Pilosa loves cosmos&#34;&gt;&lt;/p&gt;
&lt;p&gt;One of the big draws of Cosmos is that it automatically indexes everything by default. Since Pilosa is an index, you might think there isn&amp;rsquo;t much room for it here, and while we initially wondered that, experiments seem to suggest otherwise. Cosmos&#39; approach to indexing is described in some detail in this &lt;a href=&#34;http://www.vldb.org/pvldb/vol8/p1668-shukla.pdf&#34;&gt;paper&lt;/a&gt;, which turns out to be quite complementary to Pilosa&amp;rsquo;s approach.&lt;/p&gt;
&lt;p&gt;All of this makes Azure Cosmos DB and Pilosa a natural fit for each other. Pilosa needs a consistent underlying data store and support for multiple APIs. Azure Cosmos DB benefits by exposing Pilosa to enable super low latency queries for high cardinality segmentation and other query types at which Pilosa excels. Azure Cosmos DB users would benefit in this case by reducing their Cosmos Request Unit usage for queries which can be intensive and only performing simple document fetches which may fall under Azure Cosmos DB&amp;rsquo;s impressive SLAs. Later on, we believe Pilosa could be incorporated more directly into Azure Cosmos DB&amp;rsquo;s indexing system to provide enhanced performance in a way which is completely transparent to the end user.&lt;/p&gt;
&lt;p&gt;Currently, we imagine deploying Pilosa into existing software stacks using Azure Cosmos DB, and using Pilosa to help power ad-hoc queries as well as data science and machine learning applications. Azure Cosmos DB can continue serving normal application business logic, but having Pilosa available alongside it opens up new avenues for iterative data exploration that may not previously have been practical.&lt;/p&gt;
&lt;p&gt;In order to validate our theories about Azure Cosmos DB and Pilosa, we used an Azure &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/azure-functions/functions-reference#function-app&#34;&gt;Function App&lt;/a&gt; to read the Azure Cosmos DB change feed and post that to the &lt;a href=&#34;https://github.com/pilosa/pdk&#34;&gt;Pilosa Dev Kit&lt;/a&gt; using its automated indexing functionality to get the data indexed in Pilosa. Read on for the gory details and some performance comparisons!&lt;/p&gt;
&lt;h3 id=&#34;pilosa--azure-cosmos-db&#34;&gt;Pilosa + Azure Cosmos DB&lt;/h3&gt;
&lt;p&gt;We&amp;rsquo;ve documented our approach &lt;a href=&#34;https://github.com/pilosa/cosmosa&#34;&gt;here&lt;/a&gt;, so try it out yourself! We did our best to include every detail in those instructions - for newcomers to Go or Cosmos DB, but please feel free to open an issue in that repository or send us a pull request! We&amp;rsquo;ll just summarize here.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/cosmos/cosmos-integration-diagram.png&#34; alt=&#34;Azure Cosmos DB integration diagram&#34;&gt;
&lt;em&gt;Crude Azure Cosmos DB integration diagram&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In addition to the data store (Azure Cosmos DB) and the index (Pilosa), the system includes a couple of other components. Adapted from one of the Azure Cosmos DB &lt;a href=&#34;https://github.com/Azure-Samples/azure-cosmos-db-mongodb-golang-getting-started&#34;&gt;samples&lt;/a&gt;, the &lt;a href=&#34;https://github.com/pilosa/cosmosa&#34;&gt;cosmosa&lt;/a&gt; tool handles both data generation and Azure Cosmos DB querying via the Mongo API. The &lt;a href=&#34;https://github.com/pilosa/pdk&#34;&gt;Pilosa Dev Kit&lt;/a&gt; has a new &lt;code&gt;http&lt;/code&gt; subcommand, which listens for arbitrary JSON data to index in Pilosa; this plays nicely with the change feed from the Azure Cosmos DB function app, which connects directly to this PDK listener.&lt;/p&gt;
&lt;p&gt;That all sounds a little overwhelming, so I want to add some context. What does this system look like to an Azure Cosmos DB user? The database and the data generator represent existing components, and the Function App is trivial; you can copy the source from our &lt;a href=&#34;https://github.com/pilosa/cosmosa#create-a-function-app-to-process-the-cosmosdb-change-feed&#34;&gt;instructions&lt;/a&gt;. The Pilosa and PDK servers are the new components that need to be set up separately, at least for now.&lt;/p&gt;
&lt;p&gt;What do we get for this? All the raw speed of Pilosa, and all the flexibility of Azure Cosmos DB, woven together into one supercharged system!&lt;/p&gt;
&lt;p&gt;Here are some timed queries into Cosmos:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Query&lt;/th&gt;
&lt;th&gt;CosmosDB&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Count All Records&lt;/td&gt;
&lt;td&gt;80ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Record&lt;/td&gt;
&lt;td&gt;32ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Record with 3 particular tiles&lt;/td&gt;
&lt;td&gt;124ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;p1&amp;rdquo;&lt;/td&gt;
&lt;td&gt;277ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;bx&amp;rdquo;&lt;/td&gt;
&lt;td&gt;279ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;jt&amp;rdquo;&lt;/td&gt;
&lt;td&gt;527ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;wy&amp;rdquo;&lt;/td&gt;
&lt;td&gt;808ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;e8&amp;rdquo;&lt;/td&gt;
&lt;td&gt;741ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count records with p1,jt,wy&lt;/td&gt;
&lt;td&gt;806ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;These have 5 second sleeps in between them as that seemed to make the performance better. The slower Count queries (greater than 500ms) could probably have benefited from longer breaks between queries.
This may have something to do with Cosmos&#39; cost/performance structure and the number of &amp;ldquo;RUs&amp;rdquo; we had available.&lt;/p&gt;
&lt;p&gt;And here are the Pilosa queries:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Query&lt;/th&gt;
&lt;th&gt;Pilosa&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Top 20 tiles&lt;/td&gt;
&lt;td&gt;20ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;p1&amp;rdquo;&lt;/td&gt;
&lt;td&gt;9ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;bx&amp;rdquo;&lt;/td&gt;
&lt;td&gt;7ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;jt&amp;rdquo;&lt;/td&gt;
&lt;td&gt;8ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;wy&amp;rdquo;&lt;/td&gt;
&lt;td&gt;8ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count with tile &amp;ldquo;e8&amp;rdquo;&lt;/td&gt;
&lt;td&gt;11ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Count records with p1,jt,wy&lt;/td&gt;
&lt;td&gt;8ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This whole battery executes more or less instantly for what it&amp;rsquo;s worth. As you can see, Pilosa is 30-60x faster than Azure CosmosDB for these queries on this data.&lt;/p&gt;
&lt;p&gt;Stay tuned as we dig more into these numbers and figure out how to model filtered TopN queries in CosmosDB!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Alan is a software engineer at Pilosa. When he’s not mapping the universe, you can find him playing with laser cutters, building fidget spinners for his dog, or practicing his sick photography skills. Find him on Twitter &lt;a href=&#34;https://twitter.com/gsnark&#34;&gt;@gsnark&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Jaffee is a lead software engineer at Pilosa. When he’s not evangelizing independent indexes, he enjoys jiu-jitsu, building mechanical keyboards, and spending time with family. Follow him on Twitter at &lt;a href=&#34;https://twitter.com/mattjaffee?lang=en&#34;&gt;@mattjaffee&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Pilosa 0.8.8 Released</title>
          <link>https://www.pilosa.com/blog/pilosa-0-8-8-released/</link>
          <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/pilosa-0-8-8-released/</guid>
          <description>&lt;p&gt;Pilosa has seen a handful of releases since &lt;a href=&#34;https://www.pilosa.com/blog/pilosa-0-6-0-released/&#34;&gt;v0.6.0&lt;/a&gt; was announced. Pilosa &lt;a href=&#34;https://github.com/pilosa/pilosa/releases/tag/v0.7.0&#34;&gt;v0.7.0&lt;/a&gt; was released on October 10, 2017, with a number of minor features including XOR and &lt;a href=&#34;https://www.pilosa.com/docs/latest/query-language/#range-bsi&#34;&gt;BETWEEN&lt;/a&gt; support, &lt;a href=&#34;https://www.pilosa.com/docs/latest/administration/#importing-integer-values&#34;&gt;BSI imports&lt;/a&gt;, &lt;a href=&#34;https://www.pilosa.com/docs/latest/query-language/#sum&#34;&gt;Sum&lt;/a&gt; queries, and more. &lt;a href=&#34;https://github.com/pilosa/pilosa/releases/tag/v0.8.0&#34;&gt;v0.8.0&lt;/a&gt; was released on November 15 with &lt;a href=&#34;https://www.pilosa.com/docs/administration/#diagnostics&#34;&gt;Diagnostics&lt;/a&gt;, and the latest patch &lt;a href=&#34;https://github.com/pilosa/pilosa/releases/tag/v0.8.8&#34;&gt;v0.8.8&lt;/a&gt; was released this week with a &lt;a href=&#34;https://github.com/pilosa/pilosa/pull/1118/files&#34;&gt;revamp of Roaring tests&lt;/a&gt; to stamp out a whole class of bugs. Combined with other patch releases, these represent 161 contributions from 10 contributors.&lt;/p&gt;
&lt;p&gt;v0.8.8 includes:&lt;/p&gt;
&lt;h3 id=&#34;roaring-test-generation&#34;&gt;Roaring test generation&lt;/h3&gt;
&lt;p&gt;Despite having a huge number of tests in our Roaring Bitmaps package, we&amp;rsquo;ve uncovered a few bugs since the RLE implementation, each one identifying a previously undiscovered corner case. The last few &lt;a href=&#34;https://github.com/pilosa/pilosa/issues/1103&#34;&gt;bug reports&lt;/a&gt; prompted an &lt;a href=&#34;https://github.com/pilosa/pilosa/pull/1118/files&#34;&gt;overhaul&lt;/a&gt; of our approach to testing Roaring.&lt;/p&gt;
&lt;p&gt;Previously, tests were defined manually, in a best-effort sort of way. Now, we have a more automated system for defining a large, comprehensive series of tests, based on concise description structures. We define several container-sized bit patterns (e.g. all bits set, alternating bits set, etc.), plus the expected output of every operation we support on every binary combination of those bit patterns. Then we run each combination through each operation for every pair of possible &lt;a href=&#34;https://www.pilosa.com/blog/adding-rle-support/&#34;&gt;container types&lt;/a&gt;. We can expand coverage as needed by defining new bit patterns. At present this checks the correctness of 3168 roaring operations! This approach has, so far, uncovered at least &lt;a href=&#34;https://github.com/pilosa/pilosa/pull/1118&#34;&gt;six bugs&lt;/a&gt; that might have eluded us for much longer otherwise.&lt;/p&gt;
&lt;p&gt;In short, this means many new bugs in Roaring will be easier to fix, and will likely uncover any other instances of the same bug at the same time. Thanks to &lt;a href=&#34;https://github.com/FerrariHuang&#34;&gt;Ferrari Huang&lt;/a&gt; for the multiple bug reports which prompted this effort!&lt;/p&gt;
&lt;h3 id=&#34;diagnostics&#34;&gt;Diagnostics&lt;/h3&gt;
&lt;p&gt;As of v0.8.0, Pilosa server now reports &lt;a href=&#34;https://www.pilosa.com/docs/latest/administration/#diagnostics&#34;&gt;Diagnostics&lt;/a&gt; to Pilosa Corp by default. Diagnostics are anonymous usage metrics that help us understand how Pilosa is used so we can appropriately focus our efforts on improving the software.&lt;/p&gt;
&lt;h3 id=&#34;v070-updates&#34;&gt;v0.7.0 updates&lt;/h3&gt;
&lt;p&gt;v0.7.0 saw a number of minor improvements to query functionality, many related to BSI fields for indexing integer values.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/789&#34;&gt;Xor queries in PQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/847&#34;&gt;BETWEEN support for Range queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/840&#34;&gt;BSI import endpoint&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/778&#34;&gt;Sum field queries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pilosa/pilosa/pull/755&#34;&gt;BSI Range queries in PQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;changelog&#34;&gt;Changelog&lt;/h3&gt;
&lt;p&gt;To see the complete list of new features, fixes, and performance improvements, check out &lt;a href=&#34;https://github.com/pilosa/pilosa/releases&#34;&gt;our releases on Github&lt;/a&gt;.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Secret Sauce - How is Pilosa Different?</title>
          <link>https://www.pilosa.com/blog/secret-sauce/</link>
          <pubDate>Tue, 12 Dec 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/secret-sauce/</guid>
          <description>&lt;p&gt;By now, most of us have heard a thousand and one pitches for data products - and
if you&amp;rsquo;re anything like me, you&amp;rsquo;ve given a few yourself.&lt;/p&gt;
&lt;p&gt;Just wading through this surplus of information software is a challenging task;
the features and abilities of each product are the summation of hundreds of tiny
technical decisions and tradeoffs on a wide, deep tree. Many of them are nearly
identical except in a few details that may only be important to very specific
use cases, for example two competing SQL databases. Others may inhabit
completely separate branches of the tree, finding common ground only at the root
such as a document store and a graph database. Some may have nearly identical
APIs, but make wildly different performance tradeoffs and so are only
appropriate for distinct workloads.&lt;/p&gt;
&lt;p&gt;Pilosa is not exempt from this sort of analysis, and it is the product of just
as many careful technical decisions and engineering tradeoffs as anything else.
However, Pilosa differs in a major way, both technically and philosophically,
from every other data product which I have encountered. In this respect, I
believe that Pilosa resides in a largely unexplored branch of the technical
decisions tree; one it found based on the existing stack that it needed to fit
into, and the constraints of the problem which it was originally designed to
solve.&lt;/p&gt;
&lt;p&gt;The thing that makes Pilosa unique in the big data landscape is that it is an
index in a very pure sense. There are other big data products (Elasticsearch
comes to mind) which claim to be indexes, and in some sense they are, but there
is a key difference. Products like Elasticsearch store all the data you put into
them - a complete copy, with all the memory, storage, and processing power that
entails. The original notion of an index, however, comes from SQL and pre-SQL
mainframe databases. In these systems, an index is an auxiliary datastructure
which is created and maintained alongside the original data for the purpose of
improving query performance. The crucial difference is that this data structure
doesn&amp;rsquo;t replicate the original dataset, it just contains pointers to it, and
because of that it&amp;rsquo;s much smaller and more manageable than a full copy of the
data.&lt;/p&gt;
&lt;p&gt;Pilosa&amp;rsquo;s functionality is analagous to this stricter definition of an index, but
instead of maintaining the data structure in memory, or on disk alongside the
original data, it makes the index a first class entity in the world of big data
and dedicates a logically separate piece of infrastructure to it.&lt;/p&gt;
&lt;p&gt;Grizzled database architects will likely balk at this notion, and indeed there
are a number of drawbacks to decoupling the index from the datastore. Increased
operational complexity, performance degredation due to IPC between components,
and consistency issues just to name a few. As we&amp;rsquo;ve seen time and again though,
there is a tipping point in scale where these tradeoffs make sense - it&amp;rsquo;s not
unlike the decision to go from one giant SQL database running dedicated, top of
the line hardware to a few dozen Cassandra nodes in the cloud. At some point,
one must scale out rather than up, and that means dealing with distributed
systems head on.&lt;/p&gt;
&lt;p&gt;Once you&amp;rsquo;ve made the leap, there are a number of clear advantages to a separated,
stand alone index:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;index data from multiple underlying stores&lt;/li&gt;
&lt;li&gt;scale independently of the data storage layer&lt;/li&gt;
&lt;li&gt;focus on speed and availability rather than consistency and durability&lt;/li&gt;
&lt;li&gt;answer many aggregation and statistical queries without ever touching the data store&lt;/li&gt;
&lt;li&gt;tune hardware and infrastructure choices in a more granular way&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Big data tech is pretty bad at indexing. There are a lot of materialized views,
denormalized tables, precomputed queries, etc. Most of these are fancy terms for
silly hacks which boil down to us having forgotten what indexes really are, and
what they&amp;rsquo;re for. Have you ever written the same data to two different cassandra
tables which just had different primary keys? Don&amp;rsquo;t. Have you ever run an
overnight batch job to update a separate set of tables which exists to serve
certain kinds of queries? Please stop. A pure index should handle these usage
patterns without storing a complete copy of the data.&lt;/p&gt;
&lt;p&gt;We posit that databases are really trying to do two jobs which are completely at
odds with one another. On one hand, a database should store your data securely
and durably - it should be persisted to disk, and preferably replicated in
multiple physical locations. On the other hand, today&amp;rsquo;s databases are also in
charge of making the data they store available and queryable in every way
imaginable as quickly as possible. These goals are difficult, and in some cases
impossible to realize simultaneously. Our vision is to separate these
responsibilities into separate tools, so that each can do one job, and do it
well.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re really just starting this journey, and there are still a lot of unanswered
questions. It isn&amp;rsquo;t always clear how to model one&amp;rsquo;s data in Pilosa, or how to
integrate it into an existing stack. If you have multiple underlying data
stores, how do you keep track of them? How do you keep Pilosa consistent with
your durable storage if it&amp;rsquo;s a separate entity? We&amp;rsquo;re working on answers to
these questions and many others over at
&lt;a href=&#34;https://github.com/pilosa&#34;&gt;github.com/pilosa&lt;/a&gt; and I invite you to come
collaborate with us. All of our public repositories are released under
permissive open source licenses, and we welcome any interaction - from questions
about how to use Pilosa, to pull requests fixing spelling mistakes, to feature
requests.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Jaffee is a lead software engineer at Pilosa. When he’s not evangelizing independent indexes, he enjoys jiu-jitsu, building mechanical keyboards, and spending time with family. Follow him on Twitter at &lt;a href=&#34;https://twitter.com/mattjaffee?lang=en&#34;&gt;@mattjaffee&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Banner photo by Caroline Attwood on Unsplash&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Real-time Data Use Case Series: Healthcare</title>
          <link>https://www.pilosa.com/blog/real-time-data-use-case-series-healthcare/</link>
          <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/real-time-data-use-case-series-healthcare/</guid>
          <description>&lt;p&gt;The big data landscape is advancing rapidly, and changing healthcare as we know it.&lt;/p&gt;
&lt;p&gt;As Artificial Intelligence (AI) and Machine Learning (ML) slide out of the shadows and into the limelight, industries must begin to contend with their &lt;a href=&#34;https://www.wsj.com/articles/how-artificial-intelligence-will-change-everything-1488856320&#34;&gt;many possibilities&lt;/a&gt; and &lt;a href=&#34;https://www.vanityfair.com/news/2017/03/elon-musk-billion-dollar-crusade-to-stop-ai-space-x&#34;&gt;potential perils&lt;/a&gt;. Before these new technologies can be employed and perfected, however, companies must learn to manage the deluge of human and machine-generated data now clogging enterprise-level datastores.&lt;/p&gt;
&lt;p&gt;So far, the it seems the data is winning: &lt;a href=&#34;https://hbr.org/2017/05/whats-your-data-strategy&#34;&gt;cross-industry studies have shown&lt;/a&gt; that less than 50% of an organization’s structured data are actively used in making decisions, and less than 1% of its unstructured data are analyzed – or even used – at all. This can be &lt;a href=&#34;http://www.healthaffairs.org/do/10.1377/hblog20150821.050034/full/&#34;&gt;particularly problematic in healthcare&lt;/a&gt;, where &lt;a href=&#34;https://insights.datamark.net/white-papers/unstructured-data-in-electronic-health-record-systems-challenges-and-solutions&#34;&gt;approximately 60%&lt;/a&gt; of valuable patient-care data is “trapped” in unstructured formats.&lt;/p&gt;
&lt;p&gt;In this first installment of our industry-level real-time data series, we will review two existing real-time data use cases that are accelerating the pace of care and delivery breakthroughs in the US Healthcare sector.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/health-use-case-1.jpg&#34; alt=&#34;Use case one header&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;use-case-1-stopping-the-spread-of-deadly-iatrogenic-infections&#34;&gt;Use Case 1: Stopping the Spread of Deadly Iatrogenic Infections&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://www.webmd.com/digestive-disorders/clostridium-difficile-colitis#1&#34;&gt;Clostridium Difficile (C. diff)&lt;/a&gt;&lt;/em&gt; is a typically harmless bacteria found throughout the environment, often colonizing the human digestive system with no ill effects. When allowed to grow unchecked, however, it can lead to serious inflammation of the colon, known as colitis, and even death. These growth events are generally rare, as competition with other, beneficial bacteria in our microbiome typically keeps C. diff’s numbers in check. One of the only times an individual is at risk for a C. diff infection is immediately after taking a course of antibiotics, which disrupts the balance of beneficial bacteria in our digestive systems.&lt;/p&gt;
&lt;p&gt;C. diff is most often spread iatrogenically within healthcare facilities, as caregivers unknowingly carry it from room to room after touching clothing, sheets, keyboards, and other surfaces. While many hospitals are able to limit the spread of C. diff through standardized sanitation measures, two units at Salem Health hospitals in Portland, Oregon, were experiencing particularly high rates of infection in 2014.&lt;/p&gt;
&lt;p&gt;Rather than go through the standard prevention measures – repeated staff sanitation trainings – Salem &lt;a href=&#34;https://hbr.org/2017/05/whats-your-data-strategy&#34;&gt;went on the offensive&lt;/a&gt;. They deployed their clinical business intelligence (CBI) team to create a real-time reporting system that allowed caregivers across two hospitals, a rehabilitation center, and nine clinics to track and compare C. diff infections across units. They &lt;a href=&#34;http://salemhealth.org/for-healthcare-professionals/common-ground/dec-26-2016/preventing-the-spread-of-c-difficile-part-2&#34;&gt;further revised&lt;/a&gt; diagnostic algorithms to ensure more efficient diagnosis, closing the gap between symptom onset and appropriate treatment. Within two years, they had dropped off of &lt;a href=&#34;https://www.consumerreports.org/doctors-hospitals/consumer-reports-names-hospitals-with-high-c-diff-infection-rates/&#34;&gt;Consumer Reports’ list&lt;/a&gt; of hospitals with abnormally high C. diff rates.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/health-use-case-2.jpg&#34; alt=&#34;Use case one header&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;use-case-2-using-missile-defense-algorithms-to-spot-sepsis&#34;&gt;Use Case 2: Using Missile Defense Algorithms to Spot Sepsis&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.webmd.com/a-to-z-guides/sepsis-septicemia-blood-infection#1&#34;&gt;Sepsis&lt;/a&gt; &lt;a href=&#34;https://www.medicinenet.com/sepsis/article.htm&#34;&gt;kills nearly 40%&lt;/a&gt; of the 750,000 people who contract it each year, costing hospitals more than $12.5 billion in care costs. Even when it is not fatal, its effects can lead to permanent mental and physical disabilities. The high mortality is due largely to the fast pace of the disease and the difficulties healthcare workers experience in spotting it early on. On the one hand, a patient’s chances of survival drop significantly for every hour they suffer from sepsis. On the other, the disease’s early stages are so similar to the flu that many caregivers do not know to administer the required antibiotic treatments in time. Further complicating the problem, current technologies used to track sepsis are largely ignored by hospital staff due to their exceptionally high error rates.&lt;/p&gt;
&lt;p&gt;Working separately, two teams of researchers have identified improved methods to identify sepsis sooner using real-time analytics. The first, out of UC Davis, analyzed patients’ EHRs to determine whether they provided better risk indicators for patients than current methods. They found that three previously unknown indicators – lactate level, blood pressure and respiratory rate – can predict the likelihood of a patient succumbing to the disease with high levels of accuracy. They are currently in the process of creating a customized algorithm for EHR systems that will automatically track these indicators and alert medical staff of a patient’s risk in real time.&lt;/p&gt;
&lt;p&gt;The second team, out of Lockheed Martin, has &lt;a href=&#34;https://www.lockheedmartin.com/us/news/features/2014/sepsis-detection.html&#34;&gt;adapted&lt;/a&gt; the company’s signature ML algorithmic platforms – currently used in missile defense – to accelerate sepsis identification. Rather than focusing on identifying additional indicators, Lockheed Martin focused on improving both the speed and accuracy of sepsis identification. They accomplished this by monitoring continuous changes in patient vital signs and blood work, rather than momentary indicators, and then deploying data analytics to flag sepsis cases. A trial that included more than 4,500 patients concluded that this method correctly identified sepsis cases more than 90% of the time and, on average, about 14 to 16 hours before the conventional approach. Further, it reduced false positives to less than 1%, making diagnosis more reliable in critical care settings.&lt;/p&gt;
&lt;p&gt;While both of these interventions are highly disease-specific, their consequences are far reaching for the future of patient health outcomes. In the short term, effectively addressing these persistent health problems will allow caregivers more time and resources to provide better care to more patients. In the long term, these methods can be improved and adapted to additional cases, benefiting countless others in the years to come.&lt;/p&gt;
&lt;p&gt;If you have any questions about how Pilosa can help your business unlock your data store for real-time queries, please feel free to &lt;a href=&#34;https://www.pilosa.com/about/#contact&#34;&gt;contact us&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ali is the resident Jack of all trades at Pilosa. She likes health and tech probably more than she should. Find her on Twitter at &lt;a href=&#34;https://twitter.com/ay_em_see?lang=en&#34;&gt;@ay_em_see&lt;/a&gt;.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Writing a Pilosa Client Library</title>
          <link>https://www.pilosa.com/blog/writing-a-client-library/</link>
          <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/writing-a-client-library/</guid>
          <description>&lt;p&gt;In this post, we will cover creating a Pilosa client library by going through the steps of writing one in Lua.&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;The Pilosa server has a nice HTTP API which makes interaction with it a breeze. Essentially, a request with one or more &lt;a href=&#34;https://www.pilosa.com/docs/latest/query-language/&#34;&gt;PQL (Pilosa Query Language)&lt;/a&gt; queries is sent to the Pilosa server and one or more results are returned. A Pilosa client library makes it easier and less error prone to encode requests and decode responses.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.lua.org&#34;&gt;Lua&lt;/a&gt; is an embeddable scripting language which is very prevalent among game programmers due to its expressiveness, simplicity and ease of interoperability with C and C++. It is also supported by Nginx.&lt;/p&gt;
&lt;p&gt;In this article, we are going to write a Pilosa client library in Lua. Although our sample library won&amp;rsquo;t have all of the features of official client libraries, we will cover the fundamentals and have a base to improve upon. Even if you are not interested in creating a client library, you may find it useful to explore the sample client.&lt;/p&gt;
&lt;p&gt;Before delving into client library design, let&amp;rsquo;s have a quick glance at the current official libraries for Pilosa.&lt;/p&gt;
&lt;h3 id=&#34;client-libraries-overview&#34;&gt;Client Libraries Overview&lt;/h3&gt;
&lt;p&gt;Our primary target is UNIX-like platforms, but our clients run very well on Windows too. Currently we have three official client libraries written in Go, Python and Java.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Go client is at &lt;a href=&#34;https://github.com/pilosa/go-pilosa&#34;&gt;https://github.com/pilosa/go-pilosa&lt;/a&gt;. We support Go 1.8 and up.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Our Java client is at &lt;a href=&#34;https://github.com/pilosa/java-pilosa&#34;&gt;https://github.com/pilosa/java-pilosa&lt;/a&gt;. Java 7 and up is supported. We use Maven as our build and packaging system, so it is available to most JVM based projects and languages like Scala, Clojure and Kotlin.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Python client is at &lt;a href=&#34;https://github.com/pilosa/python-pilosa&#34;&gt;https://github.com/pilosa/python-pilosa&lt;/a&gt; and supports Python 2.7 and Python 3.4 and up. The Python client library is also available on &lt;a href=&#34;https://pypi.python.org/pypi&#34;&gt;PYPI&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;getting-ready&#34;&gt;Getting Ready&lt;/h3&gt;
&lt;p&gt;For the purposes of this post, we will assume you&amp;rsquo;re on a UNIX-like platform such as Linux, MacOS or using &lt;a href=&#34;https://msdn.microsoft.com/en-us/commandline/wsl/about&#34;&gt;Windows Subsystem for Linux (WSL)&lt;/a&gt;. If you are on another platform, adapt the instructions to your particular platform.&lt;/p&gt;
&lt;p&gt;Throughout this article, we will need to run queries against the Pilosa server, so let&amp;rsquo;s go ahead and launch a new Pilosa server instance. We provide &lt;a href=&#34;https://github.com/pilosa/pilosa/releases&#34;&gt;precompiled binaries&lt;/a&gt; for MacOS and Linux (works on WSL too), a &lt;a href=&#34;http://brewformulas.org/Pilosa&#34;&gt;Homebrew package&lt;/a&gt; for MacOS and a &lt;a href=&#34;https://hub.docker.com/r/pilosa/pilosa/&#34;&gt;docker image&lt;/a&gt;. See our documentation on &lt;a href=&#34;https://www.pilosa.com/docs/latest/installation/&#34;&gt;acquiring and installing Pilosa&lt;/a&gt; and &lt;a href=&#34;https://www.pilosa.com/docs/latest/getting-started/#starting-pilosa&#34;&gt;starting Pilosa&lt;/a&gt; if you need help installing Pilosa. We&amp;rsquo;ll assume Pilosa is running on the default address with the default scheme at &lt;code&gt;http://localhost:10101&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;While writing the new client library, we will need to run requests against Pilosa and analyze the responses. &lt;a href=&#34;https://curl.haxx.se&#34;&gt;curl&lt;/a&gt; is probably the most popular tool for calling HTTP endpoints. It is usually preinstalled (or easily installable) in many UNIX-like platforms. Let&amp;rsquo;s confirm that Pilosa is running and curl is installed. In a terminal, execute the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://localhost:10101/version
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should get a response similar to the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;version&amp;quot;:&amp;quot;v0.7.1&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you get the &lt;code&gt;localhost port 10101: Connection refused&lt;/code&gt; error, make sure Pilosa is running on the default address.&lt;/p&gt;
&lt;p&gt;Since we are going to write our client library in &lt;a href=&#34;https://www.lua.org&#34;&gt;Lua&lt;/a&gt; we need to install Lua. But which version? When it comes to versioning, Lua takes a different stance than many mainstream languages, and the latest main release may not be compatible with earlier main releases. Version 5.1 seems to be the most supported version in the Lua community so we will target it for this client library.&lt;/p&gt;
&lt;p&gt;Although Lua 5.1 is available with most package managers for UNIX-like platforms and it&amp;rsquo;s easy to compile, it&amp;rsquo;s most convenient to use the Python based &lt;a href=&#34;https://github.com/mpeterv/hererocks&#34;&gt;Hererocks&lt;/a&gt; script to install it. Hererocks requires a compiler to compile Lua, so install one if you didn&amp;rsquo;t already do so. Clang for MacOS, Visual Studio for Windows, and GCC for Linux, WSL and other UNIX-like platforms works great. The following command creates a Lua 5.1 virtual environment with the latest LuaRocks and activates it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python hererocks.py lua5.1 -l5.1 -rlatest
source lua5.1/bin/activate
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Run &lt;code&gt;lua -v&lt;/code&gt; to confirm that the virtual environment was created with the correct Lua version.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://luarocks.org&#34;&gt;LuaRocks&lt;/a&gt; is the defacto package manager for Lua. We are going to use it to install dependencies of our example client library. If you are using Hererocks then LuaRocks will already be installed in your virtual environment, otherwise make sure to install it.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s install the dependencies for our client library:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;luarocks install luasocket
luarocks install busted
luarocks install luacov
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;LuaSocket provides the internal HTTP client we are going to use in our library. There are other, more advanced HTTP libraries for Lua, but their Windows support is not as good. Busted is a popular testing framework. It can use Luacov for generating a test coverage report.&lt;/p&gt;
&lt;p&gt;The final project is at the &lt;a href=&#34;https://github.com/pilosa/lua-pilosa&#34;&gt;Lua Client repository&lt;/a&gt;. We are going to use the following layout for our client library project:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lua-pilosa/
    pilosa/
    integration-tests/
    tests/
    .travis.yml
    LICENSE
    Makefile
    README.md
    make.cmd
    pilosa-0.1.0-1.rockspec
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We use the &lt;code&gt;LANGUAGE-pilosa&lt;/code&gt; convention when naming client libraries at Pilosa. The library code is in the &lt;code&gt;pilosa&lt;/code&gt; directory, unit tests are in &lt;code&gt;tests&lt;/code&gt; and integration tests are (predictably) in &lt;code&gt;integration-tests&lt;/code&gt;. &lt;code&gt;pilosa-0.1.0-1.rockspec&lt;/code&gt; is the package definition file for LuaRocks. &lt;code&gt;.travis.yml&lt;/code&gt; is the confiration file for Travis CI.&lt;/p&gt;
&lt;h4 id=&#34;creating-a-makefile&#34;&gt;Creating a Makefile&lt;/h4&gt;
&lt;p&gt;It&amp;rsquo;s convenient to be able to use the same commands to execute tasks for all client libraries. All official Pilosa client library projects use a &lt;code&gt;Makefile&lt;/code&gt; (or its Windows equivalent &lt;code&gt;make.cmd&lt;/code&gt;) which has the same targets to accomplish the same task.&lt;/p&gt;
&lt;p&gt;We are going to create a trivial &lt;code&gt;Makefile&lt;/code&gt; for our client library with the following targets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;test&lt;/code&gt;: Runs unit tests.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test-all&lt;/code&gt;: Runs both unit tests and integration tests.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cover&lt;/code&gt;: Runs all tests with coverage.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-Makefile&#34; data-lang=&#34;Makefile&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;.PHONY&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; cover test test-all

&lt;span style=&#34;color:#a6e22e&#34;&gt;test&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;
	busted tests

&lt;span style=&#34;color:#a6e22e&#34;&gt;test-all&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;
	busted tests integration-tests

&lt;span style=&#34;color:#a6e22e&#34;&gt;cover&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; luacov.report.out
	cat luacov.report.out

&lt;span style=&#34;color:#a6e22e&#34;&gt;luacov.report.out&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; luacov.stats.out
	luacov pilosa/*.lua

&lt;span style=&#34;color:#a6e22e&#34;&gt;luacov.stats.out&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;
	busted --coverage tests integration-tests
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can see the equivalent &lt;code&gt;make.cmd&lt;/code&gt; &lt;a href=&#34;https://github.com/pilosa/lua-pilosa/blob/master/make.cmd&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We won&amp;rsquo;t use any other targets for this client, but official Pilosa clients make use of the following extra targets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;generate&lt;/code&gt;: Creates the protobuf encoder/decoder from definition files.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;release&lt;/code&gt;: Uploads the client library to the corresponding package manager.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;doc&lt;/code&gt;: Creates the documentation.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;build&lt;/code&gt;: Builds the client library.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;a-note-on-class-definitions&#34;&gt;A Note on Class Definitions&lt;/h4&gt;
&lt;p&gt;Although we design our client library around &lt;em&gt;classes&lt;/em&gt;, Lua doesn&amp;rsquo;t have the concept of a &lt;em&gt;class&lt;/em&gt;. Instead, it emulates object orientation through the use of &lt;em&gt;metatables&lt;/em&gt; and some syntactic sugar.&lt;/p&gt;
&lt;p&gt;For example, we would define the &lt;code&gt;Schema&lt;/code&gt; &lt;em&gt;class&lt;/em&gt; as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Schema&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; self &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; setmetatable({}, Schema)
    self.indexes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; self
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Schema&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;index&lt;/span&gt;(name)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; Index(name)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;-- Create a Schema instance&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; schema &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Schema.new()
&lt;span style=&#34;color:#75715e&#34;&gt;-- Note that we use a column instead of a dot.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;-- This is equivalent to: local myIndex = schema.index(schema, &amp;#34;my-index&amp;#34;)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; myIndex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; schema:index(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my-index&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;How to create a class is not obvious unless you are a Lua programmer, so we use the &lt;em&gt;Lua Classic&lt;/em&gt; module in &lt;code&gt;pilosa/classic.lua&lt;/code&gt; to make our classes more familiar. The &lt;code&gt;Schema&lt;/code&gt; class can be re-defined as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; Object &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pilosa.classic&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; Schema &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Object:extend()

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Schema&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;()
    self.indexes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Schema&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;index&lt;/span&gt;(name)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; Index(name)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;-- We don&amp;#39;t call new() explicitly anymore&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; schema &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Schema()
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; myIndex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; schema:index(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my-index&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;orm&#34;&gt;ORM&lt;/h3&gt;
&lt;p&gt;The ORM component provides an API to form PQL (Pilosa Query Language) queries. The advantage of using the ORM against raw queries is that it is usually less verbose and less error prone. Also, parameters are validated on the client side which allows us to catch validation related errors earlier.&lt;/p&gt;
&lt;p&gt;We are going put the ORM related code in &lt;code&gt;pilosa/orm.lua&lt;/code&gt;. Let&amp;rsquo;s start with defining &lt;code&gt;PQLQuery&lt;/code&gt; which contains a PQL query as well as the index that the query is to be executed against. &lt;code&gt;PQLQuery&lt;/code&gt; constructor receives the &lt;code&gt;index&lt;/code&gt; of type &lt;code&gt;Index&lt;/code&gt; (to be defined a bit further) and &lt;code&gt;pql&lt;/code&gt; of type string:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PQLQuery&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(index, pql)
    self.pql &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pql
    self.index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; index
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PQLQuery&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;serialize&lt;/span&gt;()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; self.pql
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The user is not supposed to create &lt;code&gt;PQLQuery&lt;/code&gt; instances directly. Instead the &lt;code&gt;Index&lt;/code&gt; class is going to have helper methods to create them.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;serialize&lt;/code&gt; method returns the query as a string.&lt;/p&gt;
&lt;p&gt;Pilosa supports many queries in the same request, which cuts down the number of HTTP calls and improves throughput. Let&amp;rsquo;s create the slightly more advanced &lt;code&gt;PQLBatchQuery&lt;/code&gt; class which keeps one or more PQL statements. &lt;code&gt;PQLBatchQuery&lt;/code&gt; implements the same interface as &lt;code&gt;PQLQuery&lt;/code&gt;, so it is usable anywhere a &lt;code&gt;PQLQuery&lt;/code&gt; is expected:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PQLBatchQuery&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(index, ...)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; queries &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, v &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; ipairs(arg) &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
        table.insert(queries, v:serialize())
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    self.queries &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; queries
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PQLBatchQuery&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;add&lt;/span&gt;(query)
    table.insert(self.queries, query:serialize())
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PQLBatchQuery&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;serialize&lt;/span&gt;()
    &lt;span style=&#34;color:#75715e&#34;&gt;-- concatenate serialized queries as a string&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; table.concat(self.queries)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The ORM hierarchy starts with the &lt;code&gt;Schema&lt;/code&gt; class, which is used to create and cache &lt;code&gt;Index&lt;/code&gt; objects:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Schema&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;()
    self.indexes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Schema&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;index&lt;/span&gt;(name)
    index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self.indexes[name]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Index(name)
        self.indexes[name] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; index
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; index
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A &lt;code&gt;Schema&lt;/code&gt; object can be instantiated directly, but usually the user loads the schema from the Pilosa server:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- create a schema&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; schema1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Schema()
&lt;span style=&#34;color:#75715e&#34;&gt;-- load a schema&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; schema2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; client.schema()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the user has a &lt;code&gt;Schema&lt;/code&gt; object she can create &lt;code&gt;Index&lt;/code&gt; instances. Note that the changes in the ORM side aren&amp;rsquo;t persisted until the user explicitly synchronizes the schema with the Pilosa server using &lt;code&gt;client.syncSchema(schema)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define the &lt;code&gt;Index&lt;/code&gt; class:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Index&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(name)
    validator.ensureValidIndexName(name)
    self.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; name
    &lt;span style=&#34;color:#75715e&#34;&gt;-- frames is a weak table&lt;/span&gt;
    self.frames &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    setmetatable(self.frames, { __mode &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;v&amp;#34;&lt;/span&gt; })
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Index&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;frame&lt;/span&gt;(name, options)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; frame &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self.frames[name]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; frame &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        frame &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Frame(self, name, options)
        self.frames[name] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; frame
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; frame
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;Index&lt;/code&gt; object keeps a cache of frames. The &lt;code&gt;frame&lt;/code&gt; method creates a new &lt;code&gt;Frame&lt;/code&gt; object or returns an already existing &lt;code&gt;Frame&lt;/code&gt; object. We should be careful when caching &lt;code&gt;Frame&lt;/code&gt; objects, since &lt;code&gt;Frame&lt;/code&gt; objects have to keep a reference to their parent &lt;code&gt;Index&lt;/code&gt; object. This creates a circular reference and that can be problematic for languages with a reference counting memory management scheme.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s add a few methods to &lt;code&gt;Index&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Index&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;rawQuery&lt;/span&gt;(query)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; PQLQuery(self, query)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Index&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;batchQuery&lt;/span&gt;(...)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; PQLBatchQuery(self, unpack(arg))
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Index&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;union&lt;/span&gt;(...)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; bitmapOp(self, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Union&amp;#34;&lt;/span&gt;, unpack(arg))
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;-- ... SNIP ... --&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bitmapOp&lt;/span&gt;(index, name, ...)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; serializedArgs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, a &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; ipairs(arg) &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
        table.insert(serializedArgs, a:serialize())
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; pql &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%s(%s)&amp;#34;&lt;/span&gt;, name, table.concat(serializedArgs, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;, &amp;#34;&lt;/span&gt;))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; PQLQuery(index, pql)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;rawQuery&lt;/code&gt; allows the user to send any string to the Pilosa server as a query and &lt;code&gt;batchQuery&lt;/code&gt; creates a &lt;code&gt;PQLBatchQuery&lt;/code&gt; object with the given queries passed as arguments.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;union&lt;/code&gt; method creates a &lt;code&gt;Union&lt;/code&gt; query with the given bitmap queries. It calls the &lt;code&gt;bitmapOp&lt;/code&gt; helper function to create the query. &lt;code&gt;intersect&lt;/code&gt;, &lt;code&gt;difference&lt;/code&gt; and &lt;code&gt;xor&lt;/code&gt; methods are defined similarly.&lt;/p&gt;
&lt;p&gt;Next up, the &lt;code&gt;Frame&lt;/code&gt; class:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Frame&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(index, name, options)
    validator.ensureValidFrameName(name)
    self.index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; index
    self.name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; name
    options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; {}
    self.options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
        timeQuantum &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options.timeQuantum &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; TimeQuantum.NONE,
        inverseEnabled &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options.inverseEnabled &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;,
        cacheType &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options.cacheType &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; CacheType.DEFAULT,
        cacheSize &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options.cacheSize &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    }
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;TimeQuantum&lt;/code&gt; and &lt;code&gt;CacheType&lt;/code&gt; contain string values accepted by the Pilosa server:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; TimeQuantum &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
    NONE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;,
    YEAR &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Y&amp;#34;&lt;/span&gt;,
    MONTH &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;M&amp;#34;&lt;/span&gt;,
    DAY &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;D&amp;#34;&lt;/span&gt;,
    HOUR &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;H&amp;#34;&lt;/span&gt;,
    YEAR_MONTH &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;YM&amp;#34;&lt;/span&gt;,
    MONTH_DAY &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MD&amp;#34;&lt;/span&gt;,
    DAY_HOUR &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DH&amp;#34;&lt;/span&gt;,
    YEAR_MONTH_DAY &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;YMD&amp;#34;&lt;/span&gt;,
    MONTH_DAY_HOUR &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MDH&amp;#34;&lt;/span&gt;,
    YEAR_MONTH_DAY_HOUR &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;YMDH&amp;#34;&lt;/span&gt;
}

&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; CacheType &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
    DEFAULT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;,
    LRU &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lru&amp;#34;&lt;/span&gt;,
    RANKED &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ranked&amp;#34;&lt;/span&gt;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The Frame constructor stores the frame&amp;rsquo;s name, its parent index, and any available frame options. Next, a few methods which implement queries that work on frames:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Frame&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;bitmap&lt;/span&gt;(rowID)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; query &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Bitmap(rowID=%d, frame=&amp;#39;%s&amp;#39;)&amp;#34;&lt;/span&gt;, rowID, self.name)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; PQLQuery(self.index, query)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Frame&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;setbit&lt;/span&gt;(rowID, columnID, timestamp)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; ts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; timestamp &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        ts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;, timestamp=&amp;#39;%s&amp;#39;&amp;#34;&lt;/span&gt;, os.date(TIME_FORMAT, timestamp))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; query &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SetBit(rowID=%d, frame=&amp;#39;%s&amp;#39;, columnID=%d%s)&amp;#34;&lt;/span&gt;, rowID, self.name, columnID, ts)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; PQLQuery(self.index, query)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Frame&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;inverseBitmap&lt;/span&gt;(columnID)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; query &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Bitmap(columnID=%d, frame=&amp;#39;%s&amp;#39;)&amp;#34;&lt;/span&gt;, columnID, self.name)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; PQLQuery(self.index, query)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s give a try our ORM classes. We define the schema first:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; schema &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Schema()
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; index1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; schema:index(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;index1&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; frame1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; index1:frame(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;frame1&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Below is the code which creates the equivalent of the PQL query &lt;code&gt;Intersect(Bitmap(frame=&amp;quot;frame1&amp;quot;, rowID=10), Bitmap(frame=&amp;quot;frame1&amp;quot;, rowID=20))&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; query &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; index1:intersect(frame1:bitmap(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;), frame1:bitmap(&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Pretty straightforward. You can check out the rest of &lt;a href=&#34;https://github.com/pilosa/lua-pilosa/blob/master/pilosa/orm.lua&#34;&gt;pilosa/orm.lua&lt;/a&gt; file &lt;a href=&#34;https://github.com/pilosa/lua-pilosa/blob/master/pilosa/orm.lua&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;client&#34;&gt;Client&lt;/h3&gt;
&lt;p&gt;A Pilosa URI (Uniform Resource Identifier) represents the address of a Pilosa node. It consists of three parts: scheme, host and port. &lt;code&gt;https://index2.pilosa.com:10501&lt;/code&gt; is a sample URI which points to the Pilosa node running at host &lt;code&gt;index2.pilosa.com&lt;/code&gt; port &lt;code&gt;10501&lt;/code&gt; and which uses the &lt;code&gt;https&lt;/code&gt; scheme. All parts of a Pilosa URI are optional, but at least one of the parts should be specified. The following URIs are equivalent:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;http://localhost:10101&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http://:10101&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;localhost:10101&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;localhost&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;:10101&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Lua code below defines the &lt;code&gt;URI&lt;/code&gt; class which keeps a Pilosa URI. It lets us write &lt;code&gt;https://index2.pilosa.com:10501&lt;/code&gt; as &lt;code&gt;URI(&amp;quot;https&amp;quot;, &amp;quot;index2.pilosa.com&amp;quot;, 10501)&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; DEFAULT_SCHEME &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; DEFAULT_HOST &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; DEFAULT_PORT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10101&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;URI&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(scheme, host, port)
    self.scheme &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; scheme
    self.host &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; host
    self.port &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; port
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;URI&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;default&lt;/span&gt;()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; URI(DEFAULT_SCHEME, DEFAULT_HOST, DEFAULT_PORT)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Generally, it is much more convenient to use a Pilosa URI as is. We can easily parse a string address and convert it to a Pilosa URI:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;URI&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;address&lt;/span&gt;(address)
    scheme, host, port &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; parseAddress(address)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; URI(scheme, host, port)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following regular expression captures all parts of a valid Pilosa URI and is used in all official client libraries:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;^(([+a-z]+)://)?([0-9a-z.-]+)?(:([0-9]+))?$
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Unfortunately Lua&amp;rsquo;s regular expressions support is not as powerful to capture all groups in that regular expression, so each combination of URI parts should be checked separately. Below are regular expressions which should be checked from top to bottom until a match is found:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; PATTERN_SCHEME_HOST_PORT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;^([+a-z]+)://([0-9a-z.-]+):([0-9]+)$&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; PATTERN_SCHEME_HOST &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;^([+a-z]+)://([0-9a-z.-]+)$&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; PATTERN_SCHEME_PORT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;^([+a-z]+)://:([0-9]+)$&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; PATTERN_HOST_PORT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;^([0-9a-z.-]+):([0-9]+)$&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; PATTERN_SCHEME &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;^([+a-z]+)://$&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; PATTERN_PORT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;^:([0-9]+)$&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; PATTERN_HOST &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;^([0-9a-z.-]+)$&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With those regular expressions defined, we can code &lt;code&gt;parseAddress&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;parseAddress&lt;/span&gt;(address)
    scheme, host, port &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.match(address, PATTERN_SCHEME_HOST_PORT)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; scheme &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; host &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; port &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; scheme, host, tonumber(port)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    
    scheme, host &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.match(address, PATTERN_SCHEME_HOST)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; scheme &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; host &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; scheme, host, DEFAULT_PORT
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;-- ... SNIP ... --&lt;/span&gt;

    host &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.match(address, PATTERN_HOST)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; host &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; DEFAULT_SCHEME, host, DEFAULT_PORT
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

    error(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Not a Pilosa URI&amp;#34;&lt;/span&gt;)    
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Lastly, we want to convert a &lt;code&gt;URI&lt;/code&gt; to a string in a format to be passed to the internal HTTP client. We call that method &lt;code&gt;normalize&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;URI&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;normalize&lt;/span&gt;()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%s://%s:%d&amp;#34;&lt;/span&gt;, self.scheme, self.host, self.port)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Pilosa server supports HTTP requests with JSON or &lt;a href=&#34;https://github.com/google/protobuf&#34;&gt;protobuf&lt;/a&gt; payload for querying, and HTTP requests with JSON payload for other endpoints. It is usually more efficient to encode/decode protobuf payloads but JSON support is more prevalent. Although  all of Pilosa&amp;rsquo;s official client libraries use protobuf payloads for querying,  we will use JSON payloads for this client library.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Content-Type&lt;/code&gt; and &lt;code&gt;Accept&lt;/code&gt; are two HTTP headers which tell the Pilosa server the type of the payload for requests and responses respectively. Most of the endpoints of Pilosa server don&amp;rsquo;t require explicitly setting those endpoints and default to &lt;code&gt;application/json&lt;/code&gt; but we are going to set them anyway in case the default changes in a future release.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s create the &lt;code&gt;PilosaClient&lt;/code&gt; class:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PilosaClient&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(uri, options)
    self.uri &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; uri &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; URI:default()
    self.options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; {}
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Most Pilosa clients can be initialized with a Pilosa URI or URIs of a cluster. But to keep things a bit simpler, we are going to assign a single URI to the client. If the user doesn&amp;rsquo;t supply a URI or options, we simply use the defaults.&lt;/p&gt;
&lt;p&gt;The actual request to a Pilosa server is not accomplished by the &lt;code&gt;PilosaClient&lt;/code&gt; itself, but rather by an underlying HTTP library which we&amp;rsquo;ll refer to as the internal HTTP client. The internal client library we use for this project doesn&amp;rsquo;t support advanced features such as connection pooling.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s write a generic method to call Pilosa which we are going to use shortly:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;httpRequest&lt;/span&gt;(client, method, path, data)
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%s%s&amp;#34;&lt;/span&gt;, client.uri:normalize(), path)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; chunks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}

    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; r, status &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; http.request{
        url&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;url,
        method&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;method,
        source&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ltn12.source.string(data),
        sink&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ltn12.sink.table(chunks),
        headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;getHeaders(data)
    }

    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; r &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;-- status contains the error string&lt;/span&gt;
        error({error&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;status, code&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;})
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; table.concat(chunks)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; status &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; status &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        error({error&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;response, code&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;status})
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; response
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;httpRequest&lt;/code&gt; function receives a &lt;code&gt;PilosaClient&lt;/code&gt; object, and the method, path and optionally the data for a request. It returns a string response. LuaSocket has the concept of sources and sinks. &lt;code&gt;http.request&lt;/code&gt; function reads from a source and saves the response to the sink in chunks. We build the response by concatenating those chunks.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;getHeaders&lt;/code&gt; function is trivially defined as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getHeaders&lt;/span&gt;(data)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; {
        &lt;span style=&#34;color:#75715e&#34;&gt;-- Content Length is the size of the data&lt;/span&gt;
        [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content-length&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;data,
        [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content-type&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;application/json&amp;#34;&lt;/span&gt;,
        [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;accept&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;application/json&amp;#34;&lt;/span&gt;
    }
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;All Pilosa queries require specifying an index, so let&amp;rsquo;s try to create one with default options using &lt;code&gt;curl&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:10101/index/sample-index -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Accept: application/json&amp;quot; -d &#39;&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs &lt;code&gt;{}&lt;/code&gt; which indicates that the index was created successfully. If you run the command above again, you will get the &lt;code&gt;index already exists&lt;/code&gt; error with the &lt;code&gt;409 Conflict&lt;/code&gt; status.&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;httpRequest&lt;/code&gt; function we defined above, we can define the &lt;code&gt;createIndex&lt;/code&gt; method of the &lt;code&gt;PilosaClient&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PilosaClient&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;createIndex&lt;/span&gt;(index)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/index/%s&amp;#34;&lt;/span&gt;, index.name)
    httpRequest(self, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POST&amp;#34;&lt;/span&gt;, path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{}&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This method just encodes index options as the payload and creates the HTTP path using the index name.&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;createIndex&lt;/code&gt; method is called with an index, it will create the index on the server side if it doesn&amp;rsquo;t already exist. If it does exist, it will raise an error. It would be convenient to have a method which would be more forgiving when trying to create an existing index. Let&amp;rsquo;s call that method &lt;code&gt;ensureIndex&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; HTTP_CONFLICT &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;409&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PilosaClient&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;ensureIndex&lt;/span&gt;(index)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; response, err &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pcall(&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;() self:createIndex(index) &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; err &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; err.code &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; HTTP_CONFLICT &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        error(err)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Frames can have options attached to them, so &lt;code&gt;createFrame&lt;/code&gt; has to POST those options in the request body: &lt;code&gt;{&amp;quot;options&amp;quot;: { ... }}&lt;/code&gt;. &lt;code&gt;createFrame&lt;/code&gt; is defined as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PilosaClient&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;createFrame&lt;/span&gt;(frame)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; frame.options}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/index/%s/frame/%s&amp;#34;&lt;/span&gt;, frame.index.name, frame.name)
    httpRequest(self, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POST&amp;#34;&lt;/span&gt;, path, json.encode(data))
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The most important method of our &lt;code&gt;PilosaClient&lt;/code&gt; class is &lt;code&gt;query&lt;/code&gt;, which serializes the ORM query we pass and returns a response. It is defined below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; QueryResponse &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; require &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pilosa.response&amp;#34;&lt;/span&gt;.QueryResponse

&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PilosaClient&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;query&lt;/span&gt;(query, options)
    options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; QueryOptions(options)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; query:serialize()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/index/%s/query%s&amp;#34;&lt;/span&gt;, query.index.name, options:encode())
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; httpRequest(self, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POST&amp;#34;&lt;/span&gt;, path, data)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; QueryResponse(response)
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;query&lt;/code&gt; method can optionally take a few query options. The user would pass those query options as a table, and we convert it to a &lt;code&gt;QueryOptions&lt;/code&gt; object which is defined below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;QueryOptions&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(options)
    options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; {}
    self.options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
        columnAttrs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options.columnAttributes &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;,
        excludeAttrs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options.excludeAttributes &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;,
        excludeBits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; options.excludeBits &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;
    }
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With the &lt;code&gt;PilosaClient&lt;/code&gt; class defined, the user can run queries similar to the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; query &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; myFrame:bitmap(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; client &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PilosaClient(URI:default())
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; client:query(query, {excludeAttributes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The rest of &lt;a href=&#34;https://github.com/pilosa/lua-pilosa/blob/master/pilosa/client.lua&#34;&gt;pilosa/client.lua&lt;/a&gt; is &lt;a href=&#34;https://github.com/pilosa/lua-pilosa/blob/master/pilosa/client.lua&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;response&#34;&gt;Response&lt;/h3&gt;
&lt;p&gt;The response from the Pilosa server for a query request may be in JSON or protobuf, depending on the &lt;code&gt;Accept&lt;/code&gt; header in the HTTP request. The number of results in the response is the same as the number of PQL statements in the query request. Results in a response encoded in protobuf have the same structure with different values for fields. On the other hand, for JSON responses, the structure of a result depends on the corresponding PQL query.&lt;/p&gt;
&lt;p&gt;Since we opted for the JSON payloads for queries, let&amp;rsquo;s try a few queries using &lt;code&gt;curl&lt;/code&gt; and check the responses.&lt;/p&gt;
&lt;p&gt;We need to create the index and frame first:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:10101/index/test-index -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Accept: application/json&amp;quot; -d &#39;&#39;
curl -X POST http://localhost:10101/index/test-index/frame/test-frame -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Accept: application/json&amp;quot; -d &#39;{&amp;quot;options&amp;quot;:{&amp;quot;inverseEnabled&amp;quot;:true}}&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s see what we get back for the &lt;code&gt;SetBit&lt;/code&gt; query:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:10101/index/test-index/query -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Accept: application/json&amp;quot; -d &#39;SetBit(frame=&amp;quot;test-frame&amp;quot;,rowID=5, columnID=100)&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs: &lt;code&gt;{&amp;quot;results&amp;quot;:[true]}&lt;/code&gt;. &lt;code&gt;SetBit&lt;/code&gt; and &lt;code&gt;ClearBit&lt;/code&gt; returns a boolean value, representing whether a bit was set or cleared.&lt;/p&gt;
&lt;p&gt;Now the &lt;code&gt;SetRowAttrs&lt;/code&gt; query:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:10101/index/test-index/query -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Accept: application/json&amp;quot; -d &#39;SetRowAttrs(frame=&amp;quot;test-frame&amp;quot;,rowID=5, attr1=1, attr2=&amp;quot;foo&amp;quot;, attr3=true)&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs: &lt;code&gt;{&amp;quot;results&amp;quot;:[null]}&lt;/code&gt;. &lt;code&gt;SetRowAttrs&lt;/code&gt; and &lt;code&gt;SetColumnAttrs&lt;/code&gt; always return &lt;code&gt;null&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;How about the &lt;code&gt;Bitmap&lt;/code&gt; query?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:10101/index/test-index/query -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Accept: application/json&amp;quot; -d &#39;Bitmap(frame=&amp;quot;test-frame&amp;quot;,rowID=5)&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs: &lt;code&gt;{&amp;quot;results&amp;quot;:[{&amp;quot;attrs&amp;quot;:{&amp;quot;attr1&amp;quot;:1,&amp;quot;attr2&amp;quot;:&amp;quot;foo&amp;quot;,&amp;quot;attr3&amp;quot;:true},&amp;quot;bits&amp;quot;:[100]}]}&lt;/code&gt;. The result for a &lt;code&gt;Bitmap&lt;/code&gt; query includes the &lt;code&gt;attrs&lt;/code&gt; map if there are any attributes set for the specified row, and the &lt;code&gt;bits&lt;/code&gt; array which contains the columns for the row.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s try a &lt;code&gt;TopN&lt;/code&gt; query:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:10101/index/test-index/query -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Accept: application/json&amp;quot; -d &#39;TopN(frame=&amp;quot;test-frame&amp;quot;)&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs: &lt;code&gt;{&amp;quot;results&amp;quot;:[[{&amp;quot;id&amp;quot;:5,&amp;quot;count&amp;quot;:1}]]}&lt;/code&gt;. The result is a list of count result items composed of a rowID and the count of bits set.&lt;/p&gt;
&lt;p&gt;Next up, the &lt;code&gt;Count&lt;/code&gt; query:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:10101/index/test-index/query -H &amp;quot;Content-Type: application/json&amp;quot; -H &amp;quot;Accept: application/json&amp;quot; -d &#39;Count(Bitmap(frame=&amp;quot;test-frame&amp;quot;,rowID=5))&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Outputs: &lt;code&gt;{&amp;quot;results&amp;quot;:[1]}&lt;/code&gt;, which is the number of bits set for the given row.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define the &lt;code&gt;QueryResponse&lt;/code&gt; class in &lt;code&gt;pilosa/response.lua&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;QueryResponse&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(response)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; jsonResponse &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; json.decode(response)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; jsonResponse[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;results&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, result &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; ipairs(jsonResponse[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;results&amp;#34;&lt;/span&gt;]) &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
            table.insert(results, QueryResult(result))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    self.results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; results
    self.result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; results[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The constructor of &lt;code&gt;QueryResponse&lt;/code&gt; receives a string response and decodes it. It then extracts the results and stores them in the &lt;code&gt;results&lt;/code&gt; property. It is convenient to access a result directly when it is the only one. So we set the &lt;code&gt;result&lt;/code&gt; property as the first result.&lt;/p&gt;
&lt;p&gt;As we have seen above, a result may contain different fields depending on the corresponding query. &lt;code&gt;QueryResult&lt;/code&gt; class consolidates those fields in a single data structure. Unset fields have a default value.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;QueryResult&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(result)
    &lt;span style=&#34;color:#75715e&#34;&gt;-- SetBit and ClearBit returns boolean values. We currently do not store them in the response.&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; result &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;
        result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; result &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; {}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Queries such as Bitmap, Union, etc. return bitmap results&lt;/span&gt;
    self.bitmap &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BitmapResult(result)
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Count and Sum queries return the count&lt;/span&gt;
    self.count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; result.count &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- Sum query returns the sum&lt;/span&gt;
    self.sum &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; result.sum &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;-- TopN returns a list of (ID, count) pairs. We call each of them count result item.&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; countItems &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; result[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;].id &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; result[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;].count &lt;span style=&#34;color:#f92672&#34;&gt;~=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, item &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; ipairs(result) &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
            table.insert(countItems, CountResultItem(item))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    self.countItems &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; countItems
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Queries such as Bitmap, Union, etc. return bitmap results. A bitmap result contains the bits set for the corresponding row or column and the attributes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;BitmapResult&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(result)
    self.bits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; result.bits &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; {}
    self.attributes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; result.attrs &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; {}
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;TopN&lt;/code&gt; queries return a list of (ID, count) pairs. We call each of them a count result item. The &lt;code&gt;CountResultItem&lt;/code&gt; is defined below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;CountResultItem&lt;/span&gt;:&lt;span style=&#34;color:#a6e22e&#34;&gt;new&lt;/span&gt;(id, count)
    self.id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; id
    self.count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; count
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here&amp;rsquo;s how our users would retrieve results from a response:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; query &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; myFrame:bitmap(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; client &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PilosaClient(URI:default())
&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; client:query(query)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, result &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; ipairs(response.results) &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt;
    print(string.format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;There are %d bits in result %d&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;result.bitmap.bits, i))
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; bitmapResult &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; response.result.bitmap
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Rest of &lt;a href=&#34;https://github.com/pilosa/lua-pilosa/blob/master/pilosa/response.lua&#34;&gt;pilosa/response.lua&lt;/a&gt; is &lt;a href=&#34;https://github.com/pilosa/lua-pilosa/blob/master/pilosa/response.lua&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;testing&#34;&gt;Testing&lt;/h3&gt;
&lt;p&gt;It&amp;rsquo;s a good idea to separate unit tests from integration tests since integration tests depend on a running Pilosa server, and may take longer to complete. Our &lt;code&gt;Makefile&lt;/code&gt; contains two targets for testing, &lt;code&gt;make test&lt;/code&gt; runs unit tests and &lt;code&gt;make test-all&lt;/code&gt; runs both unit and integration tests.&lt;/p&gt;
&lt;p&gt;Integration tests require the Pilosa server to be running on the default address, but you can change it using the &lt;code&gt;PILOSA_BIND&lt;/code&gt; environment variable.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getClient&lt;/span&gt;()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; serverAddress &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os.getenv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PILOSA_BIND&amp;#34;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; serverAddress &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;then&lt;/span&gt;
        serverAddress &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://localhost:10101&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; PilosaClient(URI:address(serverAddress))
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Below is a part of the &lt;code&gt;PilosaClient&lt;/code&gt; test case. Note that we create the necessary index and frame in the setup function &lt;code&gt;before_each&lt;/code&gt; and delete the index (which deletes the frame too) in the teardown function &lt;code&gt;after_each&lt;/code&gt;. &lt;code&gt;before_each&lt;/code&gt; and &lt;code&gt;after_each&lt;/code&gt; runs before and after each test function respectively.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;describe(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PilosaClient&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; client &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; getClient()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; schema &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; orm.Schema()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; schema:index(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;test-index&amp;#34;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; frame &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; index:frame(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;test-frame&amp;#34;&lt;/span&gt;)

    before_each(&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;()
        client:ensureIndex(index)
        client:ensureFrame(frame)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;)

    after_each(&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;()
        client:deleteIndex(index)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;-- Tests are here --&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And here is the test function for &lt;code&gt;PilosaClient:query&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-lua&#34; data-lang=&#34;lua&#34;&gt;    it(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;can send a query&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;()
        &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; client &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; getClient()
        client:query(frame:setbit(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;))        
        &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; response1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; client:query(frame:bitmap(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;local&lt;/span&gt; bitmap &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; response1.result.bitmap
        assert.equals(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;bitmap.attributes)
        assert.equals(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, table.getn(bitmap.bits))
        assert.same(&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, bitmap.bits[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;All official Pilosa clients have the same structure and similarly named classes and methods. That makes it easy to port tests between client libraries.&lt;/p&gt;
&lt;h3 id=&#34;continuous-integration&#34;&gt;Continuous Integration&lt;/h3&gt;
&lt;p&gt;Finally we have a basic Lua client library for Pilosa, together with tests. It would be nice if the tests were run automatically when the code changed using a continuous integration service.&lt;/p&gt;
&lt;p&gt;We use Github and Travis CI for our continuous integration infrastructure for our  projects at Pilosa. We provide a precompiled Pilosa binary which tracks the latest master so we can be sure that our client libraries work with the latest Pilosa server.&lt;/p&gt;
&lt;p&gt;Travis CI doesn&amp;rsquo;t directly support Lua, but we can use their Python image and install Lua using HereRocks like we have done in the Getting Started section. Below is the &lt;code&gt;.travis.yml&lt;/code&gt; we use for this project:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;language&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;python&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;python&lt;/span&gt;:
  - &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.7&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;before_install&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;wget https://s3.amazonaws.com/build.pilosa.com/pilosa-master-linux-amd64.tar.gz &amp;amp;&amp;amp; tar xf pilosa-master-linux-amd64.tar.gz&lt;/span&gt;
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;./pilosa-master-linux-amd64/pilosa server -d http_data &amp;amp;&lt;/span&gt;
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;curl -O https://github.com/mpeterv/hererocks/raw/0.17.0/hererocks.py&lt;/span&gt;
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;python hererocks.py lua5.1 -l5.1 -rlatest&lt;/span&gt;
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;source lua5.1/bin/activate&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;install&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;luarocks install luasocket busted&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;script&lt;/span&gt;:
  - &lt;span style=&#34;color:#ae81ff&#34;&gt;make test-all&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;In this article we explored the fundamentals of writing a client library for Pilosa and wrote a simple one in Lua. Hopefully this article has been useful for those of you interested in writing your own Pilosa client library, or even those just looking to better understand the current client libraries.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re always looking for feedback, so feel free to reach out if you think there&amp;rsquo;s something we missed, or other topics you&amp;rsquo;d like us to cover.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Yüce is an Independent Software Engineer at Pilosa. When he&amp;rsquo;s not writing Pilosa client libraries, you can find him watching good bad movies. He is &lt;a href=&#34;https://github.com/yuce&#34;&gt;@yuce&lt;/a&gt; on GitHub and &lt;a href=&#34;https://twitter.com/tklx?lang=en&#34;&gt;@tklx&lt;/a&gt; on Twitter.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Real Time Queries Without Compromises</title>
          <link>https://www.pilosa.com/blog/complex-queries-without-sacrificing-latency/</link>
          <pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/complex-queries-without-sacrificing-latency/</guid>
          <description>&lt;p&gt;The desire to eliminate barriers between raw data and useful insights has driven decades of engineering innovation. Countless databases, datastores, indexes, and query-level solutions promising to make this dream a reality have surfaced at regular intervals, only to fall into obscurity again as the promise remains unrealized.&lt;/p&gt;
&lt;p&gt;In the meantime, an entire class of data-centric professions has stepped in to fill the gaps left by current technologies. Those professions are doing the work of cleaning, manipulating, and analyzing data that continues to stymie our machines. So great is the demand for these skills that the &lt;a href=&#34;https://www.idc.com/getdoc.jsp?containerId=prUS41826116&#34;&gt;IDC predicts&lt;/a&gt; global revenues for big data and business analytics – the services these data solutions and professionals provide – will grow from $130.1 billion in 2016 to more than $203 billion in 2020.&lt;/p&gt;
&lt;p&gt;The rise of artificial intelligence (AI) and machine learning (ML) carries even greater promise: the &lt;a href=&#34;https://www.idc.com/getdoc.jsp?containerId=IDC_P33198&#34;&gt;IDC estimates&lt;/a&gt; that spending on AI/ML capabilities will grow 55%, ultimately reaching $47 billion in three short years.&lt;/p&gt;
&lt;p&gt;In short, industries need these technologies and services, and they’re paying massive amounts of money to get them.&lt;/p&gt;
&lt;p&gt;Take Uber, for example. The &lt;a href=&#34;https://www.nytimes.com/2017/10/21/style/susan-fowler-uber.html&#34;&gt;embattled&lt;/a&gt; &lt;a href=&#34;https://www.nytimes.com/2017/06/21/technology/uber-ceo-travis-kalanick.html&#34;&gt;tech giant’s&lt;/a&gt; mission is to make “transportation as reliable as running water, everywhere, for everyone.” In order to accomplish this, the rideshare platform connects people who need rides to strangers with cars in mere seconds, and sweetens the deal by automating payments, thereby eliminate the awkward exchange of cash or the necessity of cards. All on a smartphone. Simple. Brilliant.&lt;/p&gt;
&lt;p&gt;But it takes a ton of real-time, data-based decisions to make that happen.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/vinothchandar/&#34;&gt;Vinoth Chandar&lt;/a&gt;, a staff software engineer at Uber, recently &lt;a href=&#34;https://www.oreilly.com/ideas/ubers-case-for-incremental-processing-on-hadoop&#34;&gt;made the case for incremental processing on Hadoop&lt;/a&gt; for &lt;em&gt;near&lt;/em&gt;-real time use cases at Uber. He posits that there is a gap in capability between traditional batch oriented Hadoop, and streaming solutions like Storm, Spark Streaming and Flink; these streaming solutions work well for sub-5 minute latency requirements, and Hadoop works well when an hour or more is sufficient. So there is a gap in the 5-60 minute range; of course, the streaming solutions will work just fine here, but if you could get Hadoop to work well in that range, you can (a) save lots of cost, (b) greatly simplify your infrastructure, and (c) take advantage of more mature SQL tooling. Vinoth proposes adding some new capabilities to the Hadoop ecosystem to support incremental processing for this near real time use case.&lt;/p&gt;
&lt;p&gt;Vinoth&amp;rsquo;s post is great by the way, and you should totally go read it. We here at Pilosa agree with everything right up to the point where he suggests continuing to use Hadoop with just a few modifications.&lt;/p&gt;
&lt;p&gt;To us, this seems like putting a bandaid over ravenous flesh-eating bacteria. As we mentioned above, data volumes are only increasing, and latency requirements are plummeting. So why go through Herculean efforts to retrofit a batch-oriented, high-latency technology into working for near real-time use cases, when the need for REAL real-time use cases increases every day? If you&amp;rsquo;re going to collapse the lambda architecture to one side, let&amp;rsquo;s make it the low latency/streaming side, not the &amp;ldquo;my results are between 5 minutes and a few hours old&amp;rdquo; side!&lt;/p&gt;
&lt;p&gt;Most of Vinoth&amp;rsquo;s arguments work pretty well whether you&amp;rsquo;re talking about streaming or batch anyway. For example, if your latency requirements are not stringent, then stream processing workers can batch data store updates. Doing this will generally give you an overall increase in throughput per worker allowing you to reduce the number of workers, and therefore save on infrastructure costs. Pilosa has support for configurable batching which shows the latency/throughput trade off clearly:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Batch Size&lt;/th&gt;
&lt;th&gt;Time&lt;/th&gt;
&lt;th&gt;Latency to 1st result&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;14m47.830748948s&lt;/td&gt;
&lt;td&gt;0.0087s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;2m34.943978702s&lt;/td&gt;
&lt;td&gt;0.0154s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10000&lt;/td&gt;
&lt;td&gt;1m14.523008057s&lt;/td&gt;
&lt;td&gt;0.074s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;100000&lt;/td&gt;
&lt;td&gt;11.044166203s&lt;/td&gt;
&lt;td&gt;0.11s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;6.535759196s&lt;/td&gt;
&lt;td&gt;0.65s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Another of Vinoth&amp;rsquo;s arguments is that sticking with Hadoop allows you to take advantage of the mature tooling for SQL on Hadoop, and this is certainly valid; it&amp;rsquo;s always tempting to use the latest technology available, but more often than not it will cause as many problems as it solves.&lt;/p&gt;
&lt;p&gt;The problem with these SQL on Hadoop packages is that they are fundamentally based on Hadoop&amp;rsquo;s concepts – they operate on immutable data, and require massive amounts of precomputation to be performant. Indeed, the author&amp;rsquo;s proposed extensions to Hadoop revolve primarily around the ability to change and update existing data in an efficient way rather than rewriting entire partitions. Precomputation can be very useful for query acceleration, but it ultimately complicates things, particularly if you have delayed events, or &amp;ldquo;late data&amp;rdquo; as Vinoth calls it. If only there were some way to have &lt;a href=&#34;https://www.pilosa.com/use-cases/retail-analytics/&#34;&gt;fast queries without precomputation&amp;hellip;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vinoth&amp;rsquo;s final, major argument is &amp;ldquo;fewer moving parts;&amp;rdquo; any time you can reduce the number of subsystems in a tech stack, you&amp;rsquo;re probably going to make things less expensive, easier to change, simpler to manage, etc. Simplicity is one of our main foundations at Pilosa, so we&amp;rsquo;re nodding enthusiastically at this bit. As we mentioned earlier on though (but it bears repeating): if you&amp;rsquo;re only going to implement one arm of a lambda architecture (batch or streaming), MAKE IT STREAMING! Then take a look at &lt;a href=&#34;https://www.pilosa.com/docs/latest/introduction/&#34;&gt;Pilosa&lt;/a&gt; to see how you can still get complete, up to date results for complex queries without sacrificing latency.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ali is Pilosa&amp;rsquo;s jack of all trades and resident research nerd. Jaffee is a lead software engineer at Pilosa and is obsessed with optimization. Say hello to them on Twitter at &lt;a href=&#34;https://twitter.com/ay_em_see?lang=en&#34;&gt;@ay_em_see&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/mattjaffee?lang=en&#34;&gt;@mattjaffee&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Using Bitmaps to Perform Range Queries</title>
          <link>https://www.pilosa.com/blog/range-encoded-bitmaps/</link>
          <pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/range-encoded-bitmaps/</guid>
          <description>&lt;p&gt;Pilosa stores integer values in Base-2, Range-Encoded, Bit-sliced Indexes. This post explains what all that means.&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Pilosa is built around the concept of representing everything as bitmaps. Relationships between objects, for example, are treated as boolean values—either the relationship exists or it doesn&amp;rsquo;t—and a set of these boolean values is stored as a series of ones and zeros. These boolean sets are bitmaps, and by using bitmaps in a variety of bitwise operations, we can perform complex queries very quickly. Additionally, bitmap compression techniquies allow us to represent large amounts of data in a very compact format, which reduces the amount of resources we need to store data and perform queries.&lt;/p&gt;
&lt;p&gt;Using bitmaps and &lt;a href=&#34;http://roaringbitmap.org/&#34;&gt;Roaring bitmap compression&lt;/a&gt;, Pilosa is really good at performing segmentation queries on billions of objects. But often we see use-cases where it would be useful to work with integer values. For example, we might want to perform a query that excludes all records with a value of &lt;code&gt;foo&lt;/code&gt; greater than 1,000. This post explains, step-by-step, how we added range-encoded bitmaps to Pilosa, giving us the ability to support integer values in our query operations.&lt;/p&gt;
&lt;p&gt;All of the concepts described in this post are based on research done over the last couple of decades by some very smart people. This is my attempt to describe things at a little higher level, but I encourage you to read more about &lt;a href=&#34;https://cs.brown.edu/courses/cs227/archives/2008/Papers/Indexing/buchmann98.pdf&#34;&gt;Bit-sliced Indexes&lt;/a&gt; and &lt;a href=&#34;https://link.springer.com/chapter/10.1007/3-540-45675-9_8&#34;&gt;Range-Encoding&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;bitmap-encoding&#34;&gt;Bitmap Encoding&lt;/h3&gt;
&lt;p&gt;To get started, let&amp;rsquo;s assume that we want to catalog every member of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Animal&#34;&gt;Animal Kingdom&lt;/a&gt; in such a way that we can easily, and efficiently, explore various species based on their traits. Because we&amp;rsquo;re talking about bitmaps, an example data set might look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/example-dataset.png&#34; alt=&#34;Example data set&#34;&gt;
&lt;em&gt;Example Data Set&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;equality-encoded-bitmaps&#34;&gt;Equality-encoded Bitmaps&lt;/h4&gt;
&lt;p&gt;The example above shows a set of equality-encoded bitmaps, where each row—each trait—is a bitmap indicating which animals have that trait. Although it&amp;rsquo;s a fairly simple concept, equality-encoding can be pretty powerful. Because it lets us represent everything as a boolean relationship (i.e. a manatee has wings: yes/no), we can perform all sorts of bitwise operations on the data.&lt;/p&gt;
&lt;p&gt;The next diagram shows how we find all animals that are air-breathing invertebrates by performing a logical AND on the &lt;code&gt;Invertebrate&lt;/code&gt; and &lt;code&gt;Breathes Air&lt;/code&gt; bitmaps. Based on our sample data, we can see that the Banana Slug, Garden Snail, and Wheel Bug all have both of those traits.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/bitwise-intersection.png&#34; alt=&#34;Bitwise Intersection example&#34;&gt;
&lt;em&gt;Bitwise Intersection of two traits&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;You can get pretty far with equality-encoded bitmaps, but what about cases where a boolean value doesn&amp;rsquo;t best represent the original data? What if we want to add a trait called &lt;code&gt;Captivity&lt;/code&gt; which represents the total number of specimens that are currently held in captivity, and we want to perform queries filtered by those values? (As you probably suspect, the values that we use for &lt;code&gt;Captivity&lt;/code&gt; in the examples below are completely made up, but they help demonstrate the concepts.)&lt;/p&gt;
&lt;p&gt;Given what we know about equality-encoded bitmaps, there are a couple of (admittedly naive) approaches that we could take. One approach would be to create a trait (bitmap) for every possible &lt;code&gt;Captivity&lt;/code&gt; value, like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/captive-rows.png&#34; alt=&#34;Captivity Counts as individual bitmaps&#34;&gt;
&lt;em&gt;Captivity Counts represented as individual bitmaps&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This approach is ok, but it has a couple of limitations. First, it&amp;rsquo;s not very efficient. Depending on the cardinality, you may need to create a lot of bitmaps to represent all possible values. Second, if you want to filter your query by a range of &lt;code&gt;Captivity&lt;/code&gt; values, you&amp;rsquo;ll have to perform an &lt;code&gt;OR&lt;/code&gt; operation against every possible value in your range. In order to know which animals have fewer than 100 specimens in captivity, your query needs to perform something like (Captivity=99 OR Captivity=98 OR Captivity=97 OR &amp;hellip;). You get the idea.&lt;/p&gt;
&lt;p&gt;Instead of representing every possible value as a unique bitmap, another approach is to create buckets of &lt;code&gt;Captivity&lt;/code&gt; ranges. In that case, you might have something like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/captive-buckets.png&#34; alt=&#34;Captivity Counts as buckets&#34;&gt;
&lt;em&gt;Captivity Counts represented as buckets&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One benefit to this approach is that it&amp;rsquo;s a bit more efficient. It&amp;rsquo;s also easier to query because you don&amp;rsquo;t have to construct a Union of multiple bitmaps in order to represent a range of values. The downside is that it&amp;rsquo;s not as granular; by transforming &lt;code&gt;47&lt;/code&gt; into the bucket 0-99, you are losing information.&lt;/p&gt;
&lt;p&gt;Either of those approaches are perfectly valid solutions to some problems, but for cases where cardinality is extremely high and losing information is not acceptable, we need another way to represent non-boolean values. And we need to do it in such a way that we can perform queries on ranges of values without writing really large and cumbersome &lt;code&gt;OR&lt;/code&gt; operations. For that, let&amp;rsquo;s talk about range-encoded bitmaps and how they avoid some of the problems that we ran into with the previous approaches.&lt;/p&gt;
&lt;h4 id=&#34;range-encoded-bitmaps&#34;&gt;Range-Encoded Bitmaps&lt;/h4&gt;
&lt;p&gt;First, let&amp;rsquo;s take our example above and see what it looks like if we use range-encoded bitmaps.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/captive-range-encoded-rows.png&#34; alt=&#34;Captivity Counts as Range-Encoded bitmaps&#34;&gt;
&lt;em&gt;Captivity Counts as Range-Encoded bitmaps&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Representing a value with range-encoded bitmaps is similar to what we did with equality-encoding, but instead of just setting the bit that corresponds to a specific value, we also set a bit for every value greater than the actual value. For example, because there are 14 Koala Bears in capitivity, we set the bit in bitmap 14 as well as bitmaps 15, 16, 17, etc. Instead of a bitmap representing all the animals with a specific captivity count, a bitmap now represents all of the animals with a captivity count up to and including that amount.&lt;/p&gt;
&lt;p&gt;This encoding method lets us perform those range queries that we did before, but instead of performing an &lt;code&gt;OR&lt;/code&gt; operation on many different bitmaps, we can get what we want from just one or two bitmaps. For example, if we want to know which animals have fewer than 15 specimens in captivity, we just pull the 14 bitmap and we&amp;rsquo;re done. If we want to know which animals have more than 15 specimens in captivity, it&amp;rsquo;s a little more complicated, but not much. For that, we pull the bitmap representing the maximum count (in our case that&amp;rsquo;s the 956 bitmap), and then we subtract the 15 bitmap.&lt;/p&gt;
&lt;p&gt;Those operations are much simpler—and much more efficient—than our previous approach. We have addressed the problem that had us &lt;code&gt;OR&lt;/code&gt;&amp;lsquo;ing together dozens of bitmaps in order to find our range, and we aren&amp;rsquo;t losing any information like we did in the bucketing approach. But we still have a couple of issues that make this approach less than ideal. First, we still have to keep a bitmap representing every specific captivity count. And on top of that, we have added the complexity and overhead of having to set a bit not just for the value we&amp;rsquo;re interested in, but also for every value greater than that one. This would very likely introduce performance problems in a write-heavy use-case.&lt;/p&gt;
&lt;p&gt;Ideally what we want is to have the functionality of range-encoded bitmaps with the efficiency of equality-encoding. Next, we&amp;rsquo;ll discuss bit-sliced indexes and see how that helps us achieve what we want.&lt;/p&gt;
&lt;h3 id=&#34;bit-sliced-indexes&#34;&gt;Bit-sliced Indexes&lt;/h3&gt;
&lt;p&gt;If we want to represent every possible value from 0 to 956 using range-encoded bitmaps, we have to use 957 bitmaps. While this works, it&amp;rsquo;s not the most efficient approach, and when the cardinality of possible values gets really high, the number of bitmaps we need to maintain can become prohibitive. Bit-sliced indexes let us represent those same values in a more efficient way.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at our example data and talk about how we would represent it using bit-sliced indexes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/captive-bsi-base10.png&#34; alt=&#34;Captivity Counts as a Base-10, Bit-sliced Index&#34;&gt;
&lt;em&gt;Base-10, Bit-sliced Index&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Notice that we&amp;rsquo;ve broken our values into three, base-10 components. The first column of bits represents the value &lt;code&gt;003&lt;/code&gt;, which is the number of Manatees in captivity. Component 0 of &lt;code&gt;003&lt;/code&gt; is &lt;code&gt;3&lt;/code&gt;, so we set a bit in component 0, row 3. Components 1 and 2 of &lt;code&gt;003&lt;/code&gt; are both &lt;code&gt;0&lt;/code&gt;, so we set bits in component 1, row 0 and component 2, row 0. Each component in our base-10 index requires 10 bitmaps to represent all possible values, so in our captivity example where we need to represent values ranging from 0 to 956, we only need (3 x 10) = 30 bitmaps (as opposed to 957 bitmaps that would be required if we used a bitmap for every distinct value).&lt;/p&gt;
&lt;p&gt;So that&amp;rsquo;s great, but we&amp;rsquo;ve basically just found a way to be more efficient with our equality-encoding strategy. Let&amp;rsquo;s see what it looks like when we combine bit-sliced indexes with range-encoding.&lt;/p&gt;
&lt;h3 id=&#34;range-encoded-bit-slice-indexes&#34;&gt;Range-Encoded Bit-Slice Indexes&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/captive-bsi-range-encoded-base10.png&#34; alt=&#34;Captivity Counts as a Range-Encoded, Base-10, Bit-sliced Index&#34;&gt;
&lt;em&gt;Range-Encoded, Base-10, Bit-sliced Index&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Notice that the most significant value in each component (9 in the base-10 case) is always one. Because of this, we don&amp;rsquo;t need to store the highest value. So for base-10, range-encoded, bit-sliced indexes, we only need 9 bitmaps to represent a component. In addition to that, we need to store one more bitmap, called &amp;ldquo;Not Null&amp;rdquo;, which indicates whether or not a value has been set for that column. The next diagram shows the resulting bitmaps.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/captive-bsi-range-encoded-base10-not-null.png&#34; alt=&#34;Captivity Counts as a Range-Encoded, Base-10, Bit-sliced Index with Not-Null&#34;&gt;
&lt;em&gt;Range-Encoded, Base-10, Bit-sliced Index with Not-Null&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So for 3-component values, we need ((3 x 9) + 1) = 28 bitmaps to represent any value in the range 0 to 999. Now we have a pretty efficient way to store values, and we get the benefit of range encoding, so we can perform queries that filter on ranges. Let&amp;rsquo;s take it just one step further and try encoding the base-2 representation of our value range.&lt;/p&gt;
&lt;h4 id=&#34;base-2-components&#34;&gt;Base-2 Components&lt;/h4&gt;
&lt;p&gt;If, instead of representing our &lt;code&gt;Captivity&lt;/code&gt; values as base-10 components, we use base-2 components, then we end up with a range-encoded set of bit-sliced indexes that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/captive-bsi-range-encoded-base2.png&#34; alt=&#34;Capacity Counts as a Range-Encoded, Base-2, Bit-sliced Index&#34;&gt;
&lt;em&gt;Range-Encoded, Base-2, Bit-sliced Index&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The first column of bits represents the base-2 value &lt;code&gt;000000011&lt;/code&gt;, which is the number of Manatees in captivity (3 in base-10). Since component 0 and component 1 of &lt;code&gt;000000011&lt;/code&gt; are both &lt;code&gt;1&lt;/code&gt;, we set a bit in component 0, row 1 and component 1, row 1. Since the remaining components of &lt;code&gt;000000011&lt;/code&gt; are all &lt;code&gt;0&lt;/code&gt;, we set a bit in row 0 for components 2 through 9, and also—because these are range-encoded—we set a bit in every value greater than 0. In the case of base-2 components, that means we also set the bit in row 1 for components 2 through 9.&lt;/p&gt;
&lt;p&gt;But remember, just like we saw before with bitmap 9 of the base-10 representation, bitmap 1 is always one so we don&amp;rsquo;t need to store it. That leaves us with this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/captive-bsi-range-encoded-base2-not-null.png&#34; alt=&#34;Captivity Counts as a Range-Encoded, Base-2, Bit-sliced Index with Not-Null&#34;&gt;
&lt;em&gt;Range-Encoded, Base-2, Bit-sliced Index with Not-Null&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;With this encoding, we can represent the range of sample values with only 10 bitmaps! Also, notice that the base-2, range-encoded, bit-sliced index is the inverse of the binary representation of the integer value. What this tells us is that we can represent any range of values with cardinality n using only (n + 1) bitmaps (where the additional bitmap is the &amp;ldquo;Not Null&amp;rdquo; bitmap). And it means that we can perform range queries on large integer values without needing to store an unreasonable number of bitmaps.&lt;/p&gt;
&lt;h3 id=&#34;range-encoded-bitmaps-in-pilosa&#34;&gt;Range-Encoded Bitmaps in Pilosa&lt;/h3&gt;
&lt;p&gt;By implementing range-encoded bitmaps in Pilosa, users can now store integer values that pertain to billions of objects, and very quickly perform queries that filter by a range of values. We also support aggregation queries like &lt;code&gt;Sum()&lt;/code&gt;. What&amp;rsquo;s the total number of winged vertebrates in captivity? No problem.&lt;/p&gt;
&lt;p&gt;As one last exercise, let&amp;rsquo;s demonstrate how we would store and query our example &lt;code&gt;Captivity&lt;/code&gt; data in Pilosa.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Create an index called &amp;quot;animals&amp;quot;.
curl -X POST localhost:10101/index/animals

# Create a frame &amp;quot;traits&amp;quot; to hold captivity values.
curl localhost:10101/index/animals/frame/traits \
  -X POST \
  -d &#39;{&amp;quot;options&amp;quot;:{&amp;quot;rangeEnabled&amp;quot;: true,
                     &amp;quot;fields&amp;quot;: [{&amp;quot;name&amp;quot;: &amp;quot;captivity&amp;quot;,
                                 &amp;quot;type&amp;quot;: &amp;quot;int&amp;quot;,
                                 &amp;quot;min&amp;quot;: 0,
                                 &amp;quot;max&amp;quot;: 956}]
                    }
         }&#39;

# Add the captivity values to the field.
curl localhost:10101/index/animals/query \
  -X POST \
  -d &#39;SetFieldValue(frame=traits, col=1,  captivity=3)
      SetFieldValue(frame=traits, col=2,  captivity=392)
      SetFieldValue(frame=traits, col=3,  captivity=47)
      SetFieldValue(frame=traits, col=4,  captivity=956)
      SetFieldValue(frame=traits, col=5,  captivity=219)
      SetFieldValue(frame=traits, col=6,  captivity=14)
      SetFieldValue(frame=traits, col=7,  captivity=47)
      SetFieldValue(frame=traits, col=8,  captivity=504)
      SetFieldValue(frame=traits, col=9,  captivity=21)
      SetFieldValue(frame=traits, col=10, captivity=0)
      SetFieldValue(frame=traits, col=11, captivity=123)
      SetFieldValue(frame=traits, col=12, captivity=318)
  &#39;

# Query for all animals with more than 100 specimens
# in captivity.
curl localhost:10101/index/animals/query \
  -X POST \
  -d &#39;Range(frame=traits, captivity &amp;gt; 100)&#39;
 
# Query for the total number of animals in captivity
curl localhost:10101/index/animals/query \
  -X POST \
  -d &#39;Sum(frame=traits, field=captivity)&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;The examples that I described in this post showed how we can use Bit-sliced indexes to significantly reduce the number of bitmaps we need to represent a range of integer values. And by applying range-encoding to our indexes, we are able to perform various range queries on our data. The chart below compares the different approaches that we discussed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/range-encoded-bitmaps/example-comparison.png&#34; alt=&#34;Comparison Chart&#34;&gt;
&lt;em&gt;Comparison Chart&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We added Range-Encoding support to &lt;a href=&#34;https://github.com/pilosa/pilosa/releases/tag/v0.7.0&#34;&gt;Release 0.7.0&lt;/a&gt;. You should also check out the &lt;a href=&#34;https://www.pilosa.com/docs/latest/data-model/#bsi-range-encoding&#34;&gt;Range-Encoding Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Try it out, and let us know what you think. We&amp;rsquo;re always looking to make improvements and appreciate any feedback you have!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Travis is Chief Architect at Pilosa. Find him on Twitter at &lt;a href=&#34;https://twitter.com/travislturner?lang=en&#34;&gt;@travislturner&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>A Map of the Entire Universe</title>
          <link>https://www.pilosa.com/blog/universe-map/</link>
          <pubDate>Fri, 25 Aug 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/universe-map/</guid>
          <description>&lt;p&gt;&amp;hellip; the universe of 65536-bit sets in Roaring, that is. This is one part debugging
postmortem, one part documentation, and three parts academic deep dive on the
structure that underlies Roaring Bitmaps.&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Pilosa uses &lt;a href=&#34;http://roaringbitmap.org/&#34;&gt;Roaring Bitmaps&lt;/a&gt; for storage of and computation
with bitmaps (integer sets) in its distributed bitmap index. Roaring is a core component
of Pilosa, which makes it an easy place to look for optimization opportunities. One of
those opportunities, adding a &lt;a href=&#34;https://www.pilosa.com/blog/adding-rle-support/&#34;&gt;new compression technique&lt;/a&gt;,
was a big undertaking, and it has raised interesting questions.&lt;/p&gt;
&lt;p&gt;In this post, I&amp;rsquo;ll start with a brief explanation of Roaring and how it works.
This is important background for understanding &amp;ldquo;container space&amp;rdquo;, a two-dimensional
plane which can be used to map all integer sets under a given size. Container space is a
helpful framework for understanding some of the details of Roaring&amp;rsquo;s implementation
and performance.&lt;/p&gt;
&lt;p&gt;This came in handy in debugging and testing. At one point, we started asking more
theoretical questions, and that&amp;rsquo;s when I went down a rabbit hole, with the help of the
container space framework. In the process of answering those questions, I produced some
pretty pictures that I wanted to share. Feel free to skip to the last section to see those,
but I suggest at least skimming the next section for context.&lt;/p&gt;
&lt;h3 id=&#34;container-space&#34;&gt;Container Space&lt;/h3&gt;
&lt;p&gt;Roaring stores large sets of integers by breaking them up into
&lt;strong&gt;containers&lt;/strong&gt; that are 2&lt;!-- raw HTML omitted --&gt;16&lt;!-- raw HTML omitted --&gt; = 65536 bits long, and it uses a different
&lt;strong&gt;container type&lt;/strong&gt; for each container, depending on what&amp;rsquo;s in it. For example, the
set {0, 1, 2, 3, 6, 7, 9, 10, 14} has three equivalent representations in
Roaring:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/rle-container-example.png&#34; alt=&#34;RLE container example&#34;&gt;
&lt;em&gt;Small container type example&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The set contains nine elements, and in this toy example, we&amp;rsquo;ll use 16-bit
numbers to store them. That means the &lt;strong&gt;array&lt;/strong&gt; representation, a list of integers in
the set, uses 9×2 bytes. The uncompressed &lt;strong&gt;bitmap&lt;/strong&gt;, in which one bit is set for each
number in the set, uses a constant number of bytes (2 here), regardless of what set it
represents. Run-length encoding (&lt;strong&gt;RLE&lt;/strong&gt;) stores the set as a list of runs, where each
run contains two 16-bit numbers (the start and end of the run). For this set with four
runs, we use (4 runs) × (2 numbers per run) × (2 bytes per number).&lt;/p&gt;
&lt;p&gt;Before I get into it, here is a summary of some notation. You can skip this, just refer back to it if you lose track of what the symbols mean.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/container-terminology-table.png&#34; alt=&#34;Container terminology table&#34;&gt;
&lt;em&gt;Container terminology&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Roaring switches between these intelligently to minimize storage size. Which
container type is smallest? In this example, the uncompressed bitmap is, but
the answer depends on the set, and all three types are important in their own way. Originally, with only two container types
(uncompressed bitmaps and arrays), deciding when to switch between the two for a
given container was trivial: compare the &lt;strong&gt;cardinality&lt;/strong&gt; of
the set (N) to a threshold, (M&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt;), and only use an array if
N ≤ M&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt;. With the addition of RLE containers, this got more complicated,
because now we have to check a new attribute of the set: the &lt;strong&gt;run count&lt;/strong&gt;, the
number of runs of ones (N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;).&lt;/p&gt;
&lt;p&gt;Previously, we only had to decide between two one-dimensional intervals with a
single comparison. Now, with both N and N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; defining a two-dimensional
planar region that I have dubbed &lt;strong&gt;container space&lt;/strong&gt;, each container type
corresponds to a subregion with linear boundaries. These regions are illustrated
below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/container-type-decision.png&#34; alt=&#34;Container type decision&#34;&gt;
&lt;em&gt;Container type decision&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;M is the maximum number of bits in a container.
Note that the figure is not to scale; M is actually much larger than
M&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt; and M&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;. The 2:1 ratio of M&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt; and M&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; is
accurate, however.&lt;/p&gt;
&lt;p&gt;There is an impossible region in there. Why is that?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The solid black line sloping up-right, the N = N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; diagonal,
represents sets where every set bit is isolated - all runs are length one.
No set can be above this line, as that would mean more runs than set bits
(but each run must have at least one bit).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The other solid black diagonal line, N = M-N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;+1, represents sets where
every clear bit is isolated - all runs are as close as possible while still
being separate. No set can be above this line, as that would mean more runs
than clear bits (which must separate adjacent runs). If you think about the
complementary set, it makes sense that both of these constraints must exist.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Near the intersection of these two lines are two points, (M/2, M/2) and (M/2+1,
M/2), which represent sets with the maximum number of single-bit runs. These
are the only cases for which N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; = M/2; N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; is smaller for
all other sets.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The remaining region represents all possible sets, with container type regions
indicated by color. What about those boundaries, where do they come from?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The line N = M&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt; is the &lt;code&gt;ArrayMaxSize&lt;/code&gt; threshold constraint: when
cardinality is low enough, an array will always be smaller than a bitmap.
Array size is AN, so an array is smaller than a bitmap when AN &amp;lt; M, or N &amp;lt; M/A.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The line N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; = M&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; is a similar &lt;code&gt;RunMaxSize&lt;/code&gt; threshold constraint.
When the number of runs is low enough, an RLE container will always be smaller than a
bitmap. RLE size is 2RN&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;, so an RLE is smaller than a bitmap when
2RN&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; &amp;lt; M, or N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; &amp;lt; M/(2R).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, that dotted diagonal line is the boundary between array and RLE:
arrays are smaller than runs when AN &amp;lt; 2RN&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;, or N &amp;lt; 2(R/A)N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;.
Generally, A = R, so this simplifies to N &amp;lt; 2N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think it&amp;rsquo;s a pretty diagram. It&amp;rsquo;s satisfying to see a complex situation
condensed into a simple 2-D cartesian representation, even if it ignores
important complexity. There is one problem: it&amp;rsquo;s not symmetric enough!&lt;/p&gt;
&lt;p&gt;The above figure represents exactly what Pilosa does to decide a container type,
but there is another container type that Pilosa doesn&amp;rsquo;t use at all:
&lt;strong&gt;inverse arrays&lt;/strong&gt;. What if, for dense data, we store an array of the
&lt;em&gt;clear bits&lt;/em&gt; instead of the set bits? In other words, we store an array of the
integers that are NOT in the set, so all &lt;em&gt;other&lt;/em&gt; integers in {0, 1, &amp;hellip;, 65535}
are part of the set. Then the diagram looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/container-type-decision-with-inverse.png&#34; alt=&#34;Container type decision with inverse arrays&#34;&gt;
&lt;em&gt;Container type decision with inverse arrays&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Beautiful! The utility of the iarray container type is questionable, however, because it&amp;rsquo;s
fundamentally the same as the array type. In other words, you can achieve the same
behavior by simply storing the inverse of a set, with a little overhead. Also, the iarray
container type is really only useful for very dense data sets, which we don&amp;rsquo;t see a lot of.
If we do, we&amp;rsquo;ll consider adding support for this new type to Pilosa. Anyway, I&amp;rsquo;m just glad
to know that there is a sort of fundamental mirror symmetry to the diagram.&lt;/p&gt;
&lt;h3 id=&#34;bugs&#34;&gt;Bugs&lt;/h3&gt;
&lt;p&gt;We made fast progress with the &lt;a href=&#34;https://github.com/pilosa/pilosa/releases/tag/v0.6.0&#34;&gt;RLE work&lt;/a&gt;,
but while stress testing it with large imports, we discovered some nasty bugs.
For weeks we couldn&amp;rsquo;t even reproduce them consistently, but eventually we were
able to trim those big import jobs down to something more manageable. Only then
did we have a chance to diagnose the problem, and before long we figured it
out: some of the container type decision logic was flawed.&lt;/p&gt;
&lt;p&gt;Before RLE, every time an element was added to or removed from a container, we
checked the cardinality threshold, and converted to bitmap or array accordingly.
With RLE containers, we introduced a function to handle the new conversions in a
single place:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func (c *container) Optimize() {
  if c.isArray() {
    runs := c.arrayCountRuns()
    if runs &amp;lt; c.n/2 {
      c.arrayToRun()
    }
  } else if c.isBitmap() {
    runs := c.bitmapCountRuns()
    if runs &amp;lt; 2048 {
      c.bitmapToRun()
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With some thought we can see that this function, in itself, is incomplete: it can only result in one
of two conversion actions: &lt;code&gt;arrayToRun&lt;/code&gt; or &lt;code&gt;bitmapToRun&lt;/code&gt;. But there are &lt;em&gt;six&lt;/em&gt; possible conversions.
&lt;code&gt;arrayToBitmap&lt;/code&gt; and &lt;code&gt;bitmapToArray&lt;/code&gt; were previously being handled elsewhere, but that still leaves
&lt;code&gt;runToArray&lt;/code&gt; and &lt;code&gt;runToBitmap&lt;/code&gt;. To handle all of these possibilities at once, we should have been
doing something more like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func (c *container) Optimize() {
  runs := c.countRuns()

  // Decide new type.
  var newType byte
  if runs &amp;lt;= RunMaxSize &amp;amp;&amp;amp; runs &amp;lt;= c.n/2 {
    newType = ContainerRun
  } else if c.n &amp;lt; ArrayMaxSize {
    newType = ContainerArray
  } else {
    newType = ContainerBitmap
  }

  // Then handle all six conversions.
  if c.isArray() &amp;amp;&amp;amp; newType == ContainerBitmap {
    c.arrayToBitmap()
  else if ... {
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Implementing RLE was a big job, and at least four of our engineers contributed
to the branch. Two of us, working independently, updated the file-read/write functions to handle RLE
containers, which is why we failed to notice that the logic for deciding
container type on file read did not exactly match the logic on write (partly
because the latter was hidden inside the innocuous-sounding &lt;code&gt;container.Optimize()&lt;/code&gt;).
If you&amp;rsquo;ve implemented a binary file format before, you might be thinking: why
is there even any logic at all for deciding a container  type while reading a
file? That&amp;rsquo;s a great question, and it&amp;rsquo;s answered in full by the
&lt;a href=&#34;https://github.com/RoaringBitmap/RoaringFormatSpec&#34;&gt;Roaring storage spec&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;TL;DR: back before RLE containers, it was trivial to infer container type from
the cardinality, which had to be stored for arrays anyway, so there was no need to have explicit type
information in the file. With the addition of RLE, it became necessary to add
one extra bit per container to indicate an RLE container, since the cardinality
doesn&amp;rsquo;t tell you anything about that.&lt;/p&gt;
&lt;p&gt;Of course, if perfect backward compatibility isn&amp;rsquo;t critical, there are other,
more robust ways to store type information. We chose this route—including the
container type explicitly in the &amp;ldquo;descriptive header&amp;rdquo; section—to guard against
similar bugs in the future. We also fixed the bug, which is the reason these
diagrams exist. Once we pinpointed the faulty decision logic, I drew these diagrams
to convince myself of the correct behavior. Getting some thorough documentation
out of it was a nice bonus.&lt;/p&gt;
&lt;h3 id=&#34;testing&#34;&gt;Testing&lt;/h3&gt;
&lt;p&gt;We wrote a lot of debugging code to track down these bugs. One tool I wanted
early was a function &lt;code&gt;randomContainers()&lt;/code&gt; to randomly generate a slice of
containers with a variety of types. I accomplished this by choosing a random
cardinality, and then generating a container with that cardinality. With some
parameter tweaking, it was easy to get an acceptable variety.&lt;/p&gt;
&lt;p&gt;This lacked elegance. What I wanted was a function
&lt;code&gt;randomContainerOfType(type)&lt;/code&gt; to generate one container, guaranteed to be
a specified type. Stretch goal: the container should be selected uniformly at random
from all containers of that type. How might I do that?&lt;/p&gt;
&lt;p&gt;One approach: write a function &lt;code&gt;randomContainer(N, Nruns)&lt;/code&gt; that generates
a random container with a specified cardinality and runCount. Then I can call
that within &lt;code&gt;randomContainerOfType(type)&lt;/code&gt;, using randomly chosen pairs
(N, N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;) that fall into the correct regions of container space. That whole
thing might be wrapped up in &lt;code&gt;randomContainers()&lt;/code&gt;, which could generate
the three types with equal probability.&lt;/p&gt;
&lt;p&gt;How does &lt;code&gt;randomContainer(N, Nruns)&lt;/code&gt; work? Since &lt;code&gt;Nruns&lt;/code&gt; is known,
we should probably generate an RLE container. Remember, Roaring knows how to
convert container types, so we can generate it as whatever type is most
convenient. We need an RLE container with &lt;code&gt;Nruns&lt;/code&gt;, and the total number
of set bits among those runs is &lt;code&gt;N&lt;/code&gt;. It&amp;rsquo;s fairly easy to produce a list
of runs that satisfies these constraints. We do this by generating the
constrained run-lengths for both 1-runs and 0-runs, and converting those to the (start,
last) format used internally by Pilosa.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/container-generation-diagram.png&#34; alt=&#34;Container generation&#34;&gt;
&lt;em&gt;Random container generation&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/alanbernstein/pilosa/blob/rle-fuzz/roaring/fuzz_test.go#L95&#34;&gt;process&lt;/a&gt;
is illustrated here, and later I&amp;rsquo;ll revisit one last detail about how the
x and y values are generated&amp;hellip;&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;
&lt;em&gt;Nerd sniping (xkcd)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/mattjaffee&#34;&gt;Jaffee&lt;/a&gt; saw the container space diagram, and
made a remark similar to one that I made to myself
previously: &amp;ldquo;That array region is so small, it seems like it&amp;rsquo;s not even worth
the effort.&amp;rdquo; Of course, areas are deceptive in container space. There is no
direct correlation between the size of a region, and the number of sets in the
region, or the likelihood of a random set belonging to it. For example, a random
bitmap with a bit density of 5% is overwhelmingly likely to be an array, rather
than an RLE, &lt;em&gt;if the set bits are distributed uniformly randomly&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Or that&amp;rsquo;s what I assumed, at least. When someone else posed the question, I was
sniped. I had no choice but to validate that assumption. This served to satisfy
my curiosity more than anything else, but still, it&amp;rsquo;s good to know I understand
what I&amp;rsquo;m working on. So, I set out to answer the question &amp;ldquo;for a randomly chosen
bitmap with M = 65536 total bits, what is the probability of falling into each of
the three regions of container space?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I started out small: for M = 8, it&amp;rsquo;s easy to enumerate all 2&lt;!-- raw HTML omitted --&gt;8&lt;!-- raw HTML omitted --&gt; possible sets
and just count the number that belong to each point in the space. This produces
a low-resolution heatmap, where position corresponds to (N, N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;), and color
indicates the count for that (N, N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;) pair. For such a small M, there is
hardly any sense in switching container types, so I left the region boundaries
out of the plot.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/heatmap-8.png&#34; alt=&#34;Heatmap for M=8&#34;&gt;
&lt;em&gt;Brute force Heatmap for M=8&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For M = 256, that doesn&amp;rsquo;t work, 2&lt;!-- raw HTML omitted --&gt;256&lt;!-- raw HTML omitted --&gt; is way too big. Instead, I
sampled random sets and counted their (N, N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;) in a 256x128 grid. A million
iterations captures a decent portion of the space, and with some tweaking I
figured I could fill that out. Note that this one is in logarithmic scale. Greenish
pixels, labeled 74 in the color scale on the right, represent counts of 10&lt;!-- raw HTML omitted --&gt;74&lt;!-- raw HTML omitted --&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/heatmap-256.png&#34; alt=&#34;Heatmap for M=256&#34;&gt;
&lt;em&gt;Stochastic heatmap for M=256&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But I wanted something that would even work for M = 65536. The same sampling
approach can be used, but the space is too big. No reasonable number of samples
could get a decent picture of the distribution.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/heatmap-65536-stochastic.png&#34; alt=&#34;Stochastic Heatmap for M=65536&#34;&gt;
&lt;em&gt;Stochastic Heatmap for M=65536&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;That thing that looks like a speck of dust on your screen, that&amp;rsquo;s the result. Zooming
in, you can see all the samples are clustered around the center of the space
(M/2, M/4) = (32768, 16384).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/heatmap-65536-stochastic-zoom.png&#34; alt=&#34;Zoomed Stochastic Heatmap for M=65536&#34;&gt;
&lt;em&gt;Stochastic Heatmap for M=65536, zoom view&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;See, that just seems futile. I realized there was another approach: an analytical solution.
I thought about that for a bit, then remembered the work I did on generating
random containers, which solves almost the same problem. That is, if I know how
to generate a random container given (N, N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;), I should be able to count the
number of possible outcomes of that event. If I can reduce that to an analytical
expression, then I can simply examine that as a function, rather than use Monte
Carlo simulation on the impossibly large space.&lt;/p&gt;
&lt;p&gt;After a detour through a &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S0898122109005744&#34;&gt;paper&lt;/a&gt;
addressing a similar but much more general question, and verification from some helpful
stackexchange &lt;a href=&#34;https://math.stackexchange.com/questions/2391769/what-is-the-number-of-binary-strings-of-length-n-with-exactly-r-runs-of-ones-wi&#34;&gt;answerers&lt;/a&gt;,
I found the expression I needed:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/container-space-expression.png&#34; alt=&#34;Container Space Expression&#34;&gt;
&lt;em&gt;Analytical form of container space distribution&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If you look at the actual &lt;a href=&#34;https://github.com/alanbernstein/pilosa/blob/rle-fuzz/roaring/fuzz_test.go#L95&#34;&gt;&lt;code&gt;randomContainer&lt;/code&gt;&lt;/a&gt;
code, you can see exactly where this comes from: the two &lt;code&gt;randomPartition&lt;/code&gt; calls
correspond to the two terms in the expression. The truncated permutation
&lt;a href=&#34;https://en.wikipedia.org/wiki/Hand-waving&#34;&gt;obviously&lt;/a&gt; chooses one of a
binomial-coefficient number of possible events.&lt;/p&gt;
&lt;p&gt;So I just needed a way to compute this, accurately and efficiently, for large values
of M, N, N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;. After another few iterations, I decided that simply summing
the values of F&lt;!-- raw HTML omitted --&gt;M&lt;!-- raw HTML omitted --&gt; over the appropriate regions was the way to go. The numbers
involved are so big that it only makes sense to do this in the logarithmic domain. That
means numbers are stored as base-10 exponents, products are sums, and sums are
calculated as &lt;code&gt;y + math.log10(1 + 10 ** (x-y))&lt;/code&gt;. Since that sidesteps costly bignum
binomial-coefficient calculations, it helps with the speed quite a bit. It can even
help avoid those log-domain sums in some cases, because
10&lt;!-- raw HTML omitted --&gt;50&lt;!-- raw HTML omitted --&gt; + 10&lt;!-- raw HTML omitted --&gt;60&lt;!-- raw HTML omitted --&gt; ≈ 10&lt;!-- raw HTML omitted --&gt;60&lt;!-- raw HTML omitted --&gt;. I&amp;rsquo;m not looking for exact integer
answers here, so I&amp;rsquo;m not too worried about an approximation that&amp;rsquo;s only accurate to nine
decimal places.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/heatmap-65536-analytical.png&#34; alt=&#34;Analytical Heatmap for M=65536&#34;&gt;
&lt;em&gt;Analytical Heatmap for M=65536&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Finally, we come to the motivating question: when choosing one bitmap among all
possible bitmaps of length 65536, what is the probability of falling into each
of the container type regions? With that expression for F&lt;!-- raw HTML omitted --&gt;M&lt;!-- raw HTML omitted --&gt; in hand,
it&amp;rsquo;s a relatively simple matter to count the sets in each region, then divide
by the total to get a probability. The answer is even simpler: all sets are bitmaps.&lt;/p&gt;
&lt;p&gt;Wait, that doesn&amp;rsquo;t sound right&amp;hellip; Actually, the question was wrong. We made the
mistake of trying to look at all possible sets. In that context, the vast
majority of them are right in the middle of container space, in that bright yellow
spot in the bitmap region. Let&amp;rsquo;s pick just one point somewhere in the RLE region:
sets with cardinality 2000, and 50 runs. There are&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;(2.28×10&lt;!-- raw HTML omitted --&gt;274&lt;!-- raw HTML omitted --&gt;) sets matching this criterion. But that number is
inconceivably tiny compared to the number of bitmaps with cardinality 30000 and
10000 runs: 3.69×10&lt;!-- raw HTML omitted --&gt;17459&lt;!-- raw HTML omitted --&gt;, a number with about as many digits as there
are letters in this blog post.&lt;/p&gt;
&lt;p&gt;The numbers for the full regions are equally absurd; The bitmap region contains
the vast majority, 2.00×10&lt;!-- raw HTML omitted --&gt;19728&lt;!-- raw HTML omitted --&gt;, which is almost exactly the same as
the total count. There are approximately 9.96×10&lt;!-- raw HTML omitted --&gt;6651&lt;!-- raw HTML omitted --&gt; array sets, and
9.96×10&lt;!-- raw HTML omitted --&gt;6651&lt;!-- raw HTML omitted --&gt; RLE sets. Those look the same, which is an interesting clue.
Actually, they agree out to the eighth digit, and arrays outnumber RLEs by a small
relative margin.&lt;/p&gt;
&lt;p&gt;This is what combinatorial explosion looks like in a universe containing
2&lt;!-- raw HTML omitted --&gt;65536&lt;!-- raw HTML omitted --&gt; elements. But we don&amp;rsquo;t have to stop here, we just have to ask
different questions.&lt;/p&gt;
&lt;p&gt;For example, what happens if we ask the same question about region probabilities,
but for a range of different bit depths? That is, Pilosa uses M = 65536, and
M&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt; and M&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt; are dictated by the 16-bit array elements. Since
we&amp;rsquo;re off in la-la-land anyway, why not consider what things look like for different
values of these parameters?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/container-count-vs-M.png&#34; alt=&#34;Container count vs universe size&#34;&gt;
&lt;em&gt;Container count vs universe size&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The scale here is a little wonky: the x axis is logarithmic and the y axis doubly
logarithmic. That means the gap between the two pairs of lines is huge - a factor
of 10&lt;!-- raw HTML omitted --&gt;165&lt;!-- raw HTML omitted --&gt; for M=1024, for example. In short, that means bitmaps dominate
in probability for all M. This is why the &lt;em&gt;bitmap&lt;/em&gt; and &lt;em&gt;total&lt;/em&gt; curves coincide. Why
do the &lt;em&gt;array&lt;/em&gt; and &lt;em&gt;RLE&lt;/em&gt; curves coincide for large M? I&amp;rsquo;m not sure, but I wonder if
there is a simple counting argument to explain this. There is some discrepancy for
small M, so the near-equality appears asymptotic.&lt;/p&gt;
&lt;p&gt;Getting back to the Pilosa world, what happens if we stick with M = 65536, but
restrict bit density? That is, instead of looking at all possible bitmaps, let&amp;rsquo;s
look at a smaller portion of the space: bitmaps with a specific cardinality N. If
we do this computation for a range of values of N, we can examine the container
type distribution as a function of the bit density.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/container-count-vs-N.png&#34; alt=&#34;Container count vs cardinality&#34;&gt;
&lt;em&gt;Container count vs cardinality&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/container-count-vs-N-zoom.png&#34; alt=&#34;Zoomed container count vs cardinality&#34;&gt;
&lt;em&gt;Container count vs cardinality, zoom view&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;What exactly are we looking at here? The x-axis is cardinality, and the y-axis
is the count of all sets, in log scale again. Curves are shown for each of the
four types, but we can focus on the first three. This really shows
the difference in magnitude between the container types, and reiterates the
&amp;ldquo;everything is a bitmap&amp;rdquo; result. You can see the behavior on both sides
of the &lt;code&gt;ArrayMaxSize&lt;/code&gt; threshold: for N &amp;lt; M&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt;, containers can be
either arrays or runs, and arrays outnumber runs dramatically. Even at very low
cardinality, arrays are more than a googol times more likely than runs. When
N &amp;gt; M&lt;!-- raw HTML omitted --&gt;A&lt;!-- raw HTML omitted --&gt;, bitmaps replace arrays, and runs are still possible,
but again bitmaps outnumber them dramatically.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;At this point, my intuitive answer to Jaffee&amp;rsquo;s question seems to be confirmed:
The area of a region in container space does not necessarily correspond to the
count of sets belonging to the region. The specific result suggests a new
question: if the number of sets in the RLE region is so small, why is THAT worth
using as a separate container type?&lt;/p&gt;
&lt;p&gt;One problem with the above analysis is that we&amp;rsquo;re considering a uniform distribution
across all sets in the 2&lt;!-- raw HTML omitted --&gt;65536&lt;!-- raw HTML omitted --&gt;-bit universe. Even when I restricted N, I
still used a uniform distribution for N&lt;!-- raw HTML omitted --&gt;R&lt;!-- raw HTML omitted --&gt;. I didn&amp;rsquo;t have any fundamental
reason for picking that distribution, it&amp;rsquo;s just the simplest thing to look at. What
if we used some distribution based on real-world data?&lt;/p&gt;
&lt;p&gt;Another great question, for another post. There are quite a few variables to consider
here: the dataset, the mapping used to index it, and the order data is imported into
Pilosa, among others. Perhaps most importantly, I&amp;rsquo;ve left out any discussion of query
speed, which is another area RLE shines. I started looking at the &lt;a href=&#34;https://www.pilosa.com/use-cases/taming-transportation-data/&#34;&gt;Taxi dataset&lt;/a&gt;,
where I noticed a number of effects, with a strong dependence on the frame (and the
structure of the data contained within). I do have a brief summary of some benchmarks,
which demonstrate the value of adding RLE:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/universe-map/rle-query-benchmarks-2017-08-10.png&#34; alt=&#34;RLE Benchmarks&#34;&gt;
&lt;em&gt;Preliminary RLE benchmarks&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But there is more work to do, to understand these effects and dependencies fully.
That is a different sort of undertaking, which we&amp;rsquo;ll be exploring as part of
several upcoming posts on benchmarks.&lt;/p&gt;
&lt;p&gt;Figures were created with LaTeX or &lt;a href=&#34;https://plot.ly/&#34;&gt;plotly&lt;/a&gt;, source available
&lt;a href=&#34;https://github.com/pilosa/latex-figures/&#34;&gt;here&lt;/a&gt; and
&lt;a href=&#34;https://github.com/alanbernstein/roaring-container-theory&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Alan is a software engineer at Pilosa. When he’s not mapping the universe, you can find him playing with laser cutters, building fidget spinners for his dog, or practicing his sick photography skills. Find him on Twitter &lt;a href=&#34;https://twitter.com/gsnark&#34;&gt;@gsnark&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Pilosa 0.6.0 Released</title>
          <link>https://www.pilosa.com/blog/pilosa-0-6-0-released/</link>
          <pubDate>Fri, 11 Aug 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/pilosa-0-6-0-released/</guid>
          <description>&lt;p&gt;The Pilosa team is happy to announce the release of &lt;a href=&#34;https://github.com/pilosa/pilosa/releases/tag/v0.6.0&#34;&gt;Pilosa 0.6.0&lt;/a&gt;, massively speeding up Pilosa with &lt;a href=&#34;https://www.pilosa.com/blog/adding-rle-support/&#34;&gt;Run-length Encoding&lt;/a&gt;. This release comes just days after Pilosa 0.5.0, which introduced &lt;a href=&#34;https://www.pilosa.com/docs/input-definition/&#34;&gt;Input Definition&lt;/a&gt;. The two releases combined represent 79 contributions from 9 contributors.&lt;/p&gt;
&lt;p&gt;This release includes:&lt;/p&gt;
&lt;h3 id=&#34;run-length-encoding&#34;&gt;Run-length Encoding&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Run-length_encoding&#34;&gt;Run-length Encoding&lt;/a&gt; (RLE) is a simple technique for data compression. RLE enhances our existing Roaring implementation for improved performance and reduced data storage requirements. Read more about our Roaring implementation and RLE in our &lt;a href=&#34;https://www.pilosa.com/blog/adding-rle-support/&#34;&gt;blog post&lt;/a&gt; and &lt;a href=&#34;https://www.pilosa.com/docs/architecture/#roaring-bitmap-storage-format&#34;&gt;the docs&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;input-definition&#34;&gt;Input Definition&lt;/h3&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Input Definition is the first in a series of features that enable real-time Extract, Transform, and Load (ETL) processing within Pilosa. While we technically shipped Input Definition in Pilosa 0.5.0 a few days ago, we decided to combine the two announcements for simplicity&amp;rsquo;s sake. Read more about it in &lt;a href=&#34;https://www.pilosa.com/docs/input-definition/&#34;&gt;the docs&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;changelog&#34;&gt;Changelog&lt;/h3&gt;
&lt;p&gt;To see the complete list of new features, fixes, and performance improvements, check out &lt;a href=&#34;https://github.com/pilosa/pilosa/blob/master/CHANGELOG.md&#34;&gt;our changelog on Github&lt;/a&gt;.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Self Deploying Applications With Go</title>
          <link>https://www.pilosa.com/blog/self-deploying-applications/</link>
          <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/self-deploying-applications/</guid>
          <description>&lt;p&gt;What if your apps handled their own ops? That&amp;rsquo;s kind of like devops&#39; final form,
right? Its ultimate evolution? The Charizard of devops, if you will.&lt;/p&gt;
&lt;p&gt;Inspiration to write about this comes from Kelsey Hightower who had a good talk
at Gophercon about
&lt;a href=&#34;https://www.youtube.com/watch?v=XPC-hFL-4lU&#34;&gt;Self Deploying Kubernetes Applications&lt;/a&gt;.
Here&amp;rsquo;s the TLDR;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;myapp --kubernetes --replicas=5&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;myapp compiles itself statically for Linux, containerizes itself, and deploys to
a Kubernetes cluster with 5 replicas. No config files needed.&lt;/p&gt;
&lt;p&gt;I thought this was extremely cool, and immediately went to check out Kubernetes
to see if I could add something like it to Pilosa. Kubernetes&#39; docs have a page
dedicated to &amp;ldquo;picking the right solution,&amp;rdquo; which has 40+ different ways to get
going with Kubernetes, none of which (as far as I could tell) were &amp;ldquo;run this
binary&amp;rdquo;. Bleeeeccchhh - I don&amp;rsquo;t want to dig through pages of documentation just
for a quick experiment! I know based on what I&amp;rsquo;ve seen of Kubernetes and its
community that it&amp;rsquo;s great software, and I&amp;rsquo;m willing to bet we&amp;rsquo;ll be deploying
Pilosa to our own Kubernetes cluster one day soon. On this particular day,
however, I was really smitten with the &amp;ldquo;self-deploying applications&amp;rdquo; idea, not
the &amp;ldquo;on Kubernetes&amp;rdquo; part.&lt;/p&gt;
&lt;p&gt;I realized, in fact, that I&amp;rsquo;d already done some work in this direction for
Pilosa&amp;rsquo;s benchmarking suite. The original idea was to build a tool which would,
with a single command:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;provision cloud infrastructure on various providers&lt;/li&gt;
&lt;li&gt;install and start a Pilosa cluster on remote hosts&lt;/li&gt;
&lt;li&gt;allow for highly configurable benchmarks to be defined&lt;/li&gt;
&lt;li&gt;install and run benchmarks on remote &amp;ldquo;agent&amp;rdquo; hosts&lt;/li&gt;
&lt;li&gt;gather the results of the benchmarks&lt;/li&gt;
&lt;li&gt;gather host metrics (cpu, memory, etc.)&lt;/li&gt;
&lt;li&gt;store all the data from each benchmark run in a consistent format&lt;/li&gt;
&lt;li&gt;make and serve delicious iced beverages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wow, once that I put it in a list like that it looks pretty ridiculous - now I
understand why it has taken us something like 8 months (albeit while working
on &lt;a href=&#34;https://github.com/pilosa/pilosa&#34;&gt;Pilosa&lt;/a&gt; itself as well). In any case,
we&amp;rsquo;ve actually achieved a few of those goals with a new tool
called &lt;a href=&#34;https://github.com/pilosa/tools&#34;&gt;Pi&lt;/a&gt; which we are open sourcing &lt;em&gt;today&lt;/em&gt;.
Pi is a tool specifically for benchmarking Pilosa, but I think it contains some
reusable ideas and libraries that could be beneficial to the open source
community at large (also we&amp;rsquo;d love to get some help improving it).&lt;/p&gt;
&lt;p&gt;Right, but self deploying applications, that&amp;rsquo;s why you&amp;rsquo;re here. Let&amp;rsquo;s set aside
the cloud provisioning part of the equation for now, and say you have a set of
fresh, clean, Linux hosts to which you have ssh access, and you want to
benchmark Pilosa. You&amp;rsquo;ve got Pilosa&amp;rsquo;s codebase locally (in your &lt;code&gt;GOPATH&lt;/code&gt;) as
well as the mythical Pi tool. What&amp;rsquo;s the least amount of work you could
expect to do to run a benchmark against a Pilosa cluster and gather the results?&lt;/p&gt;
&lt;p&gt;How about running a single command, on your laptop, in a crowded, local coffee
shop, in the heart of Austin TX?&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pi spawn --pilosa-hosts=&amp;lt;...&amp;gt; --agent-hosts=&amp;lt;...&amp;gt; --spawn-file=~/my.benchmark&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You hit enter, and a few minutes later you&amp;rsquo;ve got benchmarking data in front of
you. A multi-node Pilosa cluster was created along with a number of agent hosts
to send queries to it. The agents spewed huge amounts of realistically
distributed random data into the cluster, and then followed it up with a battery
of complex queries.&lt;/p&gt;
&lt;p&gt;Keep in mind that before you ran Pi, that pool of remote hosts had no
knowledge of Go, Pilosa, Pi, or anything else. They were just the stock
Linux images from AWS or GCP or whatever.&lt;/p&gt;
&lt;p&gt;How can we do that? Let&amp;rsquo;s break this down: first of all, we need to be able to
connect with remote hosts via ssh inside a Go program. Turns out Go has a pretty
great &lt;a href=&#34;https://godoc.org/golang.org/x/crypto/ssh&#34;&gt;ssh package&lt;/a&gt; which handles most
of this for us. Once we&amp;rsquo;re connected to remote hosts, we can execute commands at
a shell just like we would from a terminal! We get standard &lt;code&gt;Reader&lt;/code&gt; and
&lt;code&gt;Writer&lt;/code&gt; interfaces for getting data into and out of those commands, so
everything is pretty hunky-dory. But what do we run? These hosts don&amp;rsquo;t have
Pilosa or Pi installed, both of which we&amp;rsquo;ll need if we want to start a cluster
and benchmark it.&lt;/p&gt;
&lt;p&gt;Well, let&amp;rsquo;s just run &lt;code&gt;cat&lt;/code&gt; - these hosts definitely have that, right?
I&amp;rsquo;m pretty sure it&amp;rsquo;s the law (or at least specified by POSIX) that Linux hosts
must have &lt;code&gt;cat&lt;/code&gt;. Specifically, we&amp;rsquo;ll run &lt;code&gt;cat &amp;gt; pilosa&lt;/code&gt; - remember that
&lt;code&gt;Writer&lt;/code&gt;? It&amp;rsquo;s actually an &lt;code&gt;io.WriteCloser&lt;/code&gt;, and it goes straight to &lt;code&gt;cat&lt;/code&gt;&amp;rsquo;s
&lt;code&gt;stdin&lt;/code&gt;. So we just write the whole Pilosa binary right into there, close it,
and the data is magically transported to a file on the remote host!&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Wait.&amp;rdquo; you say&amp;hellip; &amp;ldquo;What binary? Your laptop in that hip coffee shop in ATX is a
Macbook Pro (obviously), you don&amp;rsquo;t have a Linux binary for Pilosa.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;As you may have guessed, Go saves the day again by making it &lt;em&gt;stupidly&lt;/em&gt; easy to
cross compile for other platforms. Now, I know what you&amp;rsquo;re thinking: &amp;ldquo;This is
about to get SWEET; he&amp;rsquo;s gonna import the packages for Go&amp;rsquo;s compiler, build the
new Pilosa binary directly in memory, and stream it straight into &lt;code&gt;cat&lt;/code&gt; running
on the remote host. I CAN&amp;rsquo;T WAIT!&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Yeah, no, sorry - this is the guy that couldn&amp;rsquo;t be bothered to run a VM to try
out Kubernetes. I looked at the source for the toolchain for a hot minute and
decided to use &lt;code&gt;os/exec&lt;/code&gt; to run &lt;code&gt;go build&lt;/code&gt; in a subprocess.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;com := exec.Command(&amp;quot;go&amp;quot;, &amp;quot;build&amp;quot;, &amp;quot;-o&amp;quot;, &amp;quot;someTempFile&amp;quot;, &amp;quot;https://github.com/pilosa/pilosa&amp;quot;)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Oh, and we need to set the environment to make sure we build for Linux:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;com.Env = append(os.Environ(), &amp;quot;GOOS=linux&amp;quot;)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Not bad - open the temp file, &lt;code&gt;cat&lt;/code&gt; it to the remote host, a little &lt;code&gt;chmod&lt;/code&gt;
action to make it executable, and we&amp;rsquo;re in business. Let&amp;rsquo;s take a moment to
reflect upon how much Go helped us there - not just the ease of cross
compilation, but the fact that we can compile a standalone binary which is
fairly lightweight (ok like 12 megs, but that&amp;rsquo;s not &lt;em&gt;too&lt;/em&gt; bad), and that&amp;rsquo;s all
we need in order to run our application on another host. No JVM, no interpreter
(and no worrying about version compatibility of those things with our thing) -
it&amp;rsquo;s really just very refreshing - like a delicious iced beverage.&lt;/p&gt;
&lt;p&gt;Alright, so the Pilosa binary is in place; we can build a config file, and copy
it over the same way, or just start Pilosa with command line arguments. Once it&amp;rsquo;s
running, we can stream any logs back to us, or drop them in a file on the remote
host.&lt;/p&gt;
&lt;p&gt;Let us turn our attention to the task at hand - B E N C H M A R K I N G.
Strictly speaking, we haven&amp;rsquo;t created a &lt;em&gt;self&lt;/em&gt;-deploying application yet, we&amp;rsquo;ve
created a Pilosa deploying application - remember it&amp;rsquo;s Pi which is doing all
this stuff. But we need to run Pi on remote hosts as well because Pi has all the
benchmarking tools, and there&amp;rsquo;s no reason this cross-compiling &lt;code&gt;cat&lt;/code&gt;ing business
won&amp;rsquo;t work just as well on the source code of the very program which is running
it.&lt;/p&gt;
&lt;p&gt;We cross-compile Pi, copy it to each of the &amp;ldquo;agent&amp;rdquo; hosts, figure out which
benchmarks we&amp;rsquo;re actually supposed to run, and run them! Pi&amp;rsquo;s benchmarks report
their results in JSON format on stdout which we happily collect and aggregate
back in the coffee shop. This is CRAZY, but again, we owe a debt to Go for
providing us with a concurrency model which makes this very straightforward.
We&amp;rsquo;re running multiple, different programs on multiple remote hosts, which are
throwing huge amounts of data at each other and doing massive computation. All
this from one program on one laptop with a crappy WiFi connection. Not to
mention that we&amp;rsquo;re streaming and combining the output from all those remote
programs into a single cohesive result structure which fully describes the
benchmark. This would truly be a nightmare in most languages.&lt;/p&gt;
&lt;p&gt;So, there you have it. A self-deploying application &lt;em&gt;without&lt;/em&gt; Kubernetes. All
you need is a pile of hosts to which you have ssh access and you too can make
complex fleets of self-deploying programs.&lt;/p&gt;
&lt;p&gt;Check out the source code for &lt;a href=&#34;https://github.com/pilosa/tools&#34;&gt;Pi&lt;/a&gt; (especially the
&lt;code&gt;build&lt;/code&gt; and &lt;code&gt;ssh&lt;/code&gt; packages), and read the docs if you want to really know how to
use it - I glossed over a bunch of details and made some stuff up to make it
seem approachable 😉. Patches welcome!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Jaffee is a lead software engineer at Pilosa. When he’s not building self-deploying applications in coffee shops, you can find him practicing jiu-jitsu, woodworking, or building mechanical keyboards. Find him on Twitter at &lt;a href=&#34;https://twitter.com/mattjaffee?lang=en&#34;&gt;@mattjaffee&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Gophercon 2017: Technical Overview</title>
          <link>https://www.pilosa.com/blog/gophercon-2017-technical-overview/</link>
          <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/gophercon-2017-technical-overview/</guid>
          <description>&lt;p&gt;In addition to sponsoring Gophercon 2017, our team sent several of us engineers to Gophercon. Predictably, we all had a blast.&lt;/p&gt;
&lt;p&gt;As you may have guessed, Pilosa is written in Go, so this conference was particularly important to us. We felt that we should try to get the most from our time in Denver, so between us, we attended every. Single. Talk. Like all good Gophers, we used the time between sessions to compare notes and discuss takeaways from each.&lt;/p&gt;
&lt;p&gt;Three of us put together topline selection of our findings, although we will be writing more in the next few weeks and doing some deep dives about our favorite sessions.&lt;/p&gt;
&lt;h3 id=&#34;jaffee-forward-compatible-go-code&#34;&gt;Jaffee: Forward Compatible Go Code&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=OuT8YYAOOVI&amp;amp;index=3&amp;amp;list=PL2ntRZ1ySWBdD9bru6IR-_WXUgJqvrtx9&#34;&gt;Joe Tsai&amp;rsquo;s talk&lt;/a&gt; on what is – and more importantly – what isn&amp;rsquo;t in the Go 1 compatibility promise had both immediate and long term ramifications for Pilosa. One thing people love to do for new Go releases is benchmark their performance against the past release; as we near Go 1.9, I&amp;rsquo;m looking forward to seeing what effect the new compiler and runtime has on Pilosa&amp;rsquo;s performance. As I was watching Joe&amp;rsquo;s talk, however, it occurred to me that we might not be able to trust all of our benchmarks to provide consistent results during the transition.&lt;/p&gt;
&lt;p&gt;Many of Pilosa&amp;rsquo;s benchmarks use &lt;code&gt;math/rand&lt;/code&gt; to generate random data before querying it. We always provide a fixed seed to the random number generator so that we can have more reproducible results across each run of a given benchmark. How sparsely or densely data is stored in Pilosa, along with how it&amp;rsquo;s distributed (bunched up or spread evenly?) can have a significant impact on performance. Joe&amp;rsquo;s talk called out &amp;ldquo;packages with unstable output&amp;rdquo;, and one of them was &lt;code&gt;math/rand&lt;/code&gt;. When we upgrade to 1.9 and run benchmarks that use &lt;code&gt;math/rand&lt;/code&gt;, we won&amp;rsquo;t necessarily be generating the same data sets that we were previously, and therefore it&amp;rsquo;s difficult to know if performance changes are due to the new Go version, or just due to different data. Armed with this knowledge, however, we can do multiple runs with different random seeds and compare the average performance across the two Go versions. As long as we account for stark outliers, we should be able to get a pretty good idea of how the new version of Go is affecting performance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/gophercon-2017-technical-overview/regression-testing-failures.png&#34; alt=&#34;Regression Testing Failures&#34;&gt;&lt;/p&gt;
&lt;p&gt;Joe&amp;rsquo;s talk had many other pieces of wisdom, but one that I thought stood out was a chart showing the number of the test failures in Go over a release cycle, above. Go&amp;rsquo;s release cycle consists of 3 months of feature additions plus 3 months of code freeze and testing. Spending half of your dev time with a frozen code base might seem like overkill, but to me, this chart clearly showed the benefits of code freezes in complex projects. The code freeze started right at the center of this chart where the blue area is at its apex. Extrapolating from the data, one can imagine what might happen if the code freeze were not enforced: the project would
accrete a critical mass of bugs and slowly suffocate under the burden. Development and maintenance of a project with a huge number of bugs and stability issues is like going for a run in a pool of molasses.&lt;/p&gt;
&lt;p&gt;Until now, Pilosa&amp;rsquo;s release cycle has been fairly fast and loose – bugs and stability problems are generally prioritized higher than other issues, but it isn&amp;rsquo;t a hard rule. In light of this chart, we&amp;rsquo;ll have to carefully consider how we want to manage our release cycle as we march steadily closer to Pilosa v1.0.&lt;/p&gt;
&lt;h3 id=&#34;linh-advanced-testing-with-go&#34;&gt;Linh: Advanced Testing with Go&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mitchellh&#34;&gt;Mitchell Hashimoto&lt;/a&gt;, the founder of HashiCorp, delivered an incredibly dense &lt;a href=&#34;https://www.youtube.com/watch?v=8hQG7QlcLBk&amp;amp;list=PL2ntRZ1ySWBdD9bru6IR-_WXUgJqvrtx9&amp;amp;index=12&#34;&gt;keynote on Go testing patterns&lt;/a&gt; employed at his company. To illustrate what I mean by dense: His keynote covered 30 entirely different methods of writing testable codes. While he mentioned being unsure as to whether his keynote would be beneficial for everyone, I learned quite a few valuable lessons.&lt;/p&gt;
&lt;p&gt;A common thread throughout his talk was that you can’t just take any kind of code and test it. Mitchell declared that there are two different but equally important components of a good test: test methodology, or how you write tests, and writing testable code. Hint: It’s a lot more complicated than just using &lt;code&gt;assert(func() == expected)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Writing testable code implies writing code in a way that can be easily tested, which is harder than it sounds. Like many other developers, I often write code that I think can’t be tested. But the truth is I might have written the code in a way made it too hard to test. While rewriting code so it can testable seems painful, Mitchell’s talk proved that it can be worthwhile in the long run.&lt;/p&gt;
&lt;p&gt;Throughout his keynote, Mitchell introduced his testing methods in greater detail. He started with simple testing methods and proceeded to more advanced techniques, such as table driven tests to interfaces and mocks. One of the good tip (that I used to ignore) was that even with a single test case, we can still set up a table driven structure, as there may a scenario we want to test other parameters on in the future.&lt;/p&gt;
&lt;p&gt;He also covered testing features in newer Go versions, such as subtest in Go 1.8, which we have been adopting for our own tests as we upgrade to Go 1.8, and test helper in Go 1.9. I encourage you to find out more of these important features by watching Mitchell’s talk online, &lt;a href=&#34;https://www.youtube.com/watch?v=8hQG7QlcLBk&amp;amp;list=PL2ntRZ1ySWBdD9bru6IR-_WXUgJqvrtx9&amp;amp;index=12&#34;&gt;posted here&lt;/a&gt;. While we may not apply all of his methods to improve Pilosa test coverages, they’re useful guidance in our efforts to achieve greater test coverage, and more readable, maintainable, simpler code.&lt;/p&gt;
&lt;h3 id=&#34;travis-go-build-modes&#34;&gt;Travis: Go Build Modes&lt;/h3&gt;
&lt;p&gt;David Crawshaw&amp;rsquo;s &lt;a href=&#34;https://www.youtube.com/watch?v=x-LhC-J2Vbk&amp;amp;index=7&amp;amp;list=PL2ntRZ1ySWBdD9bru6IR-_WXUgJqvrtx9&#34;&gt;talk on Go Build Modes&lt;/a&gt; was very in-depth and provided really good insight to anyone interested in the various build modes available to Go developers. He covered all eight build modes currently supported by the Go compile tool chain:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;exe (static)&lt;/li&gt;
&lt;li&gt;exe (with libc)&lt;/li&gt;
&lt;li&gt;exe (with libc and non-Go code)&lt;/li&gt;
&lt;li&gt;pie&lt;/li&gt;
&lt;li&gt;c-archive&lt;/li&gt;
&lt;li&gt;c-shared&lt;/li&gt;
&lt;li&gt;shared&lt;/li&gt;
&lt;li&gt;plugin&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given that we at Pilosa have committed a fair amount of resources toward building and testing Go plugins (available in Go as of version 1.8), I was curious to get David&amp;rsquo;s perspective on them. Not surprisingly, his assessment of plugins pretty much corroborated the conclusion we had already come to: &amp;ldquo;If you ask me &amp;lsquo;should I use plugins?&amp;rsquo; the answer is no&amp;rdquo;. In general, it
seems like plugins are only useful when you have an extremely large development team working on a single code base.&lt;/p&gt;
&lt;p&gt;In addition to the &lt;code&gt;plugin&lt;/code&gt; build mode, it was interesting to hear David&amp;rsquo;s explanation of the &lt;code&gt;pie&lt;/code&gt; build mode. This build mode, which stands for &amp;ldquo;Position Independent Executables&amp;rdquo; was new to me. From the outside, it behaves exactly like a standard executable, but internally it allows the executable to be placed anywhere in memory. To accomplish this, the compiler uses relative addressing in jump instructions. Where the linker would typically know exactly what position in memory a jump instruction should point to, relative addressing allows the jump instruction to point to a position in memory relative to the current instruction. All of this helps support an OS security feature called ASLR (address space layout randomization), which places an executable in a different space in memory every each time the executable starts. This repositioning of the executable helps to mitigate security attacks, and in fact &lt;code&gt;pie&lt;/code&gt; is required by some operating systems like Android OS.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Cover image artwork was created using the Gopherize.me app created by Ashley McNamara and Mat Ryer, with artwork inspired by Renee French.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>How Gophercon Changed Pilosa’s Approach to Community</title>
          <link>https://www.pilosa.com/blog/how-gophercon-changed-pilosas-approach-to-community/</link>
          <pubDate>Fri, 21 Jul 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/how-gophercon-changed-pilosas-approach-to-community/</guid>
          <description>&lt;p&gt;Like all avid Gophers, several Pilosa team members made the annual pilgrimage to Denver, CO for this year’s highly anticipated paean to all things Go.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gophercon.com/&#34;&gt;Gophercon 2017&lt;/a&gt;  was full of surprises, not the least of which being the announcement of &lt;a href=&#34;https://blog.golang.org/toward-go2&#34;&gt;Go 2.0 by Russ Cox&lt;/a&gt;, one of the early co-creators of the language. Perhaps not as surprising was the uniformly high quality of the keynotes, workshops, and lightning talks throughout the conference. Of note are Liz Rice’s &lt;a href=&#34;https://about.sourcegraph.com/go/a-go-guide-to-syscalls&#34;&gt;tutorial on syscalls&lt;/a&gt; and Joe Tsai’s &lt;a href=&#34;https://about.sourcegraph.com/go/forward-compatible-go-code&#34;&gt;presentation on forward compatible Go code&lt;/a&gt;, though don’t confuse our adoration with these workshops as a slight to the other incredible presentations throughout the conference.&lt;/p&gt;
&lt;p&gt;Perhaps our favorite presentation, and by far the most moving, was Ashley MacNamara’s keynote, &lt;a href=&#34;https://about.sourcegraph.com/go/my-journey-to-go&#34;&gt;My Journey to Go&lt;/a&gt;. As the closest thing Pilosa has to a community manager and an aspiring coder myself, I must admit that I’ve become rather obsessed with it. And while the point of this post is not to summarize her amazing talk, I encourage you to read the Gophercon live blog recap, &lt;a href=&#34;https://about.sourcegraph.com/go/my-journey-to-go&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ashley’s fresh perspective on the human connections that create and define community are particularly relevant for our team as we navigate our first foray into open source. Even before we launched this past April, we spent hours discussing the type of community we wanted to build. Terms like “diversity,” “creativity,” and “brilliance” were thrown around in meetings and conference rooms, and we vowed to create the most amazing community possible.&lt;/p&gt;
&lt;p&gt;What we’ve found, of course, is that it’s one thing to talk about your dream community, and another to actually go out and build it. Our entire team has been all hands on deck since Launch, pounding the pavement to conferences, churning out some beautiful docs, and even overcoming their ambivalence to social media platforms, all just to get the word out about the incredible software they’ve devoted countless hours to building and perfecting.&lt;/p&gt;
&lt;p&gt;And we’ve had some amazing success! At present, our &lt;a href=&#34;https://github.com/pilosa/pilosa&#34;&gt;GitHub repository&lt;/a&gt; has attracted an amazing 1,071 Stargazers and counting! We&amp;rsquo;ve also had some amazing contributions from members of this growing community. But as Ashley’s talk demonstrates, building community is about more than promoting what you’ve done. It’s about creating a space where anyone, even a beginner, feels welcome to hone their skills, ask “silly” questions, fail, fail again, and learn about their craft among friends who will accept and mentor them. It’s about getting to know the people behind the project, not just their contributions.&lt;/p&gt;
&lt;p&gt;Coincidentally, a few of our developers have begun to embrace this philosophy on their own. &lt;a href=&#34;https://manishearth.github.io/blog/2016/01/03/making-your-open-source-project-newcomer-friendly/&#34;&gt;Making Your Open Source Project Newcomer-friendly&lt;/a&gt;, a great blog post by Manish Goregaokar, made the rounds in our office just as Ashley began her presentation. Inspired by it, one of our engineers crowd-sourced a response to one of our contributors to make sure he sounded appropriately encouraging. Another created a &lt;a href=&#34;https://github.com/pilosa/pilosa/issues?q=is%3Aopen+is%3Aissue+label%3Anewcomer&#34;&gt;newcomer label&lt;/a&gt; to our docs.&lt;/p&gt;
&lt;p&gt;Ok, perhaps it wasn’t pure coincidence. I firmly believe that releasing a sentiment into the ether makes it mysteriously more accessible, even to those not in its direct line of communication. Kind of like learning a new word and then suddenly noticing it everywhere you go.&lt;/p&gt;
&lt;p&gt;We still have plenty of work to do as we make this essential switch. Regardless, I want to personally thank Ashley for her honest, warm, vulnerable presentation. It has, whether directly or not, energized our entire team, myself included. We are collectively beginning to shift our focus away from simply hitting metrics to adopting a true mentoring mindset. Beginning our own journey, so to speak, as we discover that our project is not the only thing we have to offer, and learn to welcome more from our contributors than code.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Adding Run Length Encoding Support to Pilosa</title>
          <link>https://www.pilosa.com/blog/adding-rle-support/</link>
          <pubDate>Mon, 10 Jul 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/adding-rle-support/</guid>
          <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Pilosa is built on our 64-bit implementation of &lt;a href=&#34;http://roaringbitmap.org/&#34;&gt;Roaring bitmaps&lt;/a&gt;, generally accepted as the best approach to compressed storage+computation for arbitrary bitsets. Until recently, our Roaring package was missing one important feature - &lt;a href=&#34;https://en.wikipedia.org/wiki/Run-length_encoding&#34;&gt;run-length encoded&lt;/a&gt; (RLE) sets! With full RLE support added in an upcoming release, we wanted to share some details about its implementation.&lt;/p&gt;
&lt;h3 id=&#34;roaring-basics&#34;&gt;Roaring Basics&lt;/h3&gt;
&lt;p&gt;Roaring Bitmaps is a technique for compressed bitmap indexes described by Daniel Lemire et al. Their work shows that using three different representations for bitmap data results in excellent performance (storage size and computation speed) for general data. These three &amp;ldquo;container types&amp;rdquo; are integer arrays, uncompressed bitsets, and RLE.&lt;/p&gt;
&lt;p&gt;Here is a concrete example of these container types, using this set of integers:&lt;/p&gt;
&lt;p&gt;{0, 1, 2, 3, 6, 7, 9, 10, 14}.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/adding-rle-support/rle-container-example.png&#34; alt=&#34;RLE container example&#34;&gt;
&lt;em&gt;RLE container types&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Array and run values are stored as 16-bit integers, whereas the entire bitset for this small example is only 16 bits. Clearly, the bitset representation wins in size here, but each container type is appropriate for different patterns in the data. For example, if we wanted to store a set of 32 contiguous integers, the RLE representation would be smallest. As a side note, each container has an associated key, which stores the high bits that are common to all elements in the container.&lt;/p&gt;
&lt;p&gt;When we decided to build a standalone bitmap index, Roaring rose to the top as an excellent choice. Implementing it in Go, we used 64-bit keys to support high cardinality, rather than the 32-bit keys in the reference implementation. The RLE container was added to Roaring as an extension after we began our implementation, but as a non-critical feature, it sat on our roadmap for a while. In addition to in-memory storage, Roaring includes a &lt;a href=&#34;https://github.com/RoaringBitmap/RoaringFormatSpec&#34;&gt;full specification for file storage&lt;/a&gt;. Aside from some minor (but binary-incompatible) differences, we followed this closely.&lt;/p&gt;
&lt;h3 id=&#34;adding-rle&#34;&gt;Adding RLE&lt;/h3&gt;
&lt;p&gt;If you&amp;rsquo;re familiar with RLE, this might seem like an odd topic for a blog post. RLE is one of the simplest compression techniques around; functions for encoding and decoding can be written in a handful of lines of your favorite language. The key to Roaring&amp;rsquo;s speed is that the computation of any operation on two containers is done on the raw containers, without modifying either one. Let&amp;rsquo;s consider how the &lt;code&gt;AND&lt;/code&gt; (intersect) operation works, when only the first two container types are implemented. For &lt;code&gt;A AND B&lt;/code&gt;, there are three cases: &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; are arrays (array-array), &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; are bitsets (bitset-bitset), &lt;code&gt;A&lt;/code&gt; is array and &lt;code&gt;B&lt;/code&gt; is bitset or vice versa (array-bitset). Each of these must be implemented separately, so you start to see how Roaring operations are a bit more involved than the simple conceptual &lt;code&gt;AND&lt;/code&gt; operation.&lt;/p&gt;
&lt;p&gt;After adding the new RLE container type, we need three new functions: RLE-RLE, array-RLE, bitset-RLE. This is just for the &lt;code&gt;AND&lt;/code&gt; operation; we need three new functions for the &lt;code&gt;OR&lt;/code&gt; operation as well. We also support the non-commutative difference operation &lt;code&gt;ANDNOT&lt;/code&gt;, which previously required four functions (bitset-array in addition to the three above), and now requires nine (array-RLE, RLE-array, bitset-RLE, RLE-bitset, RLE-RLE). We were adding the &lt;code&gt;XOR&lt;/code&gt; operation in a parallel branch, so we included the new RLE &lt;code&gt;XOR&lt;/code&gt; functions, for another six. That&amp;rsquo;s 17 new functions just to support RLE for these four operations, and many of these are nontrivial. All of these operation functions are summarized in the tables below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/adding-rle-support/rle-function-tables.png&#34; alt=&#34;RLE operation functions&#34;&gt;
&lt;em&gt;RLE operation functions. &amp;ldquo;x&amp;rdquo; indicates a required function; new functions are green&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Functions that operate on one RLE container tend to be more complicated, and functions that operate on two RLE containers even more so. For example, &lt;code&gt;intersectRunRun&lt;/code&gt;, the function for computing &lt;code&gt;AND&lt;/code&gt; for two RLE containers, simultaneously iterates over the runs in each container. For each pair of runs encountered, there are six distinct cases, one for each of the ways that two intervals can overlap with each other. &lt;code&gt;differenceRunRun&lt;/code&gt; might be the trickiest of all the operations. Again, several different overlap cases must be considered, but unlike the intersect algorithm, these cases are interleaved.&lt;/p&gt;
&lt;p&gt;And that&amp;rsquo;s not all - Roaring needs to do a bunch of other things in addition to the binary operations. All of these operations need to be supported, on or with the RLE containers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setting and clearing bits.&lt;/li&gt;
&lt;li&gt;Writing to and reading from files for persistent storage.&lt;/li&gt;
&lt;li&gt;Converting container types for optimal storage size, and deciding when to do it.&lt;/li&gt;
&lt;li&gt;Computing summary values on container types: count, runCount, max. Some of these are also nontrivial, with very clever solutions described in the &lt;a href=&#34;https://arxiv.org/pdf/1603.06549.pdf&#34;&gt;Roaring paper&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Iterating over a Bitmap which can contain a mixture of all three container types.&lt;/li&gt;
&lt;li&gt;An internal &lt;code&gt;intersectionCount&lt;/code&gt; function which speeds up certain queries.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And of course, unit tests. Roaring is central to Pilosa, so we test it as thoroughly as possible. The RLE work consists of 1500+ new lines of feature code, plus 2500+ new lines of unit tests. Although our Roaring package is feature complete, we still have a few tasks on the todo list:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thorough benchmarking and testing on large, real data.&lt;/li&gt;
&lt;li&gt;Expanding fuzz testing.&lt;/li&gt;
&lt;li&gt;Examining inverted storage, for &amp;ldquo;sparse zeroes&amp;rdquo; data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Much of the work can be seen in this &lt;a href=&#34;https://github.com/pilosa/pilosa/pull/661/files&#34;&gt;pull request&lt;/a&gt;, or just in the current &lt;a href=&#34;https://github.com/pilosa/pilosa/tree/master/roaring&#34;&gt;Roaring package&lt;/a&gt;, if you&amp;rsquo;d like to check out the gritty details. We would also love for you to help by forking &lt;a href=&#34;https://github.com/pilosa/pilosa&#34;&gt;Pilosa&lt;/a&gt; and trying it out!&lt;/p&gt;
&lt;h3 id=&#34;departures-from-the-spec&#34;&gt;Departures from the spec&lt;/h3&gt;
&lt;p&gt;Just for the sake of posterity:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Operation support: early on, we only needed a subset of binary operations, notably missing were &lt;code&gt;XOR&lt;/code&gt; and &lt;code&gt;NOT&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Incompatible file spec differences:
&lt;ul&gt;
&lt;li&gt;Our &amp;ldquo;cookie&amp;rdquo; is always bytes 0-3; our container count is always bytes 4-7, never bytes 2-3. This just simplifies the logic of writing and reading files. Our magic number matches the Roaring magic number.&lt;/li&gt;
&lt;li&gt;Our cookie includes file format version in bytes 2-3 (equal to zero for this release).&lt;/li&gt;
&lt;li&gt;Our offset header section is always included. In the spec it is left out for small bitmaps, which explains why it is not rolled into the offset/key section. This is unneccessary parsing complexity for us.&lt;/li&gt;
&lt;li&gt;RLE runs are serialized as [start, last], not [start, length].&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;After the container storage section is an operation log, of unspecified length. This maintains a record of updates to the bitmap, which is processed when a file is read. For more details on this, stay tuned for an upcoming post on Pilosa architecture.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our file format is described in some detail in the &lt;a href=&#34;https://www.pilosa.com/docs/latest/architecture/#roaring-bitmap-storage-format&#34;&gt;docs&lt;/a&gt;.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Cover image illustration credit: &lt;a href=&#34;https://vecteezy.com&#34;&gt;Vecteezy.com&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>OSCON 2017 Recap: The Index As a First Class Citizen</title>
          <link>https://www.pilosa.com/blog/oscon-2017-recap-the-index-as-a-first-class-citizen/</link>
          <pubDate>Sat, 24 Jun 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/oscon-2017-recap-the-index-as-a-first-class-citizen/</guid>
          <description>&lt;p&gt;OSCON 2017 was our first conference as a company. Held in our backyard here in Austin, TX, and coming just days after our official launch, it was an excellent introduction into the open source community.&lt;/p&gt;
&lt;p&gt;Our entire team was on the ground attending sessions, meeting other open source enthusiasts, and trying to locate as many free fidget spinners as possible. With all of us dashing around the Austin Convention Center, it was difficult to get anyone together for a group photo, though we did manager to attend one session as a company. Pilosa showed up in force to support our very own Matt Jaffee. One of our Lead Slothware Engineers, Jaffee spoke about our mission to separate the index from storage, and its multiple advantages for query speed.&lt;/p&gt;
&lt;p&gt;A database is traditionally responsible for both storing and indexing data so that it can be kept safely and accessed quickly. Modern at-scale software architecture has increasingly tended toward breaking things apart (e.g., microservices), which databases have, with few exceptions, resisted. That’s why we created Pilosa, an open source distributed, sparse bitmap index that exists as an acceleration layer over existing data stores, which is being successfully used in production to accelerate queries that were otherwise impractical due to high latency and excess memory use. Pilosa can be used to speed up certain queries to existing databases, or make joining data from multiple stores much faster.&lt;/p&gt;
&lt;p&gt;Jaffee covers some background on databases and indexes and discusses the pros and cons of separating the index from the storage before diving into a general overview of Pilosa and a demonstration of how it can be used to reduce latency and enhance data exploration. Check out the full video, below:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;</description>
        </item>
      
    
      
        <item>
          <title>Tanimoto &amp; Chemical Similarity with Pilosa</title>
          <link>https://www.pilosa.com/blog/tanimoto-and-chemical-similarity-with-pilosa/</link>
          <pubDate>Thu, 15 Jun 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/tanimoto-and-chemical-similarity-with-pilosa/</guid>
          <description>&lt;p&gt;As we continue to test Pilosa against various types of data (e.g., the &lt;a href=&#34;https://www.pilosa.com/blog/billion-taxi-ride-dataset-with-pilosa/&#34;&gt;Billion Taxi Ride Dataset&lt;/a&gt;), we decided to turn our next endeavor into a dual-purpose test. Specifically, we decided to test Pilosa against the &lt;a href=&#34;https://www.ebi.ac.uk/chembl/downloads&#34;&gt;Chemical Similarity for ChemBL dataset&lt;/a&gt; while also testing Pilosa’s ability to run algorithms in its native core.&lt;/p&gt;
&lt;p&gt;The notion of chemical similarity (or molecular similarity) is one of the most important concepts in cheminformatics. It plays an important role in modern approaches to predicting the properties of chemical compounds, designing chemicals with a predefined set of properties and, especially, in conducting drug design studies by screening large databases containing structures of available or potentially available chemicals.
One commonly used algorithm to calculate these measures of similarity is the Tanimoto algorithm. The resulting Tanimoto coefficient is fingerprint-based, encoding each molecule to a fingerprint “bit” position, with each bit recording the presence (“1”) or absence (“0”) of a fragment in the molecule. Given the binary format, we determined it would be a perfect fit to test against Pilosa.&lt;/p&gt;
&lt;p&gt;In this post, we’ll look at the problem of finding chemical similarity and how, using Pilosa, we can achieve performance that is 3x faster than existing state-of-the-art systems (see MongoDB, below) and 10x faster than our initial naive Pilosa implementation. As solutions to the chemical similarity search problem have been attempted by other individuals using different technologies (tested on &lt;a href=&#34;http://blog.matt-swain.com/post/87093745652/chemical-similarity-search-in-mongodb&#34;&gt;MongoDB&lt;/a&gt; by Matt Swan, or on [PostgreSQL] (&lt;a href=&#34;http://blog.rguha.net/?p=1261&#34;&gt;http://blog.rguha.net/?p=1261&lt;/a&gt;) by Rajarshi Guha), we knew we would be able to compare our results to existing solutions.&lt;/p&gt;
&lt;h3 id=&#34;overview-of-tanimoto&#34;&gt;Overview of Tanimoto&lt;/h3&gt;
&lt;p&gt;The Tanimoto algorithm states that &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; are sets of fingerprint “bits” within the fingerprints of molecule &lt;em&gt;A&lt;/em&gt; and molecule &lt;em&gt;B&lt;/em&gt;. &lt;em&gt;AB&lt;/em&gt; is defined as the set of common bits of fingerprints of both molecule &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt;. The resulting Tanimoto coefficient (or &lt;em&gt;T(A,B)&lt;/em&gt;) ranges from 0, when the fingerprints have no bits in common, to 1, when the fingerprints are identical. Thus,&lt;/p&gt;
&lt;p&gt;&lt;code&gt;T(A,B) = (A ∩ B)/(A + B - A ∩ B)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The chemical similarity problem then becomes, &lt;em&gt;Given molecule A, find all formulas that have a Tanimoto coefficient greater than a given threshold&lt;/em&gt;. The greater the value of a set threshold, the more similar the molecules are.&lt;/p&gt;
&lt;h3 id=&#34;pilosa&#34;&gt;Pilosa&lt;/h3&gt;
&lt;p&gt;To model data in Pilosa, one must choose what the columns represent and what the rows represent. We chose to let each column represent a bit position ID within the digital fingerprint and each row represent a molecule ID.&lt;/p&gt;
&lt;p&gt;Pilosa stores information as a series of bits, and in this case one can use RDKit in Python to convert molecules from their SMILES encoding to Morgan fingerprints with 4,096 bits size, which are arrays of “on” bit positions. As a benchmarking measure, we also followed &lt;a href=&#34;http://blog.matt-swain.com/post/87093745652/chemical-similarity-search-in-mongodb&#34;&gt;Matt Swain’s instructions&lt;/a&gt; to import the same data set into MongoDB with the same Morgan fingerprint size.&lt;/p&gt;
&lt;p&gt;We were able create a data model in Pilosa like so:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/tanimoto-and-chemical-similarity-with-pilosa/data-model.png&#34; alt=&#34;Data Modeling&#34;&gt;&lt;/p&gt;
&lt;p&gt;It took 21 minutes to export chembl_id and SMILES from SDF to csv, and took ~3 minutes to import 1,678,343 rows into Pilosa on a MacBook Pro with a 2.8 GHz 2-core Intel Core i7 processor, memory of 16 GB 1600 MHz DDR3, single host cluster.&lt;/p&gt;
&lt;h3 id=&#34;naive-approach&#34;&gt;Naive Approach&lt;/h3&gt;
&lt;p&gt;The first approach we took after successfully loading the data into Pilosa was rather naive. We created a Python script that used a Pilosa client and sent requests to fetch the following values,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Count of &lt;em&gt;A&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Intersection &lt;em&gt;A ∩ B&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Count of &lt;em&gt;B&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The last two requests are batched requests for 100,000 rows. We then calculated the Tanimoto coefficient on the client.&lt;/p&gt;
&lt;p&gt;While this approach is simple, its performance is suboptimal due to the network latency required in sending all these requests. Using this setup, Pilosa didn’t compare favorably with MongoDB at all. While we beat MongoDB at lower thresholds, our performance didn&amp;rsquo;t improve much at higher thresholds. MongoDB has an advantage in that its aggregation framework can perform all calculation tasks at the server.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/tanimoto-and-chemical-similarity-with-pilosa/mongo-vs-pilosa1.png&#34; alt=&#34;Mongo vs. Pilosa&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Chart of comparison between MongoDB aggregation framework and naive Pilosa implementation&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;improved-approach&#34;&gt;Improved Approach&lt;/h3&gt;
&lt;p&gt;However, our naive approach definitely helped us to come up with a better solution. The main problem is network latency, which will be completely resolved if we can perform the Tanimoto algorithm in the Pilosa core. Since Pilosa already stores count of A and B in its own cache, we theorized it would be much faster to calculate Tanimoto inside Pilosa, then return similarity results to a client.&lt;/p&gt;
&lt;p&gt;Given the results below, the performance of this approach blew away our naive approach, clocking in at 10x faster. It is also 3x faster than the fastest MongoDB approach. Both used the same molecule, with Morgan fingerprint folded to fixed lengths of 4,096 bits and were run on a MacBook Pro with a 2.8 GHz 2-core Intel Core i7 processor, memory of 16 GB 1600 MHz DDR3, single host cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/tanimoto-and-chemical-similarity-with-pilosa/mongo-vs-pilosa2.png&#34; alt=&#34;Mongo vs. Pilosa&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Chart of comparison between MongoDB aggregation framework and core Pilosa implementation&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Even though we improved performance significantly, adding every new algorithm one-by-one into Pilosa’s core isn’t sustainable. Because we want to extend Pilosa’s support of other algorithms, we have implemented a plugin system (which will be released soon!). This will allow for easy and custom development of algorithms that run on Pilosa hosts, thereby cutting the network round trip. Moving Tanimoto to plugin doesn’t change the speed of the similarity calculation that we tested above, and there will be significant room for many other plugin developments without any effect on performance.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Pilosa 0.4.0 Released</title>
          <link>https://www.pilosa.com/blog/pilosa-0-4-0-released/</link>
          <pubDate>Thu, 08 Jun 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/pilosa-0-4-0-released/</guid>
          <description>&lt;p&gt;The Pilosa team is happy to announce the release of &lt;a href=&#34;https://github.com/pilosa/pilosa/releases/tag/v0.4.0&#34;&gt;Pilosa 0.4.0&lt;/a&gt;, marking our second minor release since &lt;a href=&#34;https://www.pilosa.com/blog/hello-world/&#34;&gt;open-sourcing on April 29&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This version contains 53 contributions from 13 contributors, including four volunteer contributors. Special thanks to &lt;a href=&#34;https://github.com/kalimatas&#34;&gt;Alexander G.&lt;/a&gt;, &lt;a href=&#34;https://github.com/dgryski&#34;&gt;Damian G.&lt;/a&gt;, &lt;a href=&#34;https://github.com/graphaelli&#34;&gt;Gil R.&lt;/a&gt;, and &lt;a href=&#34;https://github.com/jnovinger&#34;&gt;Jason N.&lt;/a&gt; for your pull requests on &lt;a href=&#34;https://github.com/pilosa/pilosa&#34;&gt;Github&lt;/a&gt;! Also thanks to &lt;a href=&#34;https://github.com/bgyss&#34;&gt;Brian G.&lt;/a&gt; for creating a &lt;a href=&#34;https://github.com/Homebrew/homebrew-core/pull/13251&#34;&gt;Homebrew package&lt;/a&gt; for Mac installation!&lt;/p&gt;
&lt;p&gt;Some notable features include:&lt;/p&gt;
&lt;h3 id=&#34;statsd-metrics-reporting&#34;&gt;StatsD metrics reporting&lt;/h3&gt;
&lt;p&gt;This release includes support for metrics reporting via the &lt;a href=&#34;https://github.com/etsy/statsd&#34;&gt;StatsD&lt;/a&gt; protocol. When enabled, this allows you to monitor several metrics in Pilosa like queries per second, garbage collection stats, and snapshot events. Metrics also include Datadog-compatible tags. Learn more &lt;a href=&#34;https://www.pilosa.com/docs/latest/administration/#metrics&#34;&gt;about our metrics support&lt;/a&gt; and &lt;a href=&#34;https://www.pilosa.com/docs/latest/configuration/#metric-service&#34;&gt;how to configure it&lt;/a&gt; in our documentation.&lt;/p&gt;
&lt;h3 id=&#34;webui-enhancements&#34;&gt;WebUI Enhancements&lt;/h3&gt;
&lt;p&gt;The WebUI is now more useful with the addition of query input autocompletion, a cluster metadata viewer, and a syntax for frame and index creation. &lt;a href=&#34;https://www.pilosa.com/docs/console/&#34;&gt;Learn more about the WebUI&lt;/a&gt; in our documentation.&lt;/p&gt;
&lt;h3 id=&#34;docker-multi-stage-build&#34;&gt;Docker multi-stage build&lt;/h3&gt;
&lt;p&gt;By popular demand, we cut a special release to include a &lt;a href=&#34;https://docs.docker.com/engine/userguide/eng-image/multistage-build/&#34;&gt;Docker multi-stage build&lt;/a&gt; with Pilosa 0.3.2 a few days after Docker 17.05 was released with that feature. This is the first minor Pilosa release with official support for Docker multi-stage builds. It is available through &lt;a href=&#34;https://hub.docker.com/r/pilosa/pilosa/&#34;&gt;Docker hub&lt;/a&gt; or can be built locally with &lt;code&gt;make docker&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;bug-fixes-and-performance&#34;&gt;Bug fixes and performance&lt;/h3&gt;
&lt;p&gt;We hope to always stay focused on stability and performance, so Pilosa 0.4.0 includes 14 bug fixes and 3 performance-related patches.&lt;/p&gt;
&lt;h3 id=&#34;changelog&#34;&gt;Changelog&lt;/h3&gt;
&lt;p&gt;For this release, we&amp;rsquo;ve adopted the &lt;a href=&#34;http://keepachangelog.com/&#34;&gt;Keep a Changelog&lt;/a&gt; guidelines for managing release notes.&lt;/p&gt;
&lt;p&gt;To see the complete list of new features, fixes, and performance improvements, check out &lt;a href=&#34;https://github.com/pilosa/pilosa/blob/master/CHANGELOG.md&#34;&gt;our changelog on Github&lt;/a&gt;.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>The Billion Taxi Ride Dataset with Pilosa</title>
          <link>https://www.pilosa.com/blog/billion-taxi-ride-dataset-with-pilosa/</link>
          <pubDate>Fri, 02 Jun 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/billion-taxi-ride-dataset-with-pilosa/</guid>
          <description>&lt;p&gt;Pilosa was originally built for the very specific use case of arbitrary audience
segmentation on hundreds of millions of people with tens of millions of attributes.
As we&amp;rsquo;ve spun out a separate company around Pilosa, a natural first step was to
test its efficacy on other types of problems.&lt;/p&gt;
&lt;p&gt;While the user segmentation use case has a very high number of attributes,
the data is extremely sparse—most attributes are only associated with a handful
of people, and most individuals only have a few hundred or a few thousand attributes.
Pilosa handles this type of data gracefully; in just milliseconds, one can choose any
boolean combination of the millions of attributes and find the segment of users which
satisfies that combination.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/billion-taxi-umbel.png&#34; alt=&#34;Segmentation in Umbel&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Image courtesy of Umbel&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For audience segmentation, we&amp;rsquo;d happily pit Pilosa against anything out there on
similar hardware. However, if we want Pilosa to be an index which serves as a
general purpose query acceleration layer over other data stores, it will have to
be effective at more than just segmentation queries, and more than just sparse,
high cardinality data. In order to test Pilosa, we needed a dataset which had
dense, lower cardinality data, and ideally one which has been explored by other
solutions so that we could get a feel for how we might fare against them. The
&lt;a href=&#34;http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml&#34;&gt;billion taxi ride dataset&lt;/a&gt;
fit the bill perfectly. There are myriad blog posts analyzing the dataset with
various technologies; here are just a few:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;http://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/&#34;&gt;Analyzing 1.1 Billion NYC Taxi and Uber Trips, with a Vengeance&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://kx.com/2017/01/25/kx-1-1-billion-taxi-ride-benchmark-highlights-advantages-kdb-architecture/&#34;&gt;Kx 1.1 billion taxi ride benchmark highlights advantages of kdb+ architecture&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://chriswhong.com/open-data/should-i-stay-or-should-i-go-nyc-taxis-at-the-airport/&#34;&gt;Should I Stay or Should I Go? NYC Taxis at the Airport&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of particular usefulness to us are the series of posts by Mark Litwintschik and the &lt;a href=&#34;http://tech.marksblogg.com/benchmarks.html&#34;&gt;performance comparison&lt;/a&gt; table he compiled. Here is the table for reference:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/billion-taxi-table1.png&#34; alt=&#34;Mark&amp;rsquo;s benchmarks&#34;&gt;&lt;/p&gt;
&lt;p&gt;We implemented the same four queries against Pilosa so that we could get some comparison of performance against other solutions.&lt;/p&gt;
&lt;p&gt;Here is the English description of each query:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How many rides are there with each cab type?&lt;/li&gt;
&lt;li&gt;For each number of passengers, what is the average cost of all taxi rides?&lt;/li&gt;
&lt;li&gt;In each year, and for each passenger count, how many taxi rides were there?&lt;/li&gt;
&lt;li&gt;For each combination of passenger count, year, and trip distance, how many rides were there - results ordered by year, and then number of rides descending.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now we have a dataset and a set of queries which are far outside Pilosa&amp;rsquo;s
comfort zone, along with a long list of performance comparisons on different
combinations of hardware and software.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;d like to learn more about how we modeled the dataset in Pilosa and
structured the queries, please see our &lt;a href=&#34;https://www.pilosa.com/use-cases/taming-transportation-data/&#34;&gt;transportation use case post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So instead of tens of millions of boolean attributes, we have just a few
attributes with more complex types: integers, floating point, timestamp, etc.
In short, this data is far more suitable to a relational database than the data
for which Pilosa was designed.&lt;/p&gt;
&lt;p&gt;We stood up a 3-node Pilosa cluster on AWS c4.8xlarge instances, with an additional
c4.8xlarge to load the data. We used our open source &lt;a href=&#34;https://www.pilosa.com/docs/pdk/&#34;&gt;pdk&lt;/a&gt;
tool to load the data into Pilosa with the following arguments:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pdk taxi -b 2000000 -c 50 -p &amp;lt;pilosa-host-ip&amp;gt;:10101 -f
&amp;lt;pdk_repo_location&amp;gt;/usecase/taxi/greenAndYellowUrls.txt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This took about 2 hours and 50 minutes, which includes downloading all of the csv
files from S3, parsing them, and loading the data into Pilosa.&lt;/p&gt;
&lt;p&gt;If we were to add our results to Mark&amp;rsquo;s table, it would look like the following:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/billion-taxi-table2.png&#34; alt=&#34;Mark&amp;rsquo;s benchmarks with Pilosa&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note that the hardware and software are different for each setup, so direct comparisons are difficult.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We should note that Pilosa &amp;ldquo;cheats&amp;rdquo; a bit on query 1; due to the way it stores
data, Pilosa already has this result precomputed, so the query time is mostly
network latency.&lt;/p&gt;
&lt;p&gt;For the remainder of the queries, however, Pilosa does remarkably well—in
some cases beating out exotic hardware such as multi-GPU setups. The 0.177s time
on query 3 was particularly startling—performance was along the lines of 8 Nvidia
Pascal Titan Xs. It looks like kdb+/q is beating us pretty soundly,
but keep in mind that those Xeon Phi 7210s have 256 hardware threads per chip,
as well as 16GB of memory &lt;em&gt;on the package&lt;/em&gt;. This gives them performance and
memory bandwidth closer to GPUs than CPUs. They&amp;rsquo;re also about $2400 a piece.&lt;/p&gt;
&lt;p&gt;For us, these results are enough to validate spending more time optimizing
Pilosa for uses outside of its original intent. We know that Pilosa&amp;rsquo;s internal
bitmap compression format is not optimized for dense data, and more research has
been done in this area with exciting results (e.g. &lt;a href=&#34;https://arxiv.org/pdf/1603.06549.pdf&#34;&gt;roaring-run&lt;/a&gt;),
so we have reason to believe that there is significant room for improvement in these numbers.&lt;/p&gt;
&lt;p&gt;UPDATE: After implementing run-length encoding, and some other optimizations, Pilosa is &lt;em&gt;significantly&lt;/em&gt;  faster on many of these queries and beats every other system on Query 3!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.pilosa.com/img/blog/billion-taxi-table3.png&#34; alt=&#34;Mark&amp;rsquo;s benchmarks with Pilosa - updated&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Jaffee is a lead software engineer at Pilosa. When he’s not crunching a billion taxi rides, he enjoys jiu-jitsu, building mechanical keyboards, and spending time with family. Follow him on Twitter at &lt;a href=&#34;https://twitter.com/mattjaffee?lang=en&#34;&gt;@mattjaffee&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Alan is a software engineer at Pilosa. When he’s not mapping the universe, you can find him playing with laser cutters, building fidget spinners for his dog, or practicing his sick photography skills. Find him on Twitter &lt;a href=&#34;https://twitter.com/gsnark&#34;&gt;@gsnark&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>The OSCON 2017 Guide to Authentic Austin Tacos</title>
          <link>https://www.pilosa.com/blog/oscon-2017-guide-to-authentic-austin-tacos/</link>
          <pubDate>Wed, 10 May 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/oscon-2017-guide-to-authentic-austin-tacos/</guid>
          <description>&lt;p&gt;Before we begin, OSCONers, let’s get real: If you’re not brave enough to order from a food truck, this list is not for you. Four of our top five taco picks began as food trucks, and two of the five still sell exclusively from those same food trucks within city limits.&lt;/p&gt;
&lt;p&gt;And no, we still don’t have Über or Lyft (pro tip: check out &lt;a href=&#34;https://fasten.com/&#34;&gt;Fasten&lt;/a&gt; or &lt;a href=&#34;http://www.rideaustin.com/&#34;&gt;Ride Austin&lt;/a&gt; instead). But we do have tacos. Not burritos. Not chimichangas. Just tacos. Real. Good. Tacos.&lt;/p&gt;
&lt;p&gt;To kick us off, we’re taking a stand in one of the most serious taco rivalries you never knew existed with our number one and two picks:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.tacodeli.com/&#34;&gt;Taco Deli&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Second only to the University of Texas vs. Texas A&amp;amp;M rivalry is that between Torchy’s and Taco Deli. It’s impossible to not pick sides, and we’re officially throwing in for Taco Deli, which has developed something of a cult following in this taco-loving town. With their commitment to organic, locally sourced ingredients, one bite of basically anything on the menu will have you slow nodding with satisfaction. Further, the in-house service is surprisingly friendly and generally excellent, even during the inevitable breakfast and lunch rushes.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Try: The Heather, Al Pastor, Freakin’ Vegan&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://torchystacos.com/&#34;&gt;Torchy’s Tacos&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Coming in a very close and highly contentious second is the brash Torchy’s Tacos. This local food truck turned national chain always delivers on the goods. Their delicious and adventurous tacos are a consistent pleasure to locals and tourists alike, especially if you ask for their secret menu. Bonus: Their queso is second to none, with delightful globs of guacamole and house-made diablo hot sauce in every bite.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Try: Fried Avocado, Trailer Park (Trashy), Dirty Sanchez&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://veracruztacos.com/&#34;&gt;Veracruz All Natural&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This darling food truck is, like much of Austin, more than what it seems. Their tacos will make you seriously reconsider the role of the tortilla, and make you wonder how you’ll ever accept anything less from future tacos. They’re also one of the only taco vendors in the city whose migas taco is better than an actual plate of migas – no small feat if you know anything about TexMex.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Try: Migas. Just the Migas.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://www.puebloviejoaustin.com/&#34;&gt;Pueblo Viejo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tucked away in an unassuming food trailer lot is the taco gem of the East Side. With its straightforward, no-nonsense offerings for breakfast and lunch, this food truck provides an unwavering source of stability amidst the turbulence of East 6th. While it will always be there for your after a night out on East or Dirty, breakfast is best. Beat the hangover with a Taco Bueno and feel free to thank us later.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Try: Taco Bueno, Mi Madre Taco, Taco Margarita&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;http://tacoxpress.com/&#34;&gt;Maria’s Taco Xpress&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s be real, we put this one last so tourists wouldn’t crowd the already volatile lunch and breakfast lines. And also because it’s so far south of Lamar that you probably scoffed after Google Mapping it anyway. Either way, Maria’s is a shrine to all that is weird and beautiful about Austin taco culture. Full to bursting with Austin memorabilia and guarded by the Taco Goddess herself, this quirky little taco joint is a microcosm for all that you’ll come to love after a few days in the Texas capitol.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Try: Mexi Taco, Beef Fajita, Bandera&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;And if you don’t want to visit any of these Austin taco locations, we won’t be at all upset. The lines will move that much faster when we arrive to feed our own taco obsessions.&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>OSCON 2017: The Index As a First Class Citizen</title>
          <link>https://www.pilosa.com/blog/oscon-2017-the-index-as-a-first-class-citizen/</link>
          <pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/oscon-2017-the-index-as-a-first-class-citizen/</guid>
          <description>&lt;p&gt;Don’t miss Pilosa’s Lead “Slothware” Engineer, Matt Jaffee, at his &lt;a href=&#34;https://conferences.oreilly.com/oscon/oscon-tx&#34;&gt;O&amp;rsquo;Reilly Open Source Convention&lt;/a&gt; speaking debut! Titled &lt;a href=&#34;https://conferences.oreilly.com/oscon/oscon-tx/public/schedule/detail/60565&#34;&gt;&lt;em&gt;The Index As a First-Class Citizen&lt;/em&gt;&lt;/a&gt;, Jaffee will explore what happens when you take the index out of the database and make it a separate application—one that is distributed, scalable, and takes full advantage of modern, multicore, high-memory hardware. Jaffee’s talk will be on Wednesday, May 10th at 11:00 AM in Meeting Room 13.&lt;/p&gt;
&lt;p&gt;Jaffee will discuss the traditional role of databases, which are responsible for both storing and indexing data so that it can be kept safely and accessed quickly. Modern at-scale software architecture, however, has increasingly tended toward breaking things apart (e.g., microservices), which databases have, with few exceptions, resisted.&lt;/p&gt;
&lt;p&gt;Our answer to this problem is Pilosa, an open-source, distributed, sparse bitmap index that exists as an acceleration layer over existing data stores, which is being successfully used in production to accelerate queries that were otherwise impractical due to high latency and excess memory use. Pilosa can be used to speed up certain queries to existing databases, or make joining data from multiple stores much faster.&lt;/p&gt;
&lt;p&gt;Jaffee covers some background on databases and indexes and discusses the pros and cons of separating the index from the storage before diving into a general overview of Pilosa and a demonstration of how it can be used to reduce latency and enhance data exploration.&lt;/p&gt;
&lt;p&gt;Whether or not you can make the presentation, you can catch Jaffee throughout OSCON at our booth in the Expo Hall (#532), or at any of these &lt;a href=&#34;https://www.pilosa.com/blog/pilosa-at-oscon-2017/&#34;&gt;Pilosa-sponsored OSCON events&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We hope to see you there!&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Pilosa at OSCON 2017</title>
          <link>https://www.pilosa.com/blog/pilosa-at-oscon-2017/</link>
          <pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/pilosa-at-oscon-2017/</guid>
          <description>&lt;p&gt;Join us for the official launch of Pilosa at the &lt;a href=&#34;https://conferences.oreilly.com/oscon/oscon-tx&#34;&gt;O&amp;rsquo;Reilly Open Source Convention&lt;/a&gt; in our home town of Austin, Texas!&lt;/p&gt;
&lt;p&gt;Our team of engineers will be at the Austin Convention Center on May 10th and 11th, and would love to talk all things open source. In particular, we’re eager to discuss how Pilosa—an open-source, distributed bitmap index that dramatically accelerates queries across multiple, massive data sets—can support the work of the broader open-source community. Find us at the following OSCON events:&lt;/p&gt;
&lt;h3 id=&#34;presentation-the-index-as-a-first-class-citizen&#34;&gt;Presentation: The Index As a First-Class Citizen&lt;/h3&gt;
&lt;p&gt;We’d also advise you not to miss &lt;a href=&#34;https://www.pilosa.com/blog/oscon-2017-the-index-as-a-first-class-citizen/&#34;&gt;a presentation by Matt Jaffee&lt;/a&gt;, our very own Lead “Slothware” Engineer. Titled &lt;a href=&#34;https://conferences.oreilly.com/oscon/oscon-tx/public/schedule/detail/60565&#34;&gt;The Index As a First-Class Citizen&lt;/a&gt;, Jaffee explores  what happens when you take the index out of the database and make it a separate application—one that is distributed, scalable, and takes full advantage of modern, multicore, high-memory hardware. Jaffee’s talk will be on Wednesday, May 10th at 11:00 AM in Meeting Room 13.&lt;/p&gt;
&lt;h3 id=&#34;catch-us-in-the-expo-hall&#34;&gt;Catch Us In the Expo Hall&lt;/h3&gt;
&lt;p&gt;If you can’t make Jaffee’s talk but are curious about Pilosa’s applications, members of our engineering team will be at Booth #532 in the Expo Hall on Tuesday and Wednesday. Feel free to stop by at any time, or hold out for the free food and local craft beers that will be at the booth from 5:45 PM to 7:00 PM as part of the official &lt;a href=&#34;https://conferences.oreilly.com/oscon/oscon-tx/public/schedule/detail/57853&#34;&gt;OSCON Booth Crawl&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;pilosa-launch-party&#34;&gt;Pilosa Launch Party&lt;/h3&gt;
&lt;p&gt;Last, and certainly not least, swing by our official Launch Party at &lt;a href=&#34;http://sellersaustin.com/&#34;&gt;Sellers Underground&lt;/a&gt; (&lt;a href=&#34;https://www.google.com/maps/place/Sellers/@30.2664729,-97.747739,17z/&#34;&gt;213 West 4th St.&lt;/a&gt;) at 7:00pm on Wednesday! Members of our team will be handing out tickets (good for two free drinks) all day Wednesday, so be sure to stop by our booth or flag down anyone wearing a Pilosa t-shirt!&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Hello, World</title>
          <link>https://www.pilosa.com/blog/hello-world/</link>
          <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
          
          <guid>https://www.pilosa.com/blog/hello-world/</guid>
          <description>&lt;p&gt;We are Pilosa, order of the sloth. We make slothware.&lt;/p&gt;
&lt;p&gt;Our slumber (which is what some call a group of sloths) has created a distributed bitmap index that sits on top of data stores and dramatically accelerates query speed across multiple, massive data sets.&lt;/p&gt;
&lt;p&gt;Today we are open-sourcing our work under the Apache License, version 2.0, and we hope that you will join us on this journey.&lt;/p&gt;
&lt;p&gt;Why did we create Pilosa? Because the rate that information can be read from storage has not kept pace with the exponential growth that we&amp;rsquo;ve seen in both compute capacity and data volume. Realizing this, we wanted to provide a better way to query, and gain insights from, our ever-growing data stores without being constrained by the time it takes to read all of that data.&lt;/p&gt;
&lt;p&gt;The Pilosa index helps big data seem smaller by representing the underlying data and its relationships as binary values. Unlike the indexes typically found in database systems, which are tightly coupled to and dependent upon the storage engine, Pilosa is independent of storage—a first class citizen in the data stack.&lt;/p&gt;
&lt;p&gt;When we set out to build Pilosa, our goal was to create something that would allow scientists to ask questions of all their data in real-time, no matter how large the data set. With Pilosa, I think we&amp;rsquo;ve done just that. I&amp;rsquo;m proud of what we&amp;rsquo;ve built so far, and I&amp;rsquo;m excited to see what we—and the Pilosa community—will build in the days to come!&lt;/p&gt;
&lt;p&gt;While we sloths and our superorder Xenartha began evolving 60 million years ago, Pilosa the company was founded in 2017 with a commitment to building community-driven, open-source software that unlocks the full power of data science.&lt;/p&gt;</description>
        </item>
      
    
  </channel>
</rss>
